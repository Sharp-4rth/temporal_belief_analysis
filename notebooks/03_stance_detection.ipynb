{
  "cells": [
    {
      "metadata": {
        "id": "898a584a995da034"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 1,
      "source": [
        "# !git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
      ],
      "id": "898a584a995da034"
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "j9oyyIUrws5P"
      },
      "id": "j9oyyIUrws5P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get latest version\n",
        "%cd temporal_belief_analysis\n",
        "!git pull"
      ],
      "metadata": {
        "id": "zqsW1RnMwzM5"
      },
      "id": "zqsW1RnMwzM5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "!pip install convokit"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yzRsE75Dw1nv"
      },
      "id": "yzRsE75Dw1nv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "import unsloth\n",
        "import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit\n",
        "# corpus = Corpus(filename=download(\"subreddit-PoliticalDiscussion\"))\n",
        "corpus = Corpus(filename=\"/content/pd_corpus_with_topics.zip\")"
      ],
      "metadata": {
        "id": "7N4rV-m2w3pd",
        "outputId": "48a25267-f9f9-4c19-d870-ad56f78f5160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "id": "7N4rV-m2w3pd",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'utterances' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-16-3254408778.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvokit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# corpus = Corpus(filename=download(\"subreddit-PoliticalDiscussion\"))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/pd_corpus_with_topics.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/convokit/model/corpus.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, utterances, db_collection_prefix, db_host, preload_vectors, utterance_start_index, utterance_end_index, merge_lines, exclude_utterance_meta, exclude_conversation_meta, exclude_speaker_meta, exclude_overall_meta, disable_type_check, backend, backend_mapper)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mspeakers_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mconvos_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     utterances = load_from_utterance_file(\n\u001b[0m\u001b[1;32m    173\u001b[0m                         \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutterance_start_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutterance_end_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/convokit/model/corpus_helpers.py\u001b[0m in \u001b[0;36mload_from_utterance_file\u001b[0;34m(filename, utterance_start_index, utterance_end_index)\u001b[0m\n\u001b[1;32m    331\u001b[0m                 \u001b[0;34m\"Could not load corpus. Expected json file, encountered error: \\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m             )\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutterances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'utterances' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dataset was loaded:\n",
        "print(corpus.random_utterance().text)"
      ],
      "metadata": {
        "id": "ffWPj5AFw5Ai"
      },
      "id": "ffWPj5AFw5Ai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For runpod-jupyter or local\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "from temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
        "from temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig"
      ],
      "metadata": {
        "id": "-901CJu60s2l"
      },
      "id": "-901CJu60s2l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from temporal_belief_analysis.src.temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
        "from temporal_belief_analysis.src.temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig"
      ],
      "metadata": {
        "id": "IGkImDcZ0fPq"
      },
      "id": "IGkImDcZ0fPq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt for stance detection\n",
        "\"\"\"Topic detection functionality for conversation analysis.\"\"\"\n",
        "\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TopicDetector:\n",
        "    \"\"\"Detect topics in ConvoKit conversations using BART.\"\"\"\n",
        "\n",
        "    def __init__(self, topics: Optional[List[str]] = None,\n",
        "                 config: ProjectConfig = None):\n",
        "        \"\"\"Initialize topic detector.\"\"\"\n",
        "        self.config = config or ProjectConfig()\n",
        "        self.classifier = BARTZeroShotClassifier(self.config.bart_model_name)\n",
        "        self.topics = topics or POLITICAL_TOPICS\n",
        "        logger.info(f\"Initialized topic detector with {len(self.topics)} topics\")\n",
        "\n",
        "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
        "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
        "        utterances = list(conversation.iter_utterances())\n",
        "\n",
        "        # Safe attribute access\n",
        "        title = conversation.meta.get('title', '')\n",
        "\n",
        "        # Safe utterance handling\n",
        "        first_utterance = utterances[0] if utterances else None\n",
        "        original_post = first_utterance.text if first_utterance else ''\n",
        "\n",
        "        if not original_post and not title:\n",
        "            logger.warning(f\"No utterances or title found in conversation {conversation.id}\")\n",
        "            return {\"topic\": \"unknown\", \"confidence\": 0.0}\n",
        "\n",
        "        # Truncate long texts to prevent memory issues\n",
        "        combined_text = f\"Title: {title}. Original Post: {original_post}\"[:2000]\n",
        "        result = self.classifier.classify_text(combined_text, self.topics)\n",
        "\n",
        "        return {\n",
        "            \"topic\": result[\"label\"],\n",
        "            \"confidence\": result[\"confidence\"],\n",
        "            \"all_scores\": result[\"all_scores\"],\n",
        "            \"text_length\": len(original_post),\n",
        "            \"num_utterances\": len(utterances)\n",
        "        }\n",
        "\n",
        "    def process_corpus(self, corpus, batch_size: int = 50,  # Balanced batch size\n",
        "                    save_path: Optional[str] = None) -> None:\n",
        "        \"\"\"Process entire corpus for topic detection.\"\"\"\n",
        "        conversations = list(corpus.iter_conversations())\n",
        "        logger.info(f\"Processing {len(conversations)} conversations for topic detection\")\n",
        "\n",
        "        for i in tqdm(range(0, len(conversations), batch_size),\n",
        "                      desc=\"Processing conversations\"):\n",
        "            batch = conversations[i:i + batch_size]\n",
        "\n",
        "            # Prepare all texts for batch processing\n",
        "            batch_texts = []\n",
        "            valid_conversations = []\n",
        "\n",
        "            for conv in batch:\n",
        "                try:\n",
        "                    # Safe attribute access\n",
        "                    title = conv.meta.get('title', '')\n",
        "                    utterances = list(conv.iter_utterances())\n",
        "\n",
        "                    # Safe utterance handling\n",
        "                    first_utterance = utterances[0] if utterances else None\n",
        "                    original_post = first_utterance.text if first_utterance else ''\n",
        "\n",
        "                    if not original_post and not title:\n",
        "                        logger.warning(f\"No utterances or title found in conversation {conv.id}\")\n",
        "                        # Set metadata for empty conversations\n",
        "                        conv.add_meta(\"detected_topic\", \"unknown\")\n",
        "                        conv.add_meta(\"topic_confidence\", 0.0)\n",
        "                        conv.add_meta(\"topic_scores\", {})\n",
        "                        continue\n",
        "\n",
        "                    # Truncate long texts\n",
        "                    combined_text = f\"{title}. {original_post}\"[:2000]\n",
        "                    batch_texts.append(combined_text)\n",
        "                    valid_conversations.append(conv)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to prepare conversation {conv.id}: {e}\")\n",
        "                    conv.add_meta(\"detected_topic\", \"unknown\")\n",
        "                    conv.add_meta(\"topic_confidence\", 0.0)\n",
        "                    conv.add_meta(\"topic_scores\", {})\n",
        "\n",
        "            # Process entire batch at once\n",
        "            if batch_texts:\n",
        "                try:\n",
        "                    print(f\"🚀 Attempting batch of {len(batch_texts)} texts...\")\n",
        "                    import time\n",
        "                    start = time.time()\n",
        "\n",
        "                    batch_results = self.classifier.classify_batch(batch_texts, self.topics)\n",
        "\n",
        "                    end = time.time()\n",
        "                    print(f\"✅ Batch completed in {end-start:.2f}s ({(end-start)/len(batch_texts):.3f}s per text)\")\n",
        "\n",
        "                    # Apply results back to conversations\n",
        "                    for conv, result in zip(valid_conversations, batch_results):\n",
        "                        conv.add_meta(\"detected_topic\", result[\"label\"])\n",
        "                        conv.add_meta(\"topic_confidence\", result[\"confidence\"])\n",
        "                        conv.add_meta(\"topic_scores\", result[\"all_scores\"])\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Batch processing failed: {e}\")\n",
        "                    logger.error(f\"Batch classification failed: {e}\")\n",
        "\n",
        "                    # Fallback to individual processing\n",
        "                    for conv in valid_conversations:\n",
        "                        try:\n",
        "                            topic_result = self.detect_conversation_topic(conv)\n",
        "                            conv.add_meta(\"detected_topic\", topic_result[\"topic\"])\n",
        "                            conv.add_meta(\"topic_confidence\", topic_result[\"confidence\"])\n",
        "                            conv.add_meta(\"topic_scores\", topic_result[\"all_scores\"])\n",
        "                        except Exception as e2:\n",
        "                            logger.error(f\"Individual fallback failed for {conv.id}: {e2}\")\n",
        "                            conv.add_meta(\"detected_topic\", \"unknown\")\n",
        "                            conv.add_meta(\"topic_confidence\", 0.0)\n",
        "                            conv.add_meta(\"topic_scores\", {})\n",
        "\n",
        "        if save_path:\n",
        "            corpus.dump(save_path)\n",
        "            logger.info(f\"Saved processed corpus to {save_path}\")\n",
        "\n",
        "        logger.info(\"Topic detection processing complete\")"
      ],
      "metadata": {
        "id": "42g0WnPNw9B7"
      },
      "id": "42g0WnPNw9B7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_small = Corpus(filename=download(\"reddit-corpus-small\"))"
      ],
      "metadata": {
        "id": "klQWuXgCxLvi"
      },
      "id": "klQWuXgCxLvi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 'process_corpus()'\n",
        "SAVE_PATH = \"/workspace/temporal_belief_analysis/pd_corpus_with_stances\"\n",
        "topic_detector = TopicDetector()\n",
        "topic_detector.process_corpus(corpus, save_path=SAVE_PATH)"
      ],
      "metadata": {
        "id": "bzHInQn-xMR2"
      },
      "id": "bzHInQn-xMR2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 'detect_conversation_topic()' and 'dump()'\n",
        "i = 0\n",
        "convos_small = list(corpus_small.iter_conversations())\n",
        "topic_detector = TopicDetector()\n",
        "for i in range(3):\n",
        "  utterances = list(convos_small[i].iter_utterances())\n",
        "  title = convos_small[i].meta['title']\n",
        "  og_post = utterances[0].text\n",
        "  print(100*'-')\n",
        "  print(f\"Title: {title} \\n\")\n",
        "  print(f\"OG post: {og_post} \\n\")\n",
        "  topic = topic_detector.detect_conversation_topic(convos_small[i])\n",
        "  print(f\"Detected topic: {topic['topic']} \\n\")\n",
        "  print(f\"Confidence: {topic['confidence']} \\n\")\n",
        "  convos_small[i].add_meta(\"detected_topic\", topic[\"topic\"])\n",
        "  convos_small[i].add_meta(\"topic_confidence\", topic[\"confidence\"])\n",
        "  convos_small[i].add_meta(\"topic_scores\", topic[\"all_scores\"])\n",
        "  i += 1\n",
        "\n",
        "corpus_small.dump(\"/content/drive/MyDrive/MScProject/Corpora/corpus_small\")\n"
      ],
      "metadata": {
        "id": "L1YIji5gxjdv"
      },
      "id": "L1YIji5gxjdv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if metadata gets added\n",
        "conversations = list(corpus.iter_conversations())\n",
        "\n",
        "# Check first conversation\n",
        "first_conv = conversations[1]\n",
        "print(f\"First conversation ID: {first_conv.id}\")\n",
        "print(f\"Has topic metadata: {'detected_topic' in first_conv.meta}\")\n",
        "if 'detected_topic' in first_conv.meta:\n",
        "    print(f\"Topic: {first_conv.meta['detected_topic']}\")\n",
        "    print(f\"Confidence: {first_conv.meta['topic_confidence']}\")"
      ],
      "metadata": {
        "id": "UnclCYp6xrX-"
      },
      "id": "UnclCYp6xrX-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}