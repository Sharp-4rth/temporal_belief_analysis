{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8sjSohXnld3",
    "outputId": "9f1aa5e7-dfc3-4da5-fcf9-e66916f2c622"
   },
   "id": "F8sjSohXnld3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f31f60c33c386f57",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fae50bdd-3bb9-4485-ce95-d16c822bbae0"
   },
   "cell_type": "code",
   "source": [
    "# Need to restart after:\n",
    "!pip install convokit[llm]\n",
    "!pip install convokit"
   ],
   "id": "f31f60c33c386f57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "524995afbe8f262c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4c56d880-5685-409d-af52-727fe228804f"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
     ]
    }
   ],
   "execution_count": 1,
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
    "print(\"Changed working directory to:\", os.getcwd())\n",
    "\n",
    "# Absolute path to src directory\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ],
   "id": "524995afbe8f262c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add this code BEFORE your main processing loop to count change points\n",
    "print(\"\\n=== CHANGE POINT ANALYSIS ===\")\n",
    "\n",
    "for group_idx, group in enumerate(groups_tuple):\n",
    "    print(f\"\\n📊 Group {group_idx + 1}:\")\n",
    "    print(f\"   Total users: {len(group)}\")\n",
    "\n",
    "    group_total_change_points = 0\n",
    "    user_change_points = []\n",
    "\n",
    "    for user_id, topic_timelines in group.items():\n",
    "        user_total = 0\n",
    "\n",
    "        for topic_name, topic_timeline in topic_timelines.items():\n",
    "            topic_change_points = len(topic_timeline.keys())\n",
    "            user_total += topic_change_points\n",
    "\n",
    "        user_change_points.append((user_id, user_total))\n",
    "        group_total_change_points += user_total\n",
    "\n",
    "    print(f\"   Total change points: {group_total_change_points}\")\n",
    "    print(f\"   Average per user: {group_total_change_points / len(group):.1f}\")\n",
    "\n",
    "    # Show the first few users (the ones that will actually be processed)\n",
    "    print(f\"   First 2 users (these will be processed):\")\n",
    "    for i, (user_id, count) in enumerate(user_change_points[:2]):\n",
    "        print(f\"     User {user_id}: {count} change points\")\n",
    "\n",
    "    # Show distribution\n",
    "    user_counts = [count for _, count in user_change_points]\n",
    "    if user_counts:\n",
    "        print(f\"   Min change points per user: {min(user_counts)}\")\n",
    "        print(f\"   Max change points per user: {max(user_counts)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ],
   "id": "31cc5938626b8d90"
  },
  {
   "metadata": {
    "id": "719bb8c1568bba9a",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "af024530-b7c7-4d18-badf-d0169e7cf088"
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "!pip install gdown\n",
    "import zipfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from convokit import Corpus, download\n",
    "import convokit\n",
    "from temporal_belief.core.timeline_building import TimelineBuilder\n",
    "from temporal_belief.core.persistence_change_detection import ChangeDetector\n",
    "from temporal_belief.core.window_extraction import WindowExtractor\n",
    "from temporal_belief.core.op_path_pairing import OpPathPairer\n",
    "from temporal_belief.data.preprocessors import ChangeDetectorPreprocessor\n",
    "from temporal_belief.data.preprocessors import PairPreprocessor\n",
    "from temporal_belief.data.preprocessors import ExtractFeatures\n",
    "from temporal_belief.data.preprocessors import GroupPreprocessor\n",
    "from temporal_belief.core.interplay import Interplay\n",
    "import numpy as np\n",
    "nltk.download('stopwords')"
   ],
   "id": "719bb8c1568bba9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32cc484b68d1ecdc",
    "outputId": "36deb9a9-ca1d-4dd6-afa9-7dac52186ee4"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1AIrstrzE259fcVyxJQW4-RwvAkoUyK1x\n",
      "From (redirected): https://drive.google.com/uc?id=1AIrstrzE259fcVyxJQW4-RwvAkoUyK1x&confirm=t&uuid=cf2419fc-0025-4155-93ac-cba05fe956d3\n",
      "To: /content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\n",
      "100% 1.07G/1.07G [00:11<00:00, 93.0MB/s]\n"
     ]
    }
   ],
   "execution_count": 3,
   "source": [
    "# Download and unzip with python (Dataloading):\n",
    "# !gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/1DLFY6JLMZqNjwvNRZmhlV4-rnoQP_eyH/view?usp=sharing\" -O \"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/1nWaj5N8nsG7u5homv_kAh4CLPDv01M_Z/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\" --fuzzy\n",
    "!gdown \"https://drive.google.com/file/d/1AIrstrzE259fcVyxJQW4-RwvAkoUyK1x/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\" --fuzzy\n",
    "\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\").extractall(\"/content/temporal_belief_analysis\")"
   ],
   "id": "32cc484b68d1ecdc"
  },
  {
   "cell_type": "code",
   "source": [
    "CORPUS_PATH = \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned\""
   ],
   "metadata": {
    "id": "Q98fql-ioDgx"
   },
   "id": "Q98fql-ioDgx",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "id": "f771600a48d1cc04",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8d7f930f-a350-4df6-a164-77d8e4239296"
   },
   "cell_type": "code",
   "source": [
    "corpus = Corpus(filename=CORPUS_PATH)"
   ],
   "id": "f771600a48d1cc04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "683adccaa471a6a1"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 11,
   "source": [
    "timeline_builder = TimelineBuilder(corpus)\n",
    "timelines = timeline_builder.build_timelines()\n",
    "change_detector = ChangeDetector()\n",
    "window_extractor = WindowExtractor(corpus, timelines)\n",
    "window_extractor.build_global_user_conversations_index()\n",
    "groups_preprocessor = GroupPreprocessor()\n",
    "op_path_pairer = OpPathPairer(corpus, timelines)\n",
    "pair_preprocessor = PairPreprocessor()\n",
    "feature_extractor = ExtractFeatures()\n",
    "persuasion_analyzer = Interplay()"
   ],
   "id": "95fdf3ac90e87037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "groups = change_detector.get_two_groups(timelines)\n",
    "groups_tuple = (groups['with_changes'], groups['no_changes'])\n",
    "groups = groups_preprocessor.filter_groups(groups, groups_tuple)"
   ],
   "id": "f99538a9f1bb861"
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "668ebf37f0d3de52",
    "outputId": "99f9f01f-6561-47f3-8adf-41fd053f5e90"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rProcessing groups:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.013s\n",
      "⏱️ Preprocessing: 0.000s\n",
      "⏱️ Feature extraction (enhanced): 0.003s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.016s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.047s\n",
      "⏱️ Preprocessing: 0.000s\n",
      "⏱️ Feature extraction (enhanced): 0.008s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.056s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.011s\n",
      "⏱️ Preprocessing: 0.000s\n",
      "⏱️ Feature extraction (enhanced): 0.003s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.014s\n",
      "\n",
      "👤 USER seltaeb4 TOTAL: 0.087s (3 change points)\n",
      "📊 Average per change point: 0.029s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.032s\n",
      "⏱️ Preprocessing: 0.002s\n",
      "⏱️ Feature extraction (enhanced): 0.110s\n",
      "⏱️ Scoring: 0.001s\n",
      "🔥 TOTAL for change point: 0.145s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.168s\n",
      "⏱️ Preprocessing: 0.012s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rProcessing groups:  50%|█████     | 1/2 [00:00<00:00,  1.02it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "⏱️ Feature extraction (enhanced): 0.377s\n",
      "⏱️ Scoring: 0.001s\n",
      "🔥 TOTAL for change point: 0.558s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.011s\n",
      "⏱️ Preprocessing: 0.001s\n",
      "⏱️ Feature extraction (enhanced): 0.025s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.038s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.042s\n",
      "⏱️ Preprocessing: 0.001s\n",
      "⏱️ Feature extraction (enhanced): 0.021s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.064s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "Skipping conversation 1jcj4v: Conversation failed integrity check. It is either missing an utterance in the reply-to chain and/or has multiple root nodes. Run check_integrity() to diagnose issues.\n",
      "⏱️ Path extraction: 0.026s\n",
      "⏱️ Preprocessing: 0.001s\n",
      "⏱️ Feature extraction (enhanced): 0.020s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.046s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.029s\n",
      "⏱️ Preprocessing: 0.000s\n",
      "⏱️ Feature extraction (enhanced): 0.014s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.043s\n",
      "\n",
      "👤 USER HardCoreModerate TOTAL: 0.895s (6 change points)\n",
      "📊 Average per change point: 0.149s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.000s\n",
      "⏱️ Preprocessing: 0.000s\n",
      "⏱️ Feature extraction (enhanced): 0.002s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.002s\n",
      "\n",
      "👤 USER VegemiteDesu TOTAL: 0.002s (1 change points)\n",
      "📊 Average per change point: 0.002s\n",
      "\n",
      "⏱️ Window extraction: 0.000s\n",
      "⏱️ Path extraction: 0.001s\n",
      "⏱️ Preprocessing: 0.000s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rProcessing groups: 100%|██████████| 2/2 [00:01<00:00,  1.90it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "⏱️ Feature extraction (enhanced): 0.024s\n",
      "⏱️ Scoring: 0.000s\n",
      "🔥 TOTAL for change point: 0.026s\n",
      "\n",
      "👤 USER amade183 TOTAL: 0.026s (1 change points)\n",
      "📊 Average per change point: 0.026s\n",
      "\n",
      "\n",
      "=== GROUP COMPARISON ===\n",
      "\n",
      "Group 1 Means:\n",
      "  interplay: 0.8327\n",
      "  politeness: 2.7514\n",
      "  argument_complexity: 0.8918\n",
      "  evidence_markers: 0.9904\n",
      "  hedging: 0.0044\n",
      "\n",
      "Group 2 Means:\n",
      "  interplay: 0.7555\n",
      "  politeness: 0.6286\n",
      "  argument_complexity: 1.0112\n",
      "  evidence_markers: 0.4095\n",
      "  hedging: 0.0037\n",
      "\n",
      "=== GROUP 1 vs GROUP 2 COMPARISON ===\n",
      "interplay:\n",
      "  Group 1: 0.8327\n",
      "  Group 2: 0.7555\n",
      "  Difference: 0.0772 (+10.2%)\n",
      "\n",
      "politeness:\n",
      "  Group 1: 2.7514\n",
      "  Group 2: 0.6286\n",
      "  Difference: 2.1229 (+337.7%)\n",
      "\n",
      "argument_complexity:\n",
      "  Group 1: 0.8918\n",
      "  Group 2: 1.0112\n",
      "  Difference: -0.1194 (-11.8%)\n",
      "\n",
      "evidence_markers:\n",
      "  Group 1: 0.9904\n",
      "  Group 2: 0.4095\n",
      "  Difference: 0.5809 (+141.9%)\n",
      "\n",
      "hedging:\n",
      "  Group 1: 0.0044\n",
      "  Group 2: 0.0037\n",
      "  Difference: 0.0007 (+18.5%)\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 52,
   "source": [
    "from tqdm import tqdm\n",
    "from convokit import PolitenessStrategies\n",
    "import re\n",
    "\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "# Convos has been set to test\n",
    "# Init\n",
    "i = 0\n",
    "group_means = [] # Initialize as a list to append means\n",
    "group_scores = []\n",
    "utts_num = 0\n",
    "\n",
    "# For each group\n",
    "for group_idx, group in enumerate(tqdm(groups_tuple, desc=\"Processing groups\")):\n",
    "    # Initialize dictionary for this group's scores\n",
    "    current_group_scores = {\n",
    "        'interplay': [],\n",
    "        'politeness': [],\n",
    "        'argument_complexity': [],\n",
    "        'evidence_markers': [],\n",
    "        'hedging': []\n",
    "    }\n",
    "\n",
    "    count = 0\n",
    "    for user_id, topic_timelines in group.items():\n",
    "        # Process only 2 users for debugging\n",
    "        if count < 2:\n",
    "\n",
    "            user_start_time = time.time()\n",
    "            user_change_points = 0\n",
    "\n",
    "            for topic_timeline in topic_timelines.values():\n",
    "\n",
    "                for change_point in topic_timeline.keys():  # Iterate through change points (keys)\n",
    "                    utts_num += 1\n",
    "\n",
    "                    user_change_points += 1\n",
    "\n",
    "                    # TIME: Window extraction\n",
    "                    start_time = time.time()\n",
    "                    try:\n",
    "                        candidate_convos = window_extractor.get_conversations_around_change_point(\n",
    "                            change_point=change_point, corpus=corpus, test=True\n",
    "                        )\n",
    "                        window_time = time.time() - start_time\n",
    "                        # print(f'⏱️ Window extraction: {window_time:.3f}s')\n",
    "                    except ValueError as e:\n",
    "                        # print(f\"Skipping change point {change_point}: {e}\")\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    # TIME: Path extraction\n",
    "                    start_time = time.time()\n",
    "                    timeout_duration = 0.25  # 0.25 seconds\n",
    "                    op_path_pairs = []\n",
    "\n",
    "                    for candidate_convo in candidate_convos:\n",
    "                        # Check if we've exceeded the timeout\n",
    "                        if time.time() - start_time > timeout_duration:\n",
    "                            # print(f\"⏰ Path extraction timeout reached ({timeout_duration}s)\")\n",
    "                            break\n",
    "\n",
    "                        try:\n",
    "                            op_path_pairs.extend(op_path_pairer.extract_rooted_path_from_candidate_convos(\n",
    "                                [candidate_convo], user_id\n",
    "                            ))\n",
    "                        except ValueError as e:\n",
    "                            # print(f\"Skipping conversation {candidate_convo.id}: {e}\")\n",
    "                            continue\n",
    "\n",
    "                    path_time = time.time() - start_time\n",
    "                    # print(f'⏱️ Path extraction: {path_time:.3f}s')\n",
    "\n",
    "\n",
    "                    # TIME: Preprocessing\n",
    "                    start_time = time.time()\n",
    "                    preprocessed_pairs = pair_preprocessor.concatenate_path_in_all_pairs(op_path_pairs)\n",
    "                    preprocess_time = time.time() - start_time\n",
    "                    # print(f'⏱️ Preprocessing: {preprocess_time:.3f}s')\n",
    "\n",
    "\n",
    "                    # TIME: Feature extraction (ENHANCED)\n",
    "                    start_time = time.time()\n",
    "                    interplay_features_list = []\n",
    "                    politeness_features_list = []\n",
    "                    # NEW: Feature lists for new predictors\n",
    "                    argument_complexity_features_list = []\n",
    "                    evidence_features_list = []\n",
    "                    hedging_features_list = []\n",
    "\n",
    "                    for op, paths in preprocessed_pairs:\n",
    "                        for k, concatenated_utts in paths.items():\n",
    "                            # Existing feature extraction\n",
    "                            interplay_features = persuasion_analyzer.calculate_interplay_features(\n",
    "                                op.text, concatenated_utts, stop_words_set\n",
    "                            )\n",
    "                            interplay_features_list.append(interplay_features)\n",
    "\n",
    "                            # Fixed politeness feature extraction\n",
    "                            politeness_features = feature_extractor.get_politeness_features(concatenated_utts)\n",
    "                            politeness_features_list.append(politeness_features)\n",
    "\n",
    "                            # NEW: Extract features (not scores) for new predictors\n",
    "                            complexity_features = feature_extractor.extract_argument_complexity_features(concatenated_utts)\n",
    "                            argument_complexity_features_list.append(complexity_features)\n",
    "\n",
    "                            evidence_features = feature_extractor.extract_evidence_features(concatenated_utts)\n",
    "                            evidence_features_list.append(evidence_features)\n",
    "\n",
    "                            hedging_features = feature_extractor.extract_hedging_features(concatenated_utts)\n",
    "                            hedging_features_list.append(hedging_features)\n",
    "\n",
    "                    feature_time = time.time() - start_time\n",
    "                    # print(f'⏱️ Feature extraction (enhanced): {feature_time:.3f}s')\n",
    "\n",
    "                    # TIME: Score interplay (existing)\n",
    "                    start_time = time.time()\n",
    "                    interplay_scores = []\n",
    "                    for interplay_features in interplay_features_list:\n",
    "                        score = persuasion_analyzer.calculate_persuasion_score(interplay_features)\n",
    "                        interplay_scores.append(score)\n",
    "\n",
    "                    # Score politeness features (existing)\n",
    "                    politeness_scores = []\n",
    "                    for politeness_features in politeness_features_list:\n",
    "                        politeness_total = sum(politeness_features.values())\n",
    "                        politeness_scores.append(politeness_total)\n",
    "\n",
    "                    # NEW: Score the new predictors\n",
    "                    argument_complexity_scores = []\n",
    "                    for complexity_features in argument_complexity_features_list:\n",
    "                        score = feature_extractor.calculate_complexity_score(complexity_features)\n",
    "                        argument_complexity_scores.append(score)\n",
    "\n",
    "                    evidence_scores = []\n",
    "                    for evidence_features in evidence_features_list:\n",
    "                        score = feature_extractor.calculate_evidence_score(evidence_features)\n",
    "                        evidence_scores.append(score)\n",
    "\n",
    "                    hedging_scores = []\n",
    "                    for hedging_features in hedging_features_list:\n",
    "                        score = feature_extractor.calculate_hedging_score_from_features(hedging_features)\n",
    "                        hedging_scores.append(score)\n",
    "\n",
    "                    scoring_time = time.time() - start_time\n",
    "                    # print(f'⏱️ Scoring: {scoring_time:.3f}s')\n",
    "\n",
    "                    # Add all scores to current group (NEW STRUCTURE)\n",
    "                    current_group_scores['interplay'].extend(interplay_scores)\n",
    "                    current_group_scores['politeness'].extend(politeness_scores)\n",
    "                    current_group_scores['argument_complexity'].extend(argument_complexity_scores)\n",
    "                    current_group_scores['evidence_markers'].extend(evidence_scores)\n",
    "                    current_group_scores['hedging'].extend(hedging_scores)\n",
    "\n",
    "                    # Print total time for this change point\n",
    "                    total_time = window_time + path_time + preprocess_time + feature_time + scoring_time\n",
    "                    # print(f'🔥 TOTAL for change point: {total_time:.3f}s\\n')\n",
    "\n",
    "            # TIME: End timing this user\n",
    "            user_total_time = time.time() - user_start_time\n",
    "            # print(f'👤 USER {user_id} TOTAL: {user_total_time:.3f}s ({user_change_points} change points)')\n",
    "            # print(f'📊 Average per change point: {user_total_time/max(1, user_change_points):.3f}s\\n')\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if count >= 10:\n",
    "            break\n",
    "\n",
    "    # Calculate means for each predictor for this group (ENHANCED)\n",
    "    group_mean = {}\n",
    "    for predictor_name, scores in current_group_scores.items():\n",
    "        if scores:  # Check if we have scores\n",
    "            group_mean[predictor_name] = sum(scores) / len(scores)\n",
    "        else:\n",
    "            group_mean[predictor_name] = 0\n",
    "\n",
    "    # Append this group's means\n",
    "    group_means.append(group_mean)\n",
    "    group_scores.append(current_group_scores)\n",
    "\n",
    "# Print the calculated group means for each predictor (ENHANCED)\n",
    "print(f'\\n=== GROUP COMPARISON ===')\n",
    "for group_idx, group_mean in enumerate(group_means):\n",
    "    print(f'\\nGroup {group_idx + 1} Means:')\n",
    "    for predictor, mean_score in group_mean.items():\n",
    "        print(f'  {predictor}: {mean_score:.4f}')\n",
    "\n",
    "# Print comparison between groups\n",
    "if len(group_means) >= 2:\n",
    "    print(f'\\n=== GROUP 1 vs GROUP 2 COMPARISON ===')\n",
    "    for predictor in group_means[0].keys():\n",
    "        group1_mean = group_means[0][predictor]\n",
    "        group2_mean = group_means[1][predictor]\n",
    "        difference = group1_mean - group2_mean\n",
    "        percent_diff = (difference / group2_mean * 100) if group2_mean != 0 else 0\n",
    "        print(f'{predictor}:')\n",
    "        print(f'  Group 1: {group1_mean:.4f}')\n",
    "        print(f'  Group 2: {group2_mean:.4f}')\n",
    "        print(f'  Difference: {difference:.4f} ({percent_diff:+.1f}%)')\n",
    "        print()"
   ],
   "id": "668ebf37f0d3de52"
  },
  {
   "cell_type": "code",
   "source": [
    "# ========== NEW: STATISTICAL ANALYSIS SECTION ==========\n",
    "\n",
    "def perform_statistical_tests(group1_scores, group2_scores, predictor_name, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform comprehensive statistical tests between two groups for a given predictor.\n",
    "\n",
    "    Args:\n",
    "        group1_scores: List of scores for group 1\n",
    "        group2_scores: List of scores for group 2\n",
    "        predictor_name: Name of the predictor being tested\n",
    "        alpha: Significance level (default 0.05)\n",
    "\n",
    "    Returns:\n",
    "        dict: Results of all statistical tests\n",
    "    \"\"\"\n",
    "    if not group1_scores or not group2_scores:\n",
    "        return {\n",
    "            'valid': False,\n",
    "            'reason': 'Empty score lists'\n",
    "        }\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    g1 = np.array(group1_scores)\n",
    "    g2 = np.array(group2_scores)\n",
    "\n",
    "    # Basic descriptive statistics\n",
    "    results = {\n",
    "        'valid': True,\n",
    "        'predictor': predictor_name,\n",
    "        'group1_n': len(g1),\n",
    "        'group2_n': len(g2),\n",
    "        'group1_mean': np.mean(g1),\n",
    "        'group2_mean': np.mean(g2),\n",
    "        'group1_std': np.std(g1, ddof=1),\n",
    "        'group2_std': np.std(g2, ddof=1),\n",
    "        'group1_median': np.median(g1),\n",
    "        'group2_median': np.median(g2),\n",
    "        'mean_difference': np.mean(g1) - np.mean(g2),\n",
    "    }\n",
    "\n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt(((len(g1) - 1) * results['group1_std']**2 +\n",
    "                         (len(g2) - 1) * results['group2_std']**2) /\n",
    "                        (len(g1) + len(g2) - 2))\n",
    "    results['cohens_d'] = results['mean_difference'] / pooled_std if pooled_std > 0 else 0\n",
    "\n",
    "    # Interpret effect size\n",
    "    abs_d = abs(results['cohens_d'])\n",
    "    if abs_d < 0.2:\n",
    "        effect_size_interpretation = \"negligible\"\n",
    "    elif abs_d < 0.5:\n",
    "        effect_size_interpretation = \"small\"\n",
    "    elif abs_d < 0.8:\n",
    "        effect_size_interpretation = \"medium\"\n",
    "    else:\n",
    "        effect_size_interpretation = \"large\"\n",
    "    results['effect_size_interpretation'] = effect_size_interpretation\n",
    "\n",
    "    # Test for equal variances (Levene's test)\n",
    "    try:\n",
    "        levene_stat, levene_p = levene(g1, g2)\n",
    "        results['levene_statistic'] = levene_stat\n",
    "        results['levene_p_value'] = levene_p\n",
    "        results['equal_variances'] = levene_p > alpha\n",
    "    except Exception as e:\n",
    "        results['levene_error'] = str(e)\n",
    "        results['equal_variances'] = True  # Assume equal variances if test fails\n",
    "\n",
    "    # Independent samples t-test\n",
    "    try:\n",
    "        # Use equal_var parameter based on Levene's test\n",
    "        equal_var = results.get('equal_variances', True)\n",
    "        t_stat, t_p = ttest_ind(g1, g2, equal_var=equal_var)\n",
    "        results['t_statistic'] = t_stat\n",
    "        results['t_p_value'] = t_p\n",
    "        results['t_significant'] = t_p < alpha\n",
    "\n",
    "        # Calculate degrees of freedom\n",
    "        if equal_var:\n",
    "            results['t_df'] = len(g1) + len(g2) - 2\n",
    "        else:\n",
    "            # Welch's t-test degrees of freedom\n",
    "            s1_sq, s2_sq = results['group1_std']**2, results['group2_std']**2\n",
    "            n1, n2 = len(g1), len(g2)\n",
    "            results['t_df'] = ((s1_sq/n1 + s2_sq/n2)**2) / ((s1_sq/n1)**2/(n1-1) + (s2_sq/n2)**2/(n2-1))\n",
    "\n",
    "    except Exception as e:\n",
    "        results['t_test_error'] = str(e)\n",
    "\n",
    "    # Mann-Whitney U test (non-parametric alternative)\n",
    "    try:\n",
    "        u_stat, u_p = mannwhitneyu(g1, g2, alternative='two-sided')\n",
    "        results['mannwhitney_u_statistic'] = u_stat\n",
    "        results['mannwhitney_p_value'] = u_p\n",
    "        results['mannwhitney_significant'] = u_p < alpha\n",
    "    except Exception as e:\n",
    "        results['mannwhitney_error'] = str(e)\n",
    "\n",
    "    # 95% Confidence interval for the difference in means\n",
    "    try:\n",
    "        # Pooled standard error\n",
    "        n1, n2 = len(g1), len(g2)\n",
    "        pooled_se = pooled_std * np.sqrt(1/n1 + 1/n2)\n",
    "\n",
    "        # Critical t-value\n",
    "        df = results.get('t_df', n1 + n2 - 2)\n",
    "        t_critical = stats.t.ppf(1 - alpha/2, df)\n",
    "\n",
    "        # Confidence interval\n",
    "        margin_of_error = t_critical * pooled_se\n",
    "        results['ci_lower'] = results['mean_difference'] - margin_of_error\n",
    "        results['ci_upper'] = results['mean_difference'] + margin_of_error\n",
    "    except Exception as e:\n",
    "        results['ci_error'] = str(e)\n",
    "\n",
    "    return results\n",
    "\n",
    "def format_statistical_results(results):\n",
    "    \"\"\"Format statistical results for readable output.\"\"\"\n",
    "    if not results['valid']:\n",
    "        return f\"❌ {results['predictor']}: {results['reason']}\"\n",
    "\n",
    "    output = f\"\\n📊 {results['predictor'].upper().replace('_', ' ')} ANALYSIS:\\n\"\n",
    "    output += f\"{'='*50}\\n\"\n",
    "\n",
    "    # Descriptive statistics\n",
    "    output += f\"Sample sizes: Group 1: n={results['group1_n']}, Group 2: n={results['group2_n']}\\n\"\n",
    "    output += f\"Group 1: M={results['group1_mean']:.4f} (SD={results['group1_std']:.4f}), Mdn={results['group1_median']:.4f}\\n\"\n",
    "    output += f\"Group 2: M={results['group2_mean']:.4f} (SD={results['group2_std']:.4f}), Mdn={results['group2_median']:.4f}\\n\"\n",
    "    output += f\"Mean difference: {results['mean_difference']:.4f}\\n\"\n",
    "\n",
    "    # Effect size\n",
    "    output += f\"Effect size (Cohen's d): {results['cohens_d']:.4f} ({results['effect_size_interpretation']})\\n\"\n",
    "\n",
    "    # Variance equality test\n",
    "    if 'levene_p_value' in results:\n",
    "        equal_var_str = \"✅ Equal\" if results['equal_variances'] else \"❌ Unequal\"\n",
    "        output += f\"Levene's test: F={results['levene_statistic']:.4f}, p={results['levene_p_value']:.4f} ({equal_var_str} variances)\\n\"\n",
    "\n",
    "    # t-test results\n",
    "    if 't_p_value' in results:\n",
    "        significance = \"✅ SIGNIFICANT\" if results['t_significant'] else \"❌ Not significant\"\n",
    "        test_type = \"Welch's t-test\" if not results.get('equal_variances', True) else \"Student's t-test\"\n",
    "        output += f\"{test_type}: t({results['t_df']:.1f})={results['t_statistic']:.4f}, p={results['t_p_value']:.4f} {significance}\\n\"\n",
    "\n",
    "    # Mann-Whitney U test\n",
    "    if 'mannwhitney_p_value' in results:\n",
    "        significance = \"✅ SIGNIFICANT\" if results['mannwhitney_significant'] else \"❌ Not significant\"\n",
    "        output += f\"Mann-Whitney U: U={results['mannwhitney_u_statistic']:.1f}, p={results['mannwhitney_p_value']:.4f} {significance}\\n\"\n",
    "\n",
    "    # Confidence interval\n",
    "    if 'ci_lower' in results:\n",
    "        output += f\"95% CI for difference: [{results['ci_lower']:.4f}, {results['ci_upper']:.4f}]\\n\"\n",
    "\n",
    "    return output\n",
    "\n",
    "# Print the calculated group means for each predictor (ENHANCED)\n",
    "print(f'\\n=== GROUP COMPARISON ===')\n",
    "for group_idx, group_mean in enumerate(group_means):\n",
    "    print(f'\\nGroup {group_idx + 1} Means:')\n",
    "    for predictor, mean_score in group_mean.items():\n",
    "        print(f'  {predictor}: {mean_score:.4f}')\n",
    "\n",
    "# Print comparison between groups\n",
    "if len(group_means) >= 2:\n",
    "    print(f'\\n=== GROUP 1 vs GROUP 2 COMPARISON ===')\n",
    "    for predictor in group_means[0].keys():\n",
    "        group1_mean = group_means[0][predictor]\n",
    "        group2_mean = group_means[1][predictor]\n",
    "        difference = group1_mean - group2_mean\n",
    "        percent_diff = (difference / group2_mean * 100) if group2_mean != 0 else 0\n",
    "        print(f'{predictor}:')\n",
    "        print(f'  Group 1: {group1_mean:.4f}')\n",
    "        print(f'  Group 2: {group2_mean:.4f}')\n",
    "        print(f'  Difference: {difference:.4f} ({percent_diff:+.1f}%)')\n",
    "        print()\n",
    "\n",
    "# ========== NEW: COMPREHENSIVE STATISTICAL ANALYSIS ==========\n",
    "\n",
    "if len(group_scores) >= 2:\n",
    "    print(f'\\n🔬 STATISTICAL SIGNIFICANCE TESTING')\n",
    "    print(f'=' * 60)\n",
    "\n",
    "    # Store all test results for summary\n",
    "    all_test_results = []\n",
    "    significant_predictors = []\n",
    "\n",
    "    # Test each predictor\n",
    "    for predictor in group_scores[0].keys():\n",
    "        group1_scores = group_scores[0][predictor]\n",
    "        group2_scores = group_scores[1][predictor]\n",
    "\n",
    "        # Perform statistical tests\n",
    "        test_results = perform_statistical_tests(group1_scores, group2_scores, predictor)\n",
    "        all_test_results.append(test_results)\n",
    "\n",
    "        # Print formatted results\n",
    "        print(format_statistical_results(test_results))\n",
    "\n",
    "        # Track significant predictors\n",
    "        if test_results.get('t_significant', False):\n",
    "            significant_predictors.append(predictor)\n",
    "\n",
    "    # Multiple comparison correction (Bonferroni)\n",
    "    print(f'\\n🎯 MULTIPLE COMPARISON CORRECTION')\n",
    "    print(f'=' * 40)\n",
    "    n_tests = len([r for r in all_test_results if r['valid']])\n",
    "    bonferroni_alpha = 0.05 / n_tests if n_tests > 0 else 0.05\n",
    "    print(f\"Number of tests: {n_tests}\")\n",
    "    print(f\"Bonferroni-corrected α: {bonferroni_alpha:.4f}\")\n",
    "\n",
    "    bonferroni_significant = []\n",
    "    for result in all_test_results:\n",
    "        if result['valid'] and 't_p_value' in result:\n",
    "            is_significant = result['t_p_value'] < bonferroni_alpha\n",
    "            status = \"✅ SIGNIFICANT\" if is_significant else \"❌ Not significant\"\n",
    "            print(f\"{result['predictor']}: p={result['t_p_value']:.4f} {status}\")\n",
    "            if is_significant:\n",
    "                bonferroni_significant.append(result['predictor'])\n",
    "\n",
    "    # Summary of findings\n",
    "    print(f'\\n📋 SUMMARY OF FINDINGS')\n",
    "    print(f'=' * 30)\n",
    "    print(f\"Total predictors tested: {n_tests}\")\n",
    "    print(f\"Significant at α=0.05: {len(significant_predictors)} ({len(significant_predictors)/n_tests*100:.1f}%)\")\n",
    "    print(f\"Significant after Bonferroni correction: {len(bonferroni_significant)} ({len(bonferroni_significant)/n_tests*100:.1f}%)\")\n",
    "\n",
    "    if significant_predictors:\n",
    "        print(f\"\\nSignificant predictors (uncorrected): {', '.join(significant_predictors)}\")\n",
    "    if bonferroni_significant:\n",
    "        print(f\"Significant predictors (Bonferroni): {', '.join(bonferroni_significant)}\")\n",
    "\n",
    "    # Effect size summary\n",
    "    print(f'\\n📏 EFFECT SIZES SUMMARY')\n",
    "    print(f'=' * 25)\n",
    "    for result in all_test_results:\n",
    "        if result['valid']:\n",
    "            direction = \"Group 1 > Group 2\" if result['mean_difference'] > 0 else \"Group 2 > Group 1\"\n",
    "            print(f\"{result['predictor']}: d={result['cohens_d']:.3f} ({result['effect_size_interpretation']}, {direction})\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n⚠️  Need at least 2 groups for statistical comparison\")\n",
    "\n",
    "print(f'\\n🏁 Analysis completed. Total utterances processed: {utts_num}')"
   ],
   "metadata": {
    "id": "-01zn5RzLYD1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "7332b6af-ade9-4bc4-dc05-aa9c583c805c"
   },
   "id": "-01zn5RzLYD1",
   "execution_count": 35,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "=== GROUP COMPARISON ===\n",
      "\n",
      "Group 1 Means:\n",
      "  interplay: 0.8327\n",
      "  politeness: 0.7008\n",
      "  argument_complexity: 0.8918\n",
      "  evidence_markers: 0.9904\n",
      "  hedging: 0.0044\n",
      "\n",
      "Group 2 Means:\n",
      "  interplay: 0.7555\n",
      "  politeness: 0.4190\n",
      "  argument_complexity: 1.0112\n",
      "  evidence_markers: 0.4095\n",
      "  hedging: 0.0037\n",
      "\n",
      "=== GROUP 1 vs GROUP 2 COMPARISON ===\n",
      "interplay:\n",
      "  Group 1: 0.8327\n",
      "  Group 2: 0.7555\n",
      "  Difference: 0.0772 (+10.2%)\n",
      "\n",
      "politeness:\n",
      "  Group 1: 0.7008\n",
      "  Group 2: 0.4190\n",
      "  Difference: 0.2817 (+67.2%)\n",
      "\n",
      "argument_complexity:\n",
      "  Group 1: 0.8918\n",
      "  Group 2: 1.0112\n",
      "  Difference: -0.1194 (-11.8%)\n",
      "\n",
      "evidence_markers:\n",
      "  Group 1: 0.9904\n",
      "  Group 2: 0.4095\n",
      "  Difference: 0.5809 (+141.9%)\n",
      "\n",
      "hedging:\n",
      "  Group 1: 0.0044\n",
      "  Group 2: 0.0037\n",
      "  Difference: 0.0007 (+18.5%)\n",
      "\n",
      "\n",
      "🔬 STATISTICAL SIGNIFICANCE TESTING\n",
      "============================================================\n",
      "\n",
      "📊 INTERPLAY ANALYSIS:\n",
      "==================================================\n",
      "Sample sizes: Group 1: n=1046, Group 2: n=105\n",
      "Group 1: M=0.8327 (SD=0.0828), Mdn=0.8226\n",
      "Group 2: M=0.7555 (SD=0.0779), Mdn=0.7694\n",
      "Mean difference: 0.0772\n",
      "Effect size (Cohen's d): 0.9369 (large)\n",
      "\n",
      "\n",
      "📊 POLITENESS ANALYSIS:\n",
      "==================================================\n",
      "Sample sizes: Group 1: n=1046, Group 2: n=105\n",
      "Group 1: M=0.7008 (SD=0.6410), Mdn=1.0000\n",
      "Group 2: M=0.4190 (SD=0.5509), Mdn=0.0000\n",
      "Mean difference: 0.2817\n",
      "Effect size (Cohen's d): 0.4448 (small)\n",
      "\n",
      "\n",
      "📊 ARGUMENT COMPLEXITY ANALYSIS:\n",
      "==================================================\n",
      "Sample sizes: Group 1: n=1046, Group 2: n=105\n",
      "Group 1: M=0.8918 (SD=0.2127), Mdn=0.9500\n",
      "Group 2: M=1.0112 (SD=0.0994), Mdn=1.0200\n",
      "Mean difference: -0.1194\n",
      "Effect size (Cohen's d): -0.5825 (medium)\n",
      "\n",
      "\n",
      "📊 EVIDENCE MARKERS ANALYSIS:\n",
      "==================================================\n",
      "Sample sizes: Group 1: n=1046, Group 2: n=105\n",
      "Group 1: M=0.9904 (SD=2.2723), Mdn=0.0000\n",
      "Group 2: M=0.4095 (SD=0.8626), Mdn=0.0000\n",
      "Mean difference: 0.5809\n",
      "Effect size (Cohen's d): 0.2662 (small)\n",
      "\n",
      "\n",
      "📊 HEDGING ANALYSIS:\n",
      "==================================================\n",
      "Sample sizes: Group 1: n=1046, Group 2: n=105\n",
      "Group 1: M=0.0044 (SD=0.0130), Mdn=0.0000\n",
      "Group 2: M=0.0037 (SD=0.0076), Mdn=0.0000\n",
      "Mean difference: 0.0007\n",
      "Effect size (Cohen's d): 0.0545 (negligible)\n",
      "\n",
      "\n",
      "🎯 MULTIPLE COMPARISON CORRECTION\n",
      "========================================\n",
      "Number of tests: 5\n",
      "Bonferroni-corrected α: 0.0100\n",
      "\n",
      "📋 SUMMARY OF FINDINGS\n",
      "==============================\n",
      "Total predictors tested: 5\n",
      "Significant at α=0.05: 0 (0.0%)\n",
      "Significant after Bonferroni correction: 0 (0.0%)\n",
      "\n",
      "📏 EFFECT SIZES SUMMARY\n",
      "=========================\n",
      "interplay: d=0.937 (large, Group 1 > Group 2)\n",
      "politeness: d=0.445 (small, Group 1 > Group 2)\n",
      "argument_complexity: d=-0.583 (medium, Group 2 > Group 1)\n",
      "evidence_markers: d=0.266 (small, Group 1 > Group 2)\n",
      "hedging: d=0.055 (negligible, Group 1 > Group 2)\n",
      "\n",
      "🏁 Analysis completed. Total utterances processed: 11\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bIXojYlryRqw"
   },
   "id": "bIXojYlryRqw",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
