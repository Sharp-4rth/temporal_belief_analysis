{
 "cells": [
  {
   "metadata": {
    "id": "219dcf3942026eca"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Clone Repo:\n",
    "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
   ],
   "id": "219dcf3942026eca"
  },
  {
   "metadata": {
    "id": "9d089b2bd0802cd2"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Need to restart after:\n",
    "!pip install convokit[llm]\n",
    "!pip install convokit\n",
    "!pip install statsmodels"
   ],
   "id": "9d089b2bd0802cd2"
  },
  {
   "metadata": {
    "id": "deea2a9147dd3533"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Setup: Change to notebooks directory and add src to Python path for imports\n",
    "import sys\n",
    "import os\n",
    "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
    "print(\"Changed working directory to:\", os.getcwd())\n",
    "# Absolute path to src directory\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ],
   "id": "deea2a9147dd3533"
  },
  {
   "metadata": {
    "id": "1ee224d8a1d7cb3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Imports:\n",
    "import time\n",
    "!pip install gdown\n",
    "import zipfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from convokit import Corpus, download\n",
    "import convokit\n",
    "from temporal_belief.core.timeline_building import TimelineBuilder\n",
    "from temporal_belief.core.CUSUM_change_detection import ChangeDetector\n",
    "from temporal_belief.core.window_extraction import WindowExtractor\n",
    "from temporal_belief.core.op_path_pairing import OpPathPairer\n",
    "from temporal_belief.data.preprocessors import ChangeDetectorPreprocessor\n",
    "from temporal_belief.data.preprocessors import PairPreprocessor\n",
    "from temporal_belief.data.preprocessors import ExtractFeatures\n",
    "from temporal_belief.data.preprocessors import GroupPreprocessor\n",
    "from temporal_belief.core.interplay import Interplay\n",
    "import numpy as np\n",
    "nltk.download('stopwords')"
   ],
   "id": "1ee224d8a1d7cb3"
  },
  {
   "metadata": {
    "id": "38ae4dc293871a66"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download 'r/PoliticalDiscussion' corpus with stance labels to root, unzip with python:\n",
    "!gdown \"https://drive.google.com/file/d/1AIrstrzE259fcVyxJQW4-RwvAkoUyK1x/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\" --fuzzy\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\").extractall(\"/content/temporal_belief_analysis\")"
   ],
   "id": "38ae4dc293871a66"
  },
  {
   "metadata": {
    "id": "8ad006dac3b72784"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load corpus:\n",
    "CORPUS_PATH = \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned\"\n",
    "corpus = Corpus(filename=CORPUS_PATH)"
   ],
   "id": "8ad006dac3b72784"
  },
  {
   "metadata": {
    "id": "4d9eed28676b63e1"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Init:\n",
    "timeline_builder = TimelineBuilder(corpus)\n",
    "timelines = timeline_builder.build_timelines()\n",
    "change_detector = ChangeDetector()\n",
    "window_extractor = WindowExtractor(corpus, timelines)\n",
    "window_extractor.build_global_user_conversations_index()\n",
    "op_path_pairer = OpPathPairer(corpus, timelines)\n",
    "pair_preprocessor = PairPreprocessor()\n",
    "groups_preprocessor = GroupPreprocessor()\n",
    "groups = change_detector.get_two_groups(timelines)\n",
    "feature_extractor = ExtractFeatures()\n",
    "persuasion_analyzer = Interplay()"
   ],
   "id": "4d9eed28676b63e1"
  },
  {
   "metadata": {
    "id": "84c8d6e55d889024"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Create groups:\n",
    "groups_tuple = (groups['with_changes'], groups['no_changes'])\n",
    "groups_tuple = groups_preprocessor.filter_groups(groups, groups_tuple)\n",
    "target_utterances = groups_preprocessor.get_target(groups_tuple)"
   ],
   "id": "84c8d6e55d889024"
  },
  {
   "metadata": {
    "id": "959b433ef3445ae3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run Analysis:\n",
    "from tqdm import tqdm\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "group_means = []\n",
    "group_scores = []\n",
    "\n",
    "# For each group\n",
    "for group_idx, group in enumerate(tqdm(groups_tuple, desc=\"Processing groups\")):\n",
    "    # Initialize dictionary for this group's scores (one score per utterance)\n",
    "    current_group_scores = {\n",
    "        'interplay': [],\n",
    "        'politeness': [],\n",
    "        'argument_complexity': [],\n",
    "        'evidence_markers': [],\n",
    "        'hedging': []\n",
    "    }\n",
    "\n",
    "    utterances_processed = 0\n",
    "    target_reached = False  # Flag to control all nested loops\n",
    "\n",
    "    for user_id, topic_timelines in group.items():\n",
    "        if target_reached:  # Check flag at user level\n",
    "            break\n",
    "\n",
    "        user_start_time = time.time()\n",
    "        user_change_points = 0\n",
    "\n",
    "        for topic_timeline in topic_timelines.values():\n",
    "            if target_reached:  # Check flag at topic level\n",
    "                break\n",
    "\n",
    "            for change_point in topic_timeline.keys():  # Each utterance/change point\n",
    "                if utterances_processed >= target_utterances:\n",
    "                    target_reached = True  # Set flag instead of just breaking\n",
    "                    break\n",
    "\n",
    "                # utts_num += 1\n",
    "                user_change_points += 1\n",
    "                utterances_processed += 1\n",
    "\n",
    "                # Window extraction\n",
    "                start_time = time.time()\n",
    "                try:\n",
    "                    candidate_convos = window_extractor.get_conversations_around_change_point(\n",
    "                        change_point=change_point, corpus=corpus, test=True\n",
    "                    )\n",
    "                    window_time = time.time() - start_time\n",
    "                    print(f'Window extraction: {window_time:.3f}s')\n",
    "                except ValueError as e:\n",
    "                    print(f\"Skipping change point {change_point}: {e}\")\n",
    "                    continue\n",
    "\n",
    "                # Path extraction\n",
    "                start_time = time.time()\n",
    "                timeout_duration = 0.25\n",
    "                op_path_pairs = []\n",
    "\n",
    "                for candidate_convo in candidate_convos:\n",
    "                    if time.time() - start_time > timeout_duration:\n",
    "                        print(f\"Path extraction timeout reached ({timeout_duration}s)\")\n",
    "                        break\n",
    "\n",
    "                    try:\n",
    "                        op_path_pairs.extend(op_path_pairer.extract_rooted_path_from_candidate_convos(\n",
    "                            [candidate_convo], user_id\n",
    "                        ))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Skipping conversation {candidate_convo.id}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                path_time = time.time() - start_time\n",
    "                print(f'Path extraction: {path_time:.3f}s')\n",
    "\n",
    "                # Preprocessing\n",
    "                start_time = time.time()\n",
    "                preprocessed_pairs = pair_preprocessor.concatenate_path_in_all_pairs(op_path_pairs)\n",
    "                preprocess_time = time.time() - start_time\n",
    "                print(f'Preprocessing: {preprocess_time:.3f}s')\n",
    "\n",
    "                # Feature extraction - collect ALL scores for this utterance\n",
    "                start_time = time.time()\n",
    "                utterance_interplay_scores = []\n",
    "                utterance_politeness_scores = []\n",
    "                utterance_complexity_scores = []\n",
    "                utterance_evidence_scores = []\n",
    "                utterance_hedging_scores = []\n",
    "\n",
    "                for op, paths in preprocessed_pairs:\n",
    "                    for k, concatenated_utts in paths.items():\n",
    "                        # Extract features\n",
    "                        interplay_features = persuasion_analyzer.calculate_interplay_features(\n",
    "                            op.text, concatenated_utts, stop_words_set\n",
    "                        )\n",
    "                        politeness_features = feature_extractor.get_politeness_features(concatenated_utts)\n",
    "                        complexity_features = feature_extractor.extract_argument_complexity_features(concatenated_utts)\n",
    "                        evidence_features = feature_extractor.extract_evidence_features(concatenated_utts)\n",
    "                        hedging_features = feature_extractor.extract_hedging_features(concatenated_utts)\n",
    "\n",
    "                        # Calculate scores\n",
    "                        interplay_score = persuasion_analyzer.calculate_persuasion_score(interplay_features)\n",
    "                        politeness_score = sum(politeness_features.values())\n",
    "                        complexity_score = feature_extractor.calculate_complexity_score(complexity_features)\n",
    "                        evidence_score = feature_extractor.calculate_evidence_score(evidence_features)\n",
    "                        hedging_score = feature_extractor.calculate_hedging_score_from_features(hedging_features)\n",
    "\n",
    "                        # Collect all scores for this utterance\n",
    "                        utterance_interplay_scores.append(interplay_score)\n",
    "                        utterance_politeness_scores.append(politeness_score)\n",
    "                        utterance_complexity_scores.append(complexity_score)\n",
    "                        utterance_evidence_scores.append(evidence_score)\n",
    "                        utterance_hedging_scores.append(hedging_score)\n",
    "\n",
    "                feature_time = time.time() - start_time\n",
    "\n",
    "                # Take mean across all paths for this single utterance\n",
    "                start_time = time.time()\n",
    "                if utterance_interplay_scores:  # Only if we have scores\n",
    "                    # One score per utterance (mean of all conversation paths)\n",
    "                    utterance_mean_interplay = np.mean(utterance_interplay_scores)\n",
    "                    utterance_mean_politeness = np.mean(utterance_politeness_scores)\n",
    "                    utterance_mean_complexity = np.mean(utterance_complexity_scores)\n",
    "                    utterance_mean_evidence = np.mean(utterance_evidence_scores)\n",
    "                    utterance_mean_hedging = np.mean(utterance_hedging_scores)\n",
    "\n",
    "                    # Add ONE score per utterance to group scores\n",
    "                    current_group_scores['interplay'].append(utterance_mean_interplay)\n",
    "                    current_group_scores['politeness'].append(utterance_mean_politeness)\n",
    "                    current_group_scores['argument_complexity'].append(utterance_mean_complexity)\n",
    "                    current_group_scores['evidence_markers'].append(utterance_mean_evidence)\n",
    "                    current_group_scores['hedging'].append(utterance_mean_hedging)\n",
    "\n",
    "                    print(f\"Utterance {change_point}: {len(utterance_interplay_scores)} paths -> 1 mean score\")\n",
    "                    print(f\"Group {group_idx + 1}: {utterances_processed}/{target_utterances} utterances processed\")\n",
    "                else:\n",
    "                    print(f\"Utterance {change_point}: No valid paths found, skipping\")\n",
    "\n",
    "                scoring_time = time.time() - start_time\n",
    "                print(f'Scoring: {scoring_time:.3f}s')\n",
    "\n",
    "                # Print total time for this change point\n",
    "                total_time = window_time + path_time + preprocess_time + feature_time + scoring_time\n",
    "                print(f'TOTAL for utterance: {total_time:.3f}s\\n')\n",
    "\n",
    "        user_total_time = time.time() - user_start_time\n",
    "        if user_change_points > 0:  # Only print if user had utterances\n",
    "            print(f'USER {user_id}: {user_total_time:.3f}s ({user_change_points} utterances)')\n",
    "\n",
    "    # Calculate means for each predictor for this group\n",
    "    group_mean = {}\n",
    "    for predictor_name, scores in current_group_scores.items():\n",
    "        if scores:\n",
    "            group_mean[predictor_name] = np.mean(scores)\n",
    "        else:\n",
    "            group_mean[predictor_name] = 0\n",
    "\n",
    "    print(f\"\\nGroup {group_idx + 1} final sample sizes:\")\n",
    "    for predictor_name, scores in current_group_scores.items():\n",
    "        print(f\"  {predictor_name}: n={len(scores)}\")\n",
    "\n",
    "    print(f\"Group {group_idx + 1}: Processed exactly {utterances_processed} utterances\")\n",
    "\n",
    "    group_means.append(group_mean)\n",
    "    group_scores.append(current_group_scores)"
   ],
   "id": "959b433ef3445ae3"
  },
  {
   "metadata": {
    "id": "635998c2eda7286b"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run statistical comparison:\n",
    "groups_preprocessor.run_statistical_comparison(group_scores)"
   ],
   "id": "635998c2eda7286b"
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
