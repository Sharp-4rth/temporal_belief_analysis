{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLV_TX38QI3l",
        "outputId": "be615a89-f817-4bc0-9a71-c38b28f49d6c"
      },
      "id": "tLV_TX38QI3l",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'temporal_belief_analysis'...\n",
            "remote: Enumerating objects: 492, done.\u001b[K\n",
            "remote: Counting objects: 100% (103/103), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 492 (delta 57), reused 48 (delta 24), pack-reused 389 (from 1)\u001b[K\n",
            "Receiving objects: 100% (492/492), 3.14 MiB | 6.29 MiB/s, done.\n",
            "Resolving deltas: 100% (305/305), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_id",
        "outputId": "c0166fbb-432d-4efc-c5bf-2c0254f83946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit[llm]\n",
            "  Downloading convokit-3.4.1.tar.gz (212 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/212.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (3.10.0)\n",
            "Requirement already satisfied: scipy>1.14 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (1.16.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.0.2)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit[llm])\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: spacy>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (3.8.7)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (3.9.1)\n",
            "Requirement already satisfied: dill>=0.2.9 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (0.3.8)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (1.5.1)\n",
            "Collecting clean-text>=0.6.0 (from convokit[llm])\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit[llm])\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (4.67.1)\n",
            "Collecting pymongo>=4.0 (from convokit[llm])\n",
            "  Downloading pymongo-4.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (6.0.2)\n",
            "Collecting dnspython>=1.16.0 (from convokit[llm])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (8.3.6)\n",
            "Collecting h5py==3.12.1 (from convokit[llm])\n",
            "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numexpr>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.11.0)\n",
            "Requirement already satisfied: ruff>=0.4.8 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (0.12.9)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (1.4.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (4.0.0)\n",
            "Requirement already satisfied: torch>=0.12 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.8.0+cu126)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (1.10.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (0.17.0)\n",
            "Collecting bitsandbytes (from convokit[llm])\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (4.55.2)\n",
            "Collecting unsloth (from convokit[llm])\n",
            "  Downloading unsloth-2025.8.9-py3-none-any.whl.metadata (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl>=0.12.2 (from convokit[llm])\n",
            "  Downloading trl-0.21.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.19.0)\n",
            "Requirement already satisfied: tf-keras<3.0.0,>=2.17.0 in /usr/local/lib/python3.12/dist-packages (from convokit[llm]) (2.19.0)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit[llm])\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit[llm])\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit[llm]) (2.9.0.post0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from msgpack-numpy>=0.4.3.2->convokit[llm]) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.4->convokit[llm]) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.4->convokit[llm]) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->convokit[llm]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->convokit[llm]) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->convokit[llm]) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit[llm]) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (3.10.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.18.0->convokit[llm]) (0.5.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->convokit[llm]) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->convokit[llm]) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (3.19.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=0.12->convokit[llm]) (3.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate->convokit[llm]) (5.9.5)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate->convokit[llm]) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate->convokit[llm]) (0.6.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->convokit[llm]) (18.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->convokit[llm]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->convokit[llm]) (0.70.16)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers->convokit[llm]) (0.21.4)\n",
            "Collecting unsloth_zoo>=2025.8.8 (from unsloth->convokit[llm])\n",
            "  Downloading unsloth_zoo-2025.8.8-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth->convokit[llm])\n",
            "  Downloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tyro (from unsloth->convokit[llm])\n",
            "  Downloading tyro-0.9.28-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets (from convokit[llm])\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from unsloth->convokit[llm]) (0.2.1)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.12/dist-packages (from unsloth->convokit[llm]) (0.45.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (from unsloth->convokit[llm]) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.12/dist-packages (from unsloth->convokit[llm]) (0.34.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from unsloth->convokit[llm]) (0.23.0+cu126)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (3.12.15)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit[llm]) (0.2.13)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate->convokit[llm]) (1.1.7)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (0.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit[llm]) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit[llm]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit[llm]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit[llm]) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit[llm]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit[llm]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit[llm]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit[llm]) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=0.12->convokit[llm]) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit[llm]) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit[llm]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.18.0->convokit[llm]) (3.1.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit[llm]) (1.5.4)\n",
            "Requirement already satisfied: torchao in /usr/local/lib/python3.12/dist-packages (from unsloth_zoo>=2025.8.8->unsloth->convokit[llm]) (0.10.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.8->unsloth->convokit[llm])\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.8.8->unsloth->convokit[llm])\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit[llm]) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit[llm]) (7.3.0.post1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.12/dist-packages (from diffusers->unsloth->convokit[llm]) (8.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=3.8.2->convokit[llm]) (3.0.2)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth->convokit[llm]) (0.17.0)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth->convokit[llm])\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro->unsloth->convokit[llm]) (4.4.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit[llm]) (1.20.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit[llm]) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (2.19.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata->diffusers->unsloth->convokit[llm]) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->convokit[llm]) (0.1.2)\n",
            "Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading pymongo-4.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.21.0-py3-none-any.whl (511 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.8.9-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.8.8-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.8/184.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.32.post2-cp39-abi3-manylinux_2_28_x86_64.whl (117.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.28-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.4.1-py3-none-any.whl size=255922 sha256=5864d34c62615ce5b9d6452bf6fac0c859206e8315137c75ae95c41f00e1539d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/1b/82/19dc268440f10effa084bf272c07d9d5d3cd4f6db1472b0be6\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=b116b5958d39bb681c786e157810ff1a323a09b3aeee31147072358b5a805d68\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/8c/e0/294d2e4ea0e55792bfc99b6b263e4a0511443da7b69af67688\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: emoji, unidecode, shtab, msgspec, msgpack-numpy, h5py, ftfy, dnspython, pymongo, clean-text, tyro, xformers, datasets, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, convokit, unsloth\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.14.0\n",
            "    Uninstalling h5py-3.14.0:\n",
            "      Successfully uninstalled h5py-3.14.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "Successfully installed bitsandbytes-0.47.0 clean-text-0.6.0 convokit-3.4.1 cut_cross_entropy-25.1.1 datasets-3.6.0 dnspython-2.7.0 emoji-1.7.0 ftfy-6.3.1 h5py-3.12.1 msgpack-numpy-0.4.8 msgspec-0.19.0 pymongo-4.14.1 shtab-1.7.2 trl-0.21.0 tyro-0.9.28 unidecode-1.4.0 unsloth-2025.8.9 unsloth_zoo-2025.8.8 xformers-0.0.32.post2\n",
            "Requirement already satisfied: convokit in /usr/local/lib/python3.12/dist-packages (3.4.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (3.10.0)\n",
            "Requirement already satisfied: scipy>1.14 in /usr/local/lib/python3.12/dist-packages (from convokit) (1.16.1)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (2.2.2)\n",
            "Requirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (2.0.2)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in /usr/local/lib/python3.12/dist-packages (from convokit) (0.4.8)\n",
            "Requirement already satisfied: spacy>=3.8.2 in /usr/local/lib/python3.12/dist-packages (from convokit) (3.8.7)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.12/dist-packages (from convokit) (3.9.1)\n",
            "Requirement already satisfied: dill>=0.2.9 in /usr/local/lib/python3.12/dist-packages (from convokit) (0.3.8)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from convokit) (1.5.1)\n",
            "Requirement already satisfied: clean-text>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (0.6.0)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from convokit) (1.4.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (4.67.1)\n",
            "Requirement already satisfied: pymongo>=4.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (4.14.1)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from convokit) (6.0.2)\n",
            "Requirement already satisfied: dnspython>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (2.7.0)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (8.3.6)\n",
            "Requirement already satisfied: h5py==3.12.1 in /usr/local/lib/python3.12/dist-packages (from convokit) (3.12.1)\n",
            "Requirement already satisfied: numexpr>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from convokit) (2.11.0)\n",
            "Requirement already satisfied: ruff>=0.4.8 in /usr/local/lib/python3.12/dist-packages (from convokit) (0.12.9)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.12/dist-packages (from convokit) (1.4.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from convokit) (3.6.0)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from clean-text>=0.6.0->convokit) (6.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.0.0->convokit) (2.9.0.post0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.12/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.4->convokit) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.4->convokit) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->convokit) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets->convokit) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->convokit) (18.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->convokit) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->convokit) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets->convokit) (0.34.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (3.12.15)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets->convokit) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets->convokit) (1.1.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2025.8.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (7.3.0.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy>=3.8.2->convokit) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->convokit) (1.20.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# Need to restart after:\n",
        "!pip install convokit[llm]\n",
        "!pip install convokit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
        "print(\"Changed working directory to:\", os.getcwd())\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAxzmPSXsoAb",
        "outputId": "954554dd-d016-4025-bf74-8e2a147397ed"
      },
      "id": "dAxzmPSXsoAb",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "!pip install gdown\n",
        "import zipfile\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from convokit import Corpus, download\n",
        "import convokit\n",
        "from temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njypokE6so1k",
        "outputId": "58529209-89a4-4612-d8e5-b6ab82091718"
      },
      "id": "njypokE6so1k",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip with python (Dataloading):\n",
        "# !gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/1DLFY6JLMZqNjwvNRZmhlV4-rnoQP_eyH/view?usp=sharing\" -O \"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/1nWaj5N8nsG7u5homv_kAh4CLPDv01M_Z/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/15NMRXEkGRoGjK6TXFBHIMOPjkTyZ0keP/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances200000_llm.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/15nVf6Js0KsDxA9HaB0zCXhc8VdcC-Fy-/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances75000_llm.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/1dOUvQmtjFrXq0hJvnOsP_ZLqdGEyOVNJ/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_llm.zip\" --fuzzy\n",
        "# !gdown \"https://drive.google.com/file/d/1hU1evfmh0BUAda8llDzBmXfHsMPGdO87/view?usp=sharing\" -O \"/content/temporal_belief_analysis/MT-CSD-main.zip\" --fuzzy\n",
        "!gdown \"https://drive.google.com/file/d/10HNQHIsFe386oBu_o5s9JOuo-wiaofXC/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances150000_llm.zip\" --fuzzy\n",
        "\n",
        "\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances200000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances75000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "# zipfile.ZipFile(\"/content/temporal_belief_analysis/MT-CSD-main.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances150000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/data-all-annotations.zip\").extractall(\"/content/temporal_belief_analysis\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Er6Nh6PysqxG",
        "outputId": "03eb4eab-f4fc-40d5-85ad-b748e429d918"
      },
      "id": "Er6Nh6PysqxG",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=10HNQHIsFe386oBu_o5s9JOuo-wiaofXC\n",
            "From (redirected): https://drive.google.com/uc?id=10HNQHIsFe386oBu_o5s9JOuo-wiaofXC&confirm=t&uuid=6f0da725-0cdc-4ef8-9e05-e508f069e673\n",
            "To: /content/temporal_belief_analysis/pd_corpus_with_stances150000_llm.zip\n",
            "100% 835M/835M [00:13<00:00, 59.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances150000_llm_rerun\")"
      ],
      "metadata": {
        "id": "fQTXbA7Gss7h"
      },
      "id": "fQTXbA7Gss7h",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "VALID_RAW = {\"favor\", \"against\", \"none\"}\n",
        "\n",
        "# if favoring this target => left, else right\n",
        "FAVOR_IMPLIES_LEFT = {\n",
        "    \"Climate Change is a Real Concern\": True,\n",
        "    \"Feminist Movement\": True,\n",
        "    \"Hillary Clinton\": True,\n",
        "    \"Legalization of Abortion\": True,\n",
        "    \"Atheism\": True,\n",
        "}\n",
        "\n",
        "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    cols = {c: c.strip().lower() for c in df.columns}\n",
        "    df = df.rename(columns=cols)\n",
        "    if \"tweet\" in df.columns: df = df.rename(columns={\"tweet\": \"text\"})\n",
        "    if \"opinion towards\" in df.columns: df = df.rename(columns={\"opinion towards\": \"opinion_towards\"})\n",
        "    return df\n",
        "\n",
        "def read_semeval_txt(path):\n",
        "    \"\"\"\n",
        "    Read SemEval .txt with resilient encoding handling.\n",
        "    Tries UTF-8/UTF-8-SIG/CP1252/LATIN-1 and falls back to a\n",
        "    replacement-decoded path so parsing never crashes.\n",
        "    \"\"\"\n",
        "    seps = [\"\\t\", None]  # TSV first, else autodetect\n",
        "    encs = [\"utf-8\", \"utf-8-sig\", \"cp1252\", \"latin-1\"]\n",
        "\n",
        "    last_err = None\n",
        "    for enc in encs:\n",
        "        for sep in seps:\n",
        "            try:\n",
        "                return normalize_cols(\n",
        "                    pd.read_csv(\n",
        "                        path,\n",
        "                        sep=sep,\n",
        "                        encoding=enc,\n",
        "                        engine=\"python\",\n",
        "                        on_bad_lines=\"skip\",   # ignore any malformed rows\n",
        "                        quoting=3              # QUOTE_NONE; treat quotes literally\n",
        "                    )\n",
        "                )\n",
        "            except UnicodeDecodeError as e:\n",
        "                last_err = e\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                # if it wasn't an encoding error, try next sep/enc anyway\n",
        "                last_err = e\n",
        "                continue\n",
        "\n",
        "    # Final fallback: decode with replacement to guarantee progress\n",
        "    with open(path, \"r\", encoding=\"cp1252\", errors=\"replace\") as f:\n",
        "        txt = f.read()\n",
        "    return normalize_cols(\n",
        "        pd.read_csv(\n",
        "            StringIO(txt),\n",
        "            sep=\"\\t\",\n",
        "            engine=\"python\",\n",
        "            on_bad_lines=\"skip\",\n",
        "            quoting=3\n",
        "        )\n",
        "    )\n",
        "\n",
        "CLEAN_BAD = re.compile(r\"^\\s*$|^\\.$\", re.UNICODE)\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    if s.lower() in {\"[deleted]\", \"[removed]\"}:\n",
        "        return \"\"\n",
        "    return re.sub(r\"\\s+\", \" \", s)\n",
        "\n",
        "def normalize_raw_stance(v) -> str | None:\n",
        "    if pd.isna(v): return None\n",
        "    t = str(v).strip().lower()\n",
        "    if t == \"favour\": t = \"favor\"\n",
        "    return t if t in VALID_RAW else None\n",
        "\n",
        "def raw_to_left_right(raw: str | None, target: str | None) -> str | None:\n",
        "    if raw is None: return None\n",
        "    if raw == \"none\": return \"neutral\"\n",
        "    if not target: return None\n",
        "    favor_left = FAVOR_IMPLIES_LEFT.get(target, None)\n",
        "    if favor_left is None: return None\n",
        "    if raw == \"favor\":   return \"left-leaning\"  if favor_left else \"right-leaning\"\n",
        "    if raw == \"against\": return \"right-leaning\" if favor_left else \"left-leaning\"\n",
        "    return None\n",
        "\n",
        "def apply_filters(df: pd.DataFrame, split_name: str) -> pd.DataFrame:\n",
        "    # text clean\n",
        "    df[\"text\"] = df[\"text\"].astype(str).map(clean_text)\n",
        "    df = df[~df[\"text\"].map(lambda x: CLEAN_BAD.match(x) is not None)]\n",
        "    # stance normalize\n",
        "    df[\"raw_stance\"] = df[\"stance\"].map(normalize_raw_stance)\n",
        "    df = df[df[\"raw_stance\"].notna()]\n",
        "    # left/right mapping\n",
        "    df[\"stance\"] = [raw_to_left_right(r, t) for r, t in zip(df[\"raw_stance\"], df[\"target\"])]\n",
        "    undecided = df[\"stance\"].isna()\n",
        "    df.loc[undecided & (df[\"raw_stance\"] == \"none\"), \"stance\"] = \"neutral\"\n",
        "    df = df[df[\"stance\"].notna()]\n",
        "    # ids & split\n",
        "    if \"id\" in df.columns: df[\"id\"] = df[\"id\"].astype(str)\n",
        "    else: df[\"id\"] = [f\"{split_name}_{i}\" for i in range(len(df))]\n",
        "    df[\"split\"] = split_name\n",
        "    keep = [\"id\", \"target\", \"text\", \"raw_stance\", \"stance\", \"split\"]\n",
        "    if \"opinion_towards\" in df.columns: keep.append(\"opinion_towards\")\n",
        "    if \"sentiment\" in df.columns: keep.append(\"sentiment\")\n",
        "    extras = [c for c in df.columns if c not in keep]\n",
        "    return df[keep + extras].reset_index(drop=True)\n",
        "\n",
        "def build_semeval_splits(data_dir, out_dir):\n",
        "    data_dir = Path(data_dir)\n",
        "    out_dir = Path(out_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    train_df = read_semeval_txt(data_dir / \"trainingdata-all-annotations.txt\")\n",
        "    dev_df   = read_semeval_txt(data_dir / \"trialdata-all-annotations.txt\")\n",
        "\n",
        "    for name, df in [(\"train\", train_df), (\"dev\", dev_df)]:\n",
        "        for needed in [\"id\", \"target\", \"text\", \"stance\"]:\n",
        "            if needed not in df.columns:\n",
        "                raise ValueError(f\"{name}: missing column '{needed}'. Got: {list(df.columns)}\")\n",
        "\n",
        "    train_df = apply_filters(train_df, \"train\").drop_duplicates(subset=[\"id\"])\n",
        "    dev_df   = apply_filters(dev_df, \"dev\").drop_duplicates(subset=[\"id\"])\n",
        "\n",
        "    train_out = out_dir / \"semeval16_train.csv\"; train_df.to_csv(train_out, index=False)\n",
        "    dev_out   = out_dir / \"semeval16_dev.csv\";   dev_df.to_csv(dev_out, index=False)\n",
        "\n",
        "    test_path = data_dir / \"testdata-taskA-all-annotations.txt\"\n",
        "    test_out = None\n",
        "    if test_path.exists():\n",
        "        test_df = read_semeval_txt(test_path)\n",
        "        for needed in [\"id\", \"target\", \"text\", \"stance\"]:\n",
        "            if needed not in test_df.columns:\n",
        "                raise ValueError(f\"test: missing column '{needed}'. Got: {list(test_df.columns)}\")\n",
        "        test_df = apply_filters(test_df, \"test\").drop_duplicates(subset=[\"id\"])\n",
        "        test_out = out_dir / \"semeval16_test.csv\"\n",
        "        test_df.to_csv(test_out, index=False)\n",
        "        return train_df, dev_df, test_df\n",
        "\n",
        "    return train_df, dev_df"
      ],
      "metadata": {
        "id": "PR5SVxqg_l24"
      },
      "id": "PR5SVxqg_l24",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- stance scheme (same as yours) ---\n",
        "from collections import Counter\n",
        "STANCE2ID = {\"neutral\": 0, \"left-leaning\": 1, \"right-leaning\": 2}\n",
        "NORMALIZE = {\n",
        "    \"neutral\": \"neutral\",\n",
        "    \"left\": \"left-leaning\", \"left-leaning\": \"left-leaning\",\n",
        "    \"right\": \"right-leaning\", \"right-leaning\": \"right-leaning\",\n",
        "}\n",
        "VALID = set(STANCE2ID.keys())\n",
        "\n",
        "BAD_TEXT = {\"[removed]\", \"[deleted]\", \".\"}\n",
        "\n",
        "def build_arrays_from_semeval(df):\n",
        "    \"\"\"\n",
        "    Replicates your ConvoKit filtering but for SemEval rows.\n",
        "\n",
        "    Input df columns expected (from our converter):\n",
        "      id, target, text, raw_stance, stance, split, [opinion_towards], [sentiment]\n",
        "    Returns:\n",
        "      utterances, labels, utt_ids, user_ids, topics\n",
        "    \"\"\"\n",
        "    utterances, labels, utt_ids, user_ids, topics = [], [], [], [], []\n",
        "\n",
        "    # SemEval has no confidence score or main-post threading; treat confidence=1.0\n",
        "    for _, row in df.iterrows():\n",
        "        txt = (str(row.get(\"text\") or \"\")).strip()\n",
        "        if (not txt) or (txt in BAD_TEXT):\n",
        "            continue\n",
        "\n",
        "        raw = row.get(\"stance\")\n",
        "        lab = NORMALIZE.get(str(raw).strip().lower()) if raw is not None else None\n",
        "        if lab not in VALID:\n",
        "            continue\n",
        "\n",
        "        # In your ConvoKit code you skip when 'stance_error' and stance == 'neutral'.\n",
        "        # SemEval has no such flag; equivalently, we do nothing here.\n",
        "\n",
        "        # No per-utterance confidence in SemEval; treat as passing the >= 0.8 threshold.\n",
        "        # If you want to emulate the threshold literally, you can set conf = 1.0 and check it.\n",
        "\n",
        "        # Topic: use the SemEval target\n",
        "        topic = row.get(\"target\")\n",
        "\n",
        "        # IDs: tweet id is available; fabricate a speaker id like the ConvoKit version\n",
        "        utt_id = str(row.get(\"id\"))\n",
        "        user_id = f\"tw_{utt_id}\"  # one speaker per tweet (no user info in release)\n",
        "\n",
        "        utterances.append(txt)\n",
        "        labels.append(lab)\n",
        "        utt_ids.append(utt_id)\n",
        "        user_ids.append(user_id)\n",
        "        topics.append(topic)\n",
        "\n",
        "    return utterances, labels, utt_ids, user_ids, topics\n",
        "\n",
        "# --- Example usage with your DataFrames from build_semeval_splits() ---\n",
        "\n",
        "train_X, train_y, train_utt_ids, train_user_ids, train_topics = build_arrays_from_semeval(train_df)\n",
        "dev_X,   dev_y,   dev_utt_ids,   dev_user_ids,   dev_topics   = build_arrays_from_semeval(dev_df)\n",
        "\n",
        "# Optional if you have test:\n",
        "if 'maybe_test' in locals() and len(maybe_test) == 1:\n",
        "    test_df = maybe_test[0]\n",
        "    test_X, test_y, test_utt_ids, test_user_ids, test_topics = build_arrays_from_semeval(test_df)\n",
        "\n",
        "# Quick sanity checks (should mirror earlier counts)\n",
        "# from collections import Counter\n",
        "print(Counter(train_y))  # {'right-leaning': ..., 'neutral': ..., 'left-leaning': ...}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8qnsY35EhqU",
        "outputId": "11cd32f2-e4d1-4176-9e78-280d67c125d8"
      },
      "id": "l8qnsY35EhqU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'right-leaning': 1342, 'neutral': 741, 'left-leaning': 731})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SAME stance scheme as before ===\n",
        "STANCE2ID = {\"neutral\":0, \"left-leaning\":1, \"right-leaning\":2}\n",
        "NORMALIZE = {\n",
        "    \"neutral\":\"neutral\",\n",
        "    \"left\":\"left-leaning\", \"left-leaning\":\"left-leaning\",\n",
        "    \"right\":\"right-leaning\",\"right-leaning\":\"right-leaning\",\n",
        "}\n",
        "VALID = set(STANCE2ID.keys())\n",
        "BAD_TEXT = {\"[removed]\", \"[deleted]\", \".\"}\n",
        "\n",
        "def build_arrays_from_df(df):\n",
        "    utterances, labels, utt_ids, user_ids, topics = [], [], [], [], []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        # --- text filter (same spirit as your ConvoKit filters) ---\n",
        "        txt = (str(row.get(\"text\") or \"\")).strip()\n",
        "        if (not txt) or (txt in BAD_TEXT):\n",
        "            continue\n",
        "\n",
        "        # SemEval has no confidence/stance_error; treat as passing confidence >= 0.8\n",
        "        raw = row.get(\"stance\")  # already 'left-leaning'/'right-leaning'/'neutral' from earlier step\n",
        "        if not raw:\n",
        "            continue\n",
        "\n",
        "        lab = NORMALIZE.get(str(raw).strip().lower())\n",
        "        if lab not in VALID:\n",
        "            continue\n",
        "\n",
        "        topic = row.get(\"target\")            # use SemEval target as topic\n",
        "        utt_id = str(row.get(\"id\"))          # tweet ID\n",
        "        user_id = f\"tw_{utt_id}\"             # no real users in release → synthetic speaker\n",
        "\n",
        "        utterances.append(txt)\n",
        "        labels.append(lab)\n",
        "        utt_ids.append(utt_id)\n",
        "        user_ids.append(user_id)\n",
        "        topics.append(topic)\n",
        "\n",
        "    return utterances, labels, utt_ids, user_ids, topics\n",
        "\n",
        "# ===== USE IT (pick the split you want) =====\n",
        "utterances, labels, utt_ids, user_ids, topics = build_arrays_from_df(train_df)\n",
        "\n",
        "print(len(utterances), len(labels), len(utt_ids), len(user_ids), len(topics))  # should all match\n",
        "# quick sanity:\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "\n",
        "print(Counter(labels))\n",
        "dfs = [train_df, dev_df] + ([maybe_test[0]] if 'maybe_test' in locals() and maybe_test else [])\n",
        "all_df = pd.concat(dfs, ignore_index=True)\n",
        "# utterances, labels, utt_ids, user_ids, topics = build_arrays_from_df(all_df)\n",
        "# Just train split:\n",
        "utterances, labels, utt_ids, user_ids, topics = build_arrays_from_df(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RfiKivhUEl5",
        "outputId": "0344f460-e121-4033-8a0b-e011708feb2e"
      },
      "id": "9RfiKivhUEl5",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2814 2814 2814 2814 2814\n",
            "Counter({'right-leaning': 1342, 'neutral': 741, 'left-leaning': 731})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, dev_df, *maybe_test = build_semeval_splits(\n",
        "    data_dir=\"/content/temporal_belief_analysis/data-all-annotations\",\n",
        "    out_dir=\"./semeval_splits\"\n",
        ")"
      ],
      "metadata": {
        "id": "RZlHQYGhABoj"
      },
      "id": "RZlHQYGhABoj",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df[\"target\"].value_counts())\n",
        "print(train_df[\"stance\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAsyffQCEQpO",
        "outputId": "1d1d1116-c64f-4282-a61d-982d88fbc335"
      },
      "id": "vAsyffQCEQpO",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "target\n",
            "Feminist Movement                   664\n",
            "Hillary Clinton                     639\n",
            "Legalization of Abortion            603\n",
            "Atheism                             513\n",
            "Climate Change is a Real Concern    395\n",
            "Name: count, dtype: int64\n",
            "stance\n",
            "right-leaning    1342\n",
            "neutral           741\n",
            "left-leaning      731\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Inputs: For ConvoKit Corpus ===\n",
        "# from convokit import Corpus\n",
        "# corpus = Corpus(\"path_or_url\")\n",
        "\n",
        "STANCE2ID = {\"neutral\":0, \"left-leaning\":1, \"right-leaning\":2}\n",
        "NORMALIZE = {\n",
        "    \"neutral\":\"neutral\",\n",
        "    \"left\":\"left-leaning\", \"left-leaning\":\"left-leaning\",\n",
        "    \"right\":\"right-leaning\",\"right-leaning\":\"right-leaning\",\n",
        "}\n",
        "VALID = set(STANCE2ID.keys())\n",
        "\n",
        "utterances, labels, utt_ids, user_ids, topics = [], [], [], [], []\n",
        "\n",
        "for u in corpus.iter_utterances():\n",
        "    txt = (u.text or \"\").strip()\n",
        "    stance = u.meta.get('detected_stance')\n",
        "    main_post_id = u.conversation_id\n",
        "    main_post = corpus.get_utterance(main_post_id)\n",
        "    conv = corpus.get_conversation(main_post_id)\n",
        "\n",
        "    conf_raw = u.meta.get('stance_confidence')\n",
        "    # normalize confidence\n",
        "    try:\n",
        "        conf = float(conf_raw)\n",
        "    except (TypeError, ValueError):\n",
        "        conf = None\n",
        "\n",
        "    # --------- SKIP problematic utterances ----------\n",
        "    # missing/empty main post or duplicate of main post\n",
        "    if not txt or txt in {'[removed]', '[deleted]', '.'}:\n",
        "        continue\n",
        "\n",
        "    if not main_post.text or txt == main_post.text:\n",
        "        continue\n",
        "\n",
        "    if 'stance_error' in u.meta.keys() and stance == 'neutral':\n",
        "        continue\n",
        "\n",
        "    if stance not in {'left-leaning', 'right-leaning', 'neutral'}:\n",
        "        continue\n",
        "\n",
        "    # confidence threshold depends on stance\n",
        "    if stance == 'neutral':\n",
        "        if conf is None or conf < 0.8:\n",
        "            continue\n",
        "    elif stance == 'left-leaning':\n",
        "        if conf is None or conf < 0.8:\n",
        "            continue\n",
        "    elif stance == 'right-leaning':\n",
        "        if conf is None or conf < 0.8:\n",
        "            continue\n",
        "\n",
        "    # --- EDIT HERE: pull topic if you have it, else use None/\"\" ---\n",
        "\n",
        "    raw = u.meta.get(\"detected_stance\")\n",
        "\n",
        "    # ------------------------------------------------\n",
        "\n",
        "    # Okay also check this from runpod\n",
        "\n",
        "    if not raw:\n",
        "        continue\n",
        "    lab = NORMALIZE.get(str(raw).strip().lower())  # map aliases\n",
        "    if lab not in VALID:                           # filters Unknown / other\n",
        "        continue\n",
        "\n",
        "    # --- EDIT HERE: pull topic if you have it, else use None/\"\" ---\n",
        "    topic = u.meta.get(\"topic\")  # or compute from your mapping\n",
        "    # --------------------------------------------------------------\n",
        "\n",
        "    utterances.append(txt)\n",
        "    labels.append(lab)\n",
        "    utt_ids.append(u.id)\n",
        "    user_ids.append(u.speaker.id if u.speaker else \"unknown\")\n",
        "    topics.append(topic)"
      ],
      "metadata": {
        "id": "ckuKVY9EtQ-l"
      },
      "id": "ckuKVY9EtQ-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Cap max utterances per label ---\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "# Set your per-label maximums here:\n",
        "MAX_PER_LABEL = {\n",
        "    \"neutral\": 50000,\n",
        "    \"left-leaning\": 50000,\n",
        "    \"right-leaning\": 900,\n",
        "}\n",
        "\n",
        "# Shuffle indices first for randomness\n",
        "all_idx = np.arange(len(labels))\n",
        "rng = np.random.default_rng(42)\n",
        "rng.shuffle(all_idx)\n",
        "\n",
        "# Collect capped indices\n",
        "label_counts = defaultdict(int)\n",
        "keep_idx = []\n",
        "\n",
        "for i in all_idx:\n",
        "    lab = labels[i]\n",
        "    if lab in MAX_PER_LABEL and label_counts[lab] < MAX_PER_LABEL[lab]:\n",
        "        keep_idx.append(i)\n",
        "        label_counts[lab] += 1\n",
        "\n",
        "# Apply filtering\n",
        "utterances = [utterances[i] for i in keep_idx]\n",
        "labels     = [labels[i] for i in keep_idx]\n",
        "utt_ids    = [utt_ids[i] for i in keep_idx]\n",
        "user_ids   = [user_ids[i] for i in keep_idx]\n",
        "topics     = [topics[i] for i in keep_idx]\n",
        "\n",
        "print(\"Final counts per label:\")\n",
        "from collections import Counter\n",
        "print(Counter(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GALleUjaIC0i",
        "outputId": "b2b0e136-a3c1-43b5-9a8d-91eb92156f4e"
      },
      "id": "GALleUjaIC0i",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final counts per label:\n",
            "Counter({'right-leaning': 900, 'neutral': 741, 'left-leaning': 731})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make a user-based split\n",
        "import numpy as np\n",
        "rng = np.random.default_rng(42)\n",
        "uniq_users = np.array(sorted(set(user_ids)))\n",
        "rng.shuffle(uniq_users)\n",
        "cut = int(0.8 * len(uniq_users))\n",
        "train_users = set(uniq_users[:cut])\n",
        "val_users   = set(uniq_users[cut:])\n",
        "\n",
        "train_idx = np.array([i for i,u in enumerate(user_ids) if u in train_users])\n",
        "val_idx   = np.array([i for i,u in enumerate(user_ids) if u in val_users])\n",
        "\n",
        "# Sanity\n",
        "assert len(utterances) == len(labels) == len(utt_ids) == len(user_ids)\n",
        "\n",
        "print(f\"Kept {len(utterances)} labeled utterances.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywKTqttZKlG0",
        "outputId": "af92d674-cc46-4677-9924-54d7bc4d903b"
      },
      "id": "ywKTqttZKlG0",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept 2372 labeled utterances.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "order = ['left-leaning', 'neutral', 'right-leaning']  # desired print order\n",
        "\n",
        "# --- overall counts ---\n",
        "all_counts = Counter(labels)\n",
        "total = len(labels)\n",
        "print(\"Overall:\")\n",
        "for k in order:\n",
        "    c = all_counts.get(k, 0)\n",
        "    print(f\"  {k:13s}: {c:6d} ({c/total:.1%})\")\n",
        "\n",
        "# --- per-split counts (uses your train_idx / val_idx) ---\n",
        "def counts_for_idx(idx):\n",
        "    return Counter(labels[i] for i in idx)\n",
        "\n",
        "print(\"\\nTrain split:\")\n",
        "train_counts = counts_for_idx(train_idx)\n",
        "for k in order:\n",
        "    c = train_counts.get(k, 0)\n",
        "    print(f\"  {k:13s}: {c:6d} ({c/len(train_idx):.1%})\")\n",
        "\n",
        "print(\"\\nVal split:\")\n",
        "val_counts = counts_for_idx(val_idx)\n",
        "for k in order:\n",
        "    c = val_counts.get(k, 0)\n",
        "    print(f\"  {k:13s}: {c:6d} ({c/len(val_idx):.1%})\")\n",
        "\n",
        "# --- optional: class weights aligned with STANCE2ID (for weighted loss) ---\n",
        "num_classes = len(STANCE2ID)\n",
        "class_weights = np.zeros(num_classes, dtype=np.float32)\n",
        "for stance, idx in STANCE2ID.items():\n",
        "    freq = all_counts.get(stance, 0)\n",
        "    class_weights[idx] = (total / (num_classes * max(freq, 1)))  # inverse frequency\n",
        "\n",
        "print(\"\\nClass weights (index order per STANCE2ID):\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1nDYfhmteYu",
        "outputId": "318e71f6-6857-488c-9ef1-88701ffec0c1"
      },
      "id": "N1nDYfhmteYu",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall:\n",
            "  left-leaning :    731 (30.8%)\n",
            "  neutral      :    741 (31.2%)\n",
            "  right-leaning:    900 (37.9%)\n",
            "\n",
            "Train split:\n",
            "  left-leaning :    585 (30.8%)\n",
            "  neutral      :    593 (31.3%)\n",
            "  right-leaning:    719 (37.9%)\n",
            "\n",
            "Val split:\n",
            "  left-leaning :    146 (30.7%)\n",
            "  neutral      :    148 (31.2%)\n",
            "  right-leaning:    181 (38.1%)\n",
            "\n",
            "Class weights (index order per STANCE2ID): [1.0670265 1.0816233 0.8785185]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "import torch, numpy as np\n",
        "from transformers import EarlyStoppingCallback\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler  # <-- add this\n",
        "from collections import Counter\n",
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from transformers import Trainer\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# STANCE2ID = {\"neutral\":0, \"left-leaning\":1, \"right-leaning\":2}\n",
        "ID2STANCE = {v:k for k,v in STANCE2ID.items()}\n",
        "MAX_LEN = 128\n",
        "\n",
        "# ==== you provide ====\n",
        "# utterances: list[str]; labels: list[str] aligned with utterances\n",
        "# Prefer split by USER so test utterances come from unseen users.\n",
        "utterances = utterances   # texts\n",
        "labels     = labels\n",
        "train_idx, val_idx = train_idx, val_idx # indices for your split (ideally user-based)\n",
        "# =====================\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"vinai/bertweet-base\", num_labels=3, id2label=ID2STANCE, label2id=STANCE2ID\n",
        ")\n",
        "\n",
        "# Probs\n",
        "def get_probs(text, target):\n",
        "    # target-aware formatting (recommended)\n",
        "    s = f\"Target: {target} </s> Post: {text}\"\n",
        "    batch = tok(s, return_tensors=\"pt\", truncation=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        logits = mdl(**batch).logits  # [1,3]\n",
        "    return softmax(logits, dim=1).squeeze(0).tolist()  # [p_neutral, p_left, p_right]\n",
        "\n",
        "class StanceDS(Dataset):\n",
        "    def __init__(self, texts, labs):\n",
        "        self.enc = tok(texts, truncation=True, padding=\"max_length\", max_length=MAX_LEN, return_tensors=\"pt\", pad_to_multiple_of=8)\n",
        "        self.y = torch.tensor([STANCE2ID[l] for l in labs], dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i):\n",
        "        item = {k:v[i] for k,v in self.enc.items()}\n",
        "        item[\"labels\"] = self.y[i]\n",
        "        return item\n",
        "\n",
        "train_ds = StanceDS([utterances[i] for i in train_idx], [labels[i] for i in train_idx])\n",
        "val_ds   = StanceDS([utterances[i] for i in val_idx],   [labels[i] for i in val_idx])\n",
        "\n",
        "\n",
        "# === soft class weights from the TRAIN SPLIT ===\n",
        "train_counts = Counter(labels[i] for i in train_idx)\n",
        "num_classes = len(STANCE2ID)\n",
        "total_train = len(train_idx)\n",
        "\n",
        "weights_np = np.zeros(num_classes, dtype=np.float32)\n",
        "for stance, idx in STANCE2ID.items():\n",
        "    freq = max(train_counts.get(stance, 1), 1)\n",
        "    weights_np[idx] = total_train / (num_classes * freq)  # inverse frequency\n",
        "\n",
        "class_weights = torch.tensor(weights_np, dtype=torch.float)\n",
        "# soften the spread: mean=1.0, clamp to a narrow band\n",
        "class_weights = class_weights / class_weights.mean()\n",
        "class_weights = torch.clamp(class_weights, 0.9, 1.2)\n",
        "\n",
        "LABEL_SMOOTH = 0.00  # label smoothing amount\n",
        "\n",
        "# === Trainer with weighted CE + label smoothing (only change to loss) ===\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if isinstance(class_weights, np.ndarray):\n",
        "            class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
        "        self.class_weights = class_weights\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        w = None\n",
        "        if self.class_weights is not None:\n",
        "            w = self.class_weights.to(device=logits.device, dtype=logits.dtype)\n",
        "\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=w, label_smoothing=LABEL_SMOOTH)\n",
        "        loss = loss_fct(logits, labels)\n",
        "\n",
        "        inputs[\"labels\"] = labels  # put back for HF internals\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, y_true = eval_pred\n",
        "    y_pred = logits.argmax(axis=-1)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(\n",
        "        y_true, y_pred, average=\"macro\", zero_division=0\n",
        "    )\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"macro_precision\": p,\n",
        "        \"macro_recall\": r,\n",
        "        \"macro_f1\": f1,\n",
        "    }\n",
        "\n",
        "# init trainining argument\n",
        "args = TrainingArguments(\n",
        "    \"stance-clf\",\n",
        "    learning_rate=2.5e-5,                 # start here for DeBERTa-base\n",
        "    per_device_train_batch_size=16,      # L4: easy fit\n",
        "    per_device_eval_batch_size=32,\n",
        "    # gradient_accumulation_steps = 4,\n",
        "    num_train_epochs=11,                 # allow up to 5 but early-stop\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",   # <-- change\n",
        "    greater_is_better=True,             # <-- change\n",
        "    warmup_ratio=0.1,\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=True,                          # <-- put here, not in Trainer\n",
        "    optim=\"adamw_torch\",\n",
        "    report_to=[],\n",
        "    logging_strategy=\"epoch\",       # <-- add this\n",
        "    logging_first_step=True\n",
        ")\n",
        "\n",
        "# Init trainer\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=tok,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "    # class_weights=class_weights,   # <--- NEW\n",
        ")\n",
        "trainer.train()\n",
        "trainer.save_model(\"stance-clf-best\")\n",
        "tok.save_pretrained(\"stance-clf-best\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "XLPQaZKOt8I0",
        "outputId": "e69e0c9b-48cc-492b-f7c8-d88b7ddcbda9"
      },
      "id": "XLPQaZKOt8I0",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/bertweet-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-794748614.py:77: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='952' max='1309' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 952/1309 02:13 < 00:50, 7.13 it/s, Epoch 8/11]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Macro Precision</th>\n",
              "      <th>Macro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.068900</td>\n",
              "      <td>0.934307</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.586772</td>\n",
              "      <td>0.566751</td>\n",
              "      <td>0.566278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.798700</td>\n",
              "      <td>0.770242</td>\n",
              "      <td>0.669474</td>\n",
              "      <td>0.678602</td>\n",
              "      <td>0.675642</td>\n",
              "      <td>0.669980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539900</td>\n",
              "      <td>0.760723</td>\n",
              "      <td>0.713684</td>\n",
              "      <td>0.715819</td>\n",
              "      <td>0.711821</td>\n",
              "      <td>0.712466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>0.838550</td>\n",
              "      <td>0.713684</td>\n",
              "      <td>0.718978</td>\n",
              "      <td>0.713535</td>\n",
              "      <td>0.713229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.206700</td>\n",
              "      <td>0.992188</td>\n",
              "      <td>0.722105</td>\n",
              "      <td>0.722398</td>\n",
              "      <td>0.721241</td>\n",
              "      <td>0.721763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.110100</td>\n",
              "      <td>1.261888</td>\n",
              "      <td>0.690526</td>\n",
              "      <td>0.696341</td>\n",
              "      <td>0.695978</td>\n",
              "      <td>0.690023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.071200</td>\n",
              "      <td>1.297753</td>\n",
              "      <td>0.715789</td>\n",
              "      <td>0.715033</td>\n",
              "      <td>0.716537</td>\n",
              "      <td>0.715617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.031600</td>\n",
              "      <td>1.447948</td>\n",
              "      <td>0.705263</td>\n",
              "      <td>0.708603</td>\n",
              "      <td>0.700071</td>\n",
              "      <td>0.702700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('stance-clf-best/tokenizer_config.json',\n",
              " 'stance-clf-best/special_tokens_map.json',\n",
              " 'stance-clf-best/vocab.txt',\n",
              " 'stance-clf-best/bpe.codes',\n",
              " 'stance-clf-best/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "out = trainer.predict(val_ds)\n",
        "y_pred = np.argmax(out.predictions, axis=1)\n",
        "y_true = out.label_ids\n",
        "\n",
        "print(classification_report(\n",
        "    y_true, y_pred,\n",
        "    target_names=[\"neutral\",\"left-leaning\",\"right-leaning\"],\n",
        "    digits=2\n",
        "))\n",
        "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "AFBFDF0c6hn_",
        "outputId": "1c9b3c31-8520-43a7-b8c7-dbd7c138d9eb"
      },
      "id": "AFBFDF0c6hn_",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "      neutral       0.70      0.69      0.70       148\n",
            " left-leaning       0.74      0.74      0.74       146\n",
            "right-leaning       0.72      0.73      0.73       181\n",
            "\n",
            "     accuracy                           0.72       475\n",
            "    macro avg       0.72      0.72      0.72       475\n",
            " weighted avg       0.72      0.72      0.72       475\n",
            "\n",
            "Confusion matrix (rows=true, cols=pred):\n",
            "[[102  14  32]\n",
            " [ 18 108  20]\n",
            " [ 25  23 133]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------Deploying it--------------\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.nn.functional import softmax\n",
        "\n",
        "def predict_proba(trainer, dataset):\n",
        "    \"\"\"Runs HF Trainer.predict and returns probabilities (N, C) as np.array.\"\"\"\n",
        "    out = trainer.predict(dataset)                 # out.predictions = logits (N, C)\n",
        "    logits = torch.tensor(out.predictions)         # -> torch tensor\n",
        "    probs = softmax(logits, dim=1).cpu().numpy()   # -> probabilities\n",
        "    return probs, out.label_ids                    # (N, C), (N,)\n",
        "\n",
        "# _____________Use it ___________________\n",
        "probs, y_true = predict_proba(trainer, val_ds)     # probs[:,0:3] are p_neutral/left/right\n",
        "y_hat = probs.argmax(axis=1)"
      ],
      "metadata": {
        "id": "KAQP7T_R_lTY"
      },
      "id": "KAQP7T_R_lTY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many rows in each split?\n",
        "print(len(train_df), \"train rows\")\n",
        "print(len(dev_df), \"dev rows\")\n",
        "if maybe_test:\n",
        "    print(len(maybe_test[0]), \"test rows\")\n",
        "\n",
        "# Peek at first few rows\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "X8qUd7tuDam_",
        "outputId": "7770079a-7cc7-4e71-d37e-11cd9ebcc9a4"
      },
      "id": "X8qUd7tuDam_",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2814 train rows\n",
            "100 dev rows\n",
            "1249 test rows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id   target                                               text raw_stance  \\\n",
              "0  101  Atheism  dear lord thank u for all of ur blessings forg...    against   \n",
              "1  102  Atheism  Blessed are the peacemakers, for they shall be...    against   \n",
              "2  103  Atheism  I am not conformed to this world. I am transfo...    against   \n",
              "3  104  Atheism  Salah should be prayed with #focus and #unders...    against   \n",
              "4  105  Atheism  And stay in your houses and do not display you...    against   \n",
              "\n",
              "          stance  split opinion_towards sentiment  \n",
              "0  right-leaning  train           OTHER  POSITIVE  \n",
              "1  right-leaning  train           OTHER  POSITIVE  \n",
              "2  right-leaning  train           OTHER  POSITIVE  \n",
              "3  right-leaning  train           OTHER  POSITIVE  \n",
              "4  right-leaning  train           OTHER  NEGATIVE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-065f0c4a-73c2-43bd-924c-96b381978316\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>raw_stance</th>\n",
              "      <th>stance</th>\n",
              "      <th>split</th>\n",
              "      <th>opinion_towards</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>dear lord thank u for all of ur blessings forg...</td>\n",
              "      <td>against</td>\n",
              "      <td>right-leaning</td>\n",
              "      <td>train</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>102</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>Blessed are the peacemakers, for they shall be...</td>\n",
              "      <td>against</td>\n",
              "      <td>right-leaning</td>\n",
              "      <td>train</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>103</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>I am not conformed to this world. I am transfo...</td>\n",
              "      <td>against</td>\n",
              "      <td>right-leaning</td>\n",
              "      <td>train</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>104</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>Salah should be prayed with #focus and #unders...</td>\n",
              "      <td>against</td>\n",
              "      <td>right-leaning</td>\n",
              "      <td>train</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>POSITIVE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>105</td>\n",
              "      <td>Atheism</td>\n",
              "      <td>And stay in your houses and do not display you...</td>\n",
              "      <td>against</td>\n",
              "      <td>right-leaning</td>\n",
              "      <td>train</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>NEGATIVE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-065f0c4a-73c2-43bd-924c-96b381978316')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-065f0c4a-73c2-43bd-924c-96b381978316 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-065f0c4a-73c2-43bd-924c-96b381978316');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-340db67b-b5b5-4461-9434-2c744d7fb9fa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-340db67b-b5b5-4461-9434-2c744d7fb9fa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-340db67b-b5b5-4461-9434-2c744d7fb9fa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 2814,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2814,\n        \"samples\": [\n          \"551\",\n          \"1275\",\n          \"1293\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Climate Change is a Real Concern\",\n          \"Legalization of Abortion\",\n          \"Feminist Movement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2814,\n        \"samples\": [\n          \"Secularism. . .secularism. I'm just gonna say this one more time. Secularism. Learn it. #religiousfreedom #freedomfromreligion #SemST\",\n          \"@brandileighhhhh its called sexual coercion, and it is the same as rape. #RapeCulture #SemST\",\n          \"It's frustrating & awful that the only voices getting access to a wider audience are the voices of hate. #ConfederateFlag #race #SemST\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_stance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"against\",\n          \"favor\",\n          \"none\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stance\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"right-leaning\",\n          \"left-leaning\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"split\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"train\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opinion_towards\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"OTHER\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"POSITIVE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(train_df[\"target\"], train_df[\"stance\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "JwH1_VEcECOB",
        "outputId": "ac6c7ced-30ac-4e84-9403-5841958ce9b5"
      },
      "id": "JwH1_VEcECOB",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stance                            left-leaning  neutral  right-leaning\n",
              "target                                                                \n",
              "Atheism                                     92      117            304\n",
              "Climate Change is a Real Concern           212      168             15\n",
              "Feminist Movement                          210      126            328\n",
              "Hillary Clinton                            112      166            361\n",
              "Legalization of Abortion                   105      164            334"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-393fb9bf-10d7-45dd-8e8d-8c5b256b8276\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>stance</th>\n",
              "      <th>left-leaning</th>\n",
              "      <th>neutral</th>\n",
              "      <th>right-leaning</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Atheism</th>\n",
              "      <td>92</td>\n",
              "      <td>117</td>\n",
              "      <td>304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Climate Change is a Real Concern</th>\n",
              "      <td>212</td>\n",
              "      <td>168</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feminist Movement</th>\n",
              "      <td>210</td>\n",
              "      <td>126</td>\n",
              "      <td>328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Hillary Clinton</th>\n",
              "      <td>112</td>\n",
              "      <td>166</td>\n",
              "      <td>361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Legalization of Abortion</th>\n",
              "      <td>105</td>\n",
              "      <td>164</td>\n",
              "      <td>334</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-393fb9bf-10d7-45dd-8e8d-8c5b256b8276')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-393fb9bf-10d7-45dd-8e8d-8c5b256b8276 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-393fb9bf-10d7-45dd-8e8d-8c5b256b8276');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e14abafe-cb19-44c2-8b2f-64c58eceb681\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e14abafe-cb19-44c2-8b2f-64c58eceb681')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e14abafe-cb19-44c2-8b2f-64c58eceb681 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Climate Change is a Real Concern\",\n          \"Legalization of Abortion\",\n          \"Feminist Movement\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"left-leaning\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 59,\n        \"min\": 92,\n        \"max\": 212,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          212,\n          105,\n          210\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"neutral\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24,\n        \"min\": 117,\n        \"max\": 168,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          168,\n          164,\n          126\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"right-leaning\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 143,\n        \"min\": 15,\n        \"max\": 361,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          15,\n          334,\n          328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIydkN9wFZPh"
      },
      "id": "oIydkN9wFZPh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}