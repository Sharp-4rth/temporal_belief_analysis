{
  "cells": [
    {
      "metadata": {
        "id": "8ecfca0265e767d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
      ],
      "id": "8ecfca0265e767d"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install convokit"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5iucLpFZRvd9"
      },
      "id": "5iucLpFZRvd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit\n"
      ],
      "metadata": {
        "id": "faAxYx26R4t6",
        "outputId": "21819877-8b8f-46aa-8b7c-4f3076459f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "faAxYx26R4t6",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = Corpus(filename=download(\"subreddit-PoliticalDiscussion\"))"
      ],
      "metadata": {
        "id": "9mcx9qMoUA68",
        "outputId": "4d8dc739-f238-4984-b0aa-d7178df721fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9mcx9qMoUA68",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "model_directory: ~/.convokit/saved-models\n",
            "default_backend: mem\n",
            "Downloading subreddit-PoliticalDiscussion to /root/.convokit/saved-corpora/subreddit-PoliticalDiscussion\n",
            "Downloading subreddit-PoliticalDiscussion from http://zissou.infosci.cornell.edu/convokit/datasets/subreddit-corpus/corpus-zipped/PokkenGameCirclejerk~-~PoliticalVideos/PoliticalDiscussion.corpus.zip (801.4MB)... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Topic detection functionality for conversation analysis.\"\"\"\n",
        "\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "from temporal_belief_analysis.src.temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
        "from temporal_belief_analysis.src.temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TopicDetector:\n",
        "    \"\"\"Detect topics in ConvoKit conversations using BART.\"\"\"\n",
        "\n",
        "    def __init__(self, topics: Optional[List[str]] = None,\n",
        "                 config: ProjectConfig = None):\n",
        "        \"\"\"Initialize topic detector.\"\"\"\n",
        "        self.config = config or ProjectConfig()\n",
        "        self.classifier = BARTZeroShotClassifier(self.config.bart_model_name)\n",
        "        self.topics = topics or POLITICAL_TOPICS\n",
        "        logger.info(f\"Initialized topic detector with {len(self.topics)} topics\")\n",
        "\n",
        "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
        "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
        "        utterances = list(conversation.iter_utterances())\n",
        "        if not utterances:\n",
        "            logger.warning(f\"No utterances found in conversation {conversation.id}\")\n",
        "            return {\"topic\": \"unknown\", \"confidence\": 0.0}\n",
        "\n",
        "        original_post = utterances[0].text\n",
        "        result = self.classifier.classify_text(original_post, self.topics)\n",
        "\n",
        "        # Clean up the result\n",
        "        # clean_topic = result[\"label\"].replace(\" policy\", \"\")\n",
        "\n",
        "        return {\n",
        "            \"topic\": result[\"label\"],\n",
        "            \"confidence\": result[\"confidence\"],\n",
        "            \"all_scores\": result[\"all_scores\"],\n",
        "            \"text_length\": len(original_post),\n",
        "            \"num_utterances\": len(utterances)\n",
        "        }\n",
        "\n",
        "    def process_corpus(self, corpus, batch_size: int = 50,\n",
        "                       save_path: Optional[str] = None) -> None:\n",
        "        \"\"\"Process entire corpus for topic detection.\"\"\"\n",
        "        conversations = list(corpus.iter_conversations())\n",
        "        logger.info(f\"Processing {len(conversations)} conversations for topic detection\")\n",
        "\n",
        "        # Progress bar library:\n",
        "        for i in tqdm(range(0, len(conversations), batch_size),\n",
        "                      desc=\"Processing conversations\"):\n",
        "            batch = conversations[i:i + batch_size]\n",
        "\n",
        "            for conv in batch:\n",
        "                try:\n",
        "                    topic_result = self.detect_conversation_topic(conv)\n",
        "\n",
        "                    # Add to conversation metadata\n",
        "                    conv.add_meta(\"detected_topic\", topic_result[\"topic\"])\n",
        "                    conv.add_meta(\"topic_confidence\", topic_result[\"confidence\"])\n",
        "                    conv.add_meta(\"topic_scores\", topic_result[\"all_scores\"])\n",
        "\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Failed to process conversation {conv.id}: {e}\")\n",
        "                    conv.add_meta(\"detected_topic\", \"unknown\")\n",
        "                    conv.add_meta(\"topic_confidence\", 0.0)\n",
        "\n",
        "        if save_path:\n",
        "            corpus.dump(save_path)\n",
        "            logger.info(f\"Saved processed corpus to {save_path}\")\n",
        "\n",
        "        logger.info(\"Topic detection processing complete\")"
      ],
      "metadata": {
        "id": "vPF-AwIWUxJe"
      },
      "id": "vPF-AwIWUxJe",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.random_utterance().text"
      ],
      "metadata": {
        "id": "swrcdASP2LaX",
        "outputId": "9b4d472d-b217-4e07-c7a8-3ad85448ff06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "id": "swrcdASP2LaX",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"It was after Sandy Hook, it would have been voluntary having trouble finding an article. \\n\\nHere's a more recent article on Two Republican and Two democrat gun bills voted down https://www.washingtonpost.com/news/powerpost/wp/2016/06/20/senate-heads-for-gun-control-showdown-likely-to-go-nowhere/?utm_term=.cb0a93df0660&amp;wpisrc=al_alert-COMBO-politics%252Bnation\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1O_2ag5g3eCm"
      },
      "id": "1O_2ag5g3eCm",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}