{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-24T09:35:37.555304Z",
     "start_time": "2025-06-24T09:35:34.857381Z"
    }
   },
   "source": [
    "from convokit import Corpus, download\n",
    "import convokit"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonidas/GitHub/temporal_belief_analysis/venv/lib/python3.12/site-packages/convokit/coordination/coordination.py:5: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:39:35.955618Z",
     "start_time": "2025-06-24T09:39:35.951149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
    "from src.temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ],
   "id": "5abb8e28821b51c5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T08:54:08.414391Z",
     "start_time": "2025-06-24T08:54:02.280307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# For your case, something like:\n",
    "corpus = Corpus(download('reddit-corpus-small'))"
   ],
   "id": "de83f8a7e017b092",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists at /Users/leonidas/GitHub/temporal_belief_analysis/data/reddit-corpus-small\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T10:26:10.948704Z",
     "start_time": "2025-06-24T10:26:10.940007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TopicDetector:\n",
    "    \"\"\"Detect topics in ConvoKit conversations using BART.\"\"\"\n",
    "\n",
    "    def __init__(self, topics: Optional[List[str]] = None,\n",
    "             config: ProjectConfig = None):\n",
    "        \"\"\"Initialize topic detector.\"\"\"\n",
    "        self.config = config or ProjectConfig()\n",
    "        self.classifier = BARTZeroShotClassifier(self.config.bart_model_name)\n",
    "        self.topics = topics or POLITICAL_TOPICS\n",
    "        logger.info(f\"Initialized topic detector with {len(self.topics)} topics\")\n",
    "\n",
    "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
    "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
    "        utterances = list(conversation.iter_utterances())\n",
    "        if not utterances:\n",
    "            logger.warning(f\"No utterances found in conversation {conversation.id}\")\n",
    "            return {\"topic\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "        original_post = utterances[0].text\n",
    "        result = self.classifier.classify_text(original_post, self.topics)\n",
    "\n",
    "        return {\n",
    "            \"topic\": result[\"label\"],\n",
    "            \"confidence\": result[\"confidence\"],\n",
    "            \"all_scores\": result[\"all_scores\"],\n",
    "            \"text_length\": len(original_post),\n",
    "            \"num_utterances\": len(utterances)\n",
    "        }\n",
    "\n",
    "    def process_corpus(self, corpus, batch_size: int = 50,\n",
    "                   save_path: Optional[str] = None) -> None:\n",
    "        \"\"\"Process entire corpus for topic detection.\"\"\"\n",
    "        conversations = list(corpus.iter_conversations())\n",
    "        logger.info(f\"Processing {len(conversations)} conversations for topic detection\")\n",
    "\n",
    "        for i in tqdm(range(0, len(conversations), batch_size),\n",
    "                      desc=\"Processing conversations\"):\n",
    "            batch = conversations[i:i + batch_size]\n",
    "\n",
    "            for conv in batch:\n",
    "                try:\n",
    "                    topic_result = self.detect_conversation_topic(conv)\n",
    "\n",
    "                    # Add to conversation metadata\n",
    "                    conv.add_meta(\"detected_topic\", topic_result[\"topic\"])\n",
    "                    conv.add_meta(\"topic_confidence\", topic_result[\"confidence\"])\n",
    "                    conv.add_meta(\"topic_scores\", topic_result[\"all_scores\"])\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to process conversation {conv.id}: {e}\")\n",
    "                    conv.add_meta(\"detected_topic\", \"unknown\")\n",
    "                    conv.add_meta(\"topic_confidence\", 0.0)\n",
    "\n",
    "        if save_path:\n",
    "            corpus.dump(save_path)\n",
    "            logger.info(f\"Saved processed corpus to {save_path}\")\n",
    "\n",
    "        logger.info(\"Topic detection processing complete\")\n"
   ],
   "id": "771eb5a1728036f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8ecfca0265e767d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
