{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "EH8DdCK0Or0F"
      },
      "id": "EH8DdCK0Or0F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
      ],
      "metadata": {
        "collapsed": true,
        "id": "8N1qQjVhaKQy"
      },
      "id": "8N1qQjVhaKQy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get latest version\n",
        "%cd temporal_belief_analysis\n",
        "!git pull"
      ],
      "metadata": {
        "collapsed": true,
        "id": "klCvx9YUvKv6"
      },
      "id": "klCvx9YUvKv6",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "8ecfca0265e767d"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# For colab:\n",
        "!pip install convokit"
      ],
      "id": "8ecfca0265e767d"
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "import unsloth\n",
        "import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit\n",
        "# corpus = Corpus(filename=download(\"subreddit-PoliticalDiscussion\"))\n",
        "from temporal_belief_analysis.src.temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
        "from temporal_belief_analysis.src.temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9mcx9qMoUA68"
      },
      "id": "9mcx9qMoUA68",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For local:\n",
        "from src.temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
        "from src.temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig"
      ],
      "metadata": {
        "id": "8n26m1TaPh9b"
      },
      "id": "8n26m1TaPh9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Topic detection functionality for conversation analysis.\"\"\"\n",
        "\n",
        "from typing import List, Dict, Any, Optional\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class TopicDetector:\n",
        "    \"\"\"Detect topics in ConvoKit conversations using BART.\"\"\"\n",
        "\n",
        "    def __init__(self, topics: Optional[List[str]] = None,\n",
        "                 config: ProjectConfig = None):\n",
        "        \"\"\"Initialize topic detector.\"\"\"\n",
        "        self.config = config or ProjectConfig()\n",
        "        self.classifier = BARTZeroShotClassifier(self.config.bart_model_name)\n",
        "        self.topics = topics or POLITICAL_TOPICS\n",
        "        logger.info(f\"Initialized topic detector with {len(self.topics)} topics\")\n",
        "\n",
        "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
        "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
        "        utterances = list(conversation.iter_utterances())\n",
        "        title = conversation.meta['title']\n",
        "        original_post = utterances[0].text\n",
        "        if not original_post and not title:\n",
        "            logger.warning(f\"No utterances or title found in conversation {conversation.id}\")\n",
        "            return {\"topic\": \"unknown\", \"confidence\": 0.0}\n",
        "\n",
        "        combined_text = f\"Title: {title}. Original Post: {original_post}\"\n",
        "        result = self.classifier.classify_text(combined_text, self.topics)\n",
        "\n",
        "        # Clean up the result\n",
        "        # clean_topic = result[\"label\"].replace(\" policy\", \"\")\n",
        "\n",
        "        return {\n",
        "            \"topic\": result[\"label\"],\n",
        "            \"confidence\": result[\"confidence\"],\n",
        "            \"all_scores\": result[\"all_scores\"],\n",
        "            \"text_length\": len(original_post),\n",
        "            \"num_utterances\": len(utterances)\n",
        "        }\n",
        "\n",
        "    def _prepare_conversation_text(self, conversation):\n",
        "      \"\"\"Extract and prepare text from conversation. Returns (text, metadata).\"\"\"\n",
        "      try:\n",
        "          title = conversation.meta.get('title', '')\n",
        "          first_utterance = next(conversation.iter_utterances(), None)\n",
        "          original_post = first_utterance.text if first_utterance else ''\n",
        "\n",
        "          if not original_post and not title:\n",
        "              return None, {\"topic\": \"unknown\", \"confidence\": 0.0, \"topic_scores\": {}}\n",
        "\n",
        "          # Consistent text formatting and truncation\n",
        "          combined_text = f\"{title}. {original_post}\"[:2000]\n",
        "\n",
        "          metadata = {\n",
        "              \"text_length\": len(original_post),\n",
        "              \"num_utterances\": len(list(conversation.iter_utterances()))\n",
        "          }\n",
        "\n",
        "          return combined_text, metadata\n",
        "\n",
        "      except Exception as e:\n",
        "          logger.error(f\"Failed to prepare conversation {conversation.id}: {e}\")\n",
        "          return None, {\"topic\": \"unknown\", \"confidence\": 0.0, \"topic_scores\": {}}\n",
        "\n",
        "    def _set_conversation_metadata(self, conversation, result: Dict[str, Any]):\n",
        "        \"\"\"Set topic metadata on conversation.\"\"\"\n",
        "        conversation.add_meta(\"detected_topic\", result[\"topic\"])\n",
        "        conversation.add_meta(\"topic_confidence\", result[\"confidence\"])\n",
        "        conversation.add_meta(\"topic_scores\", result.get(\"all_scores\", {}))\n",
        "\n",
        "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
        "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
        "        combined_text, metadata = self._prepare_conversation_text(conversation)\n",
        "\n",
        "        if combined_text is None:\n",
        "            return metadata  # Already contains error result\n",
        "\n",
        "        result = self.classifier.classify_text(combined_text, self.topics)\n",
        "\n",
        "        return {\n",
        "            \"topic\": result[\"label\"],\n",
        "            \"confidence\": result[\"confidence\"],\n",
        "            \"all_scores\": result[\"all_scores\"],\n",
        "            **metadata  # Include text_length, num_utterances\n",
        "        }\n",
        "\n",
        "    def process_corpus(self, corpus, batch_size: int = 200,\n",
        "                    save_path: Optional[str] = None) -> None:\n",
        "        \"\"\"Process entire corpus for topic detection.\"\"\"\n",
        "        conversations = list(corpus.iter_conversations())\n",
        "        logger.info(f\"Processing {len(conversations)} conversations for topic detection\")\n",
        "\n",
        "        for i in tqdm(range(0, len(conversations), batch_size),\n",
        "                      desc=\"Processing conversations\"):\n",
        "            batch = conversations[i:i + batch_size]\n",
        "\n",
        "            # Prepare batch using shared logic\n",
        "            batch_data = []\n",
        "\n",
        "            for conv in batch:\n",
        "                combined_text, metadata = self._prepare_conversation_text(conv)\n",
        "\n",
        "                if combined_text is None:\n",
        "                    # Set error metadata and skip\n",
        "                    self._set_conversation_metadata(conv, metadata)\n",
        "                    continue\n",
        "\n",
        "                batch_data.append((conv, combined_text))\n",
        "\n",
        "            # Process entire batch at once\n",
        "            if batch_data:\n",
        "                texts = [data[1] for data in batch_data]\n",
        "                conversations_to_process = [data[0] for data in batch_data]\n",
        "\n",
        "                try:\n",
        "                    print(f\"üöÄ Attempting batch of {len(texts)} texts...\")\n",
        "                    import time\n",
        "                    start = time.time()\n",
        "\n",
        "                    batch_results = self.classifier.classify_batch(texts, self.topics)\n",
        "\n",
        "                    end = time.time()\n",
        "                    print(f\"‚úÖ Batch completed in {end-start:.2f}s ({(end-start)/len(texts):.3f}s per text)\")\n",
        "\n",
        "                    # Apply results using shared logic\n",
        "                    for conv, result in zip(conversations_to_process, batch_results):\n",
        "                        self._set_conversation_metadata(conv, result)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Batch processing failed: {e}\")\n",
        "                    logger.error(f\"Batch classification failed: {e}\")\n",
        "\n",
        "                    # Fallback: mark all as unknown\n",
        "                    unknown_result = {\"topic\": \"unknown\", \"confidence\": 0.0, \"topic_scores\": {}}\n",
        "                    for conv in conversations_to_process:\n",
        "                        self._set_conversation_metadata(conv, unknown_result)\n",
        "\n",
        "        if save_path:\n",
        "            corpus.dump(save_path)\n",
        "            logger.info(f\"Saved processed corpus to {save_path}\")\n",
        "\n",
        "        logger.info(\"Topic detection processing complete\")"
      ],
      "metadata": {
        "id": "vPF-AwIWUxJe"
      },
      "id": "vPF-AwIWUxJe",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_small = Corpus(filename=download(\"reddit-corpus-small\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "T1ow8xBrcr1e"
      },
      "id": "T1ow8xBrcr1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 'process_corpus()'\n",
        "SAVE_PATH = \"/content/drive/MyDrive/MScProject/Corpora/corpus_small\"\n",
        "topic_detector = TopicDetector()\n",
        "topic_detector.process_corpus(corpus_small, save_path=SAVE_PATH)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "K8oYk7YLM_oW"
      },
      "id": "K8oYk7YLM_oW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing 'detect_conversation_topic()' and 'dump()'\n",
        "i = 0\n",
        "convos_small = list(corpus_small.iter_conversations())\n",
        "topic_detector = TopicDetector()\n",
        "for i in range(3):\n",
        "  utterances = list(convos_small[i].iter_utterances())\n",
        "  title = convos_small[i].meta['title']\n",
        "  og_post = utterances[0].text\n",
        "  print(100*'-')\n",
        "  print(f\"Title: {title} \\n\")\n",
        "  print(f\"OG post: {og_post} \\n\")\n",
        "  topic = topic_detector.detect_conversation_topic(convos_small[i])\n",
        "  print(f\"Detected topic: {topic['topic']} \\n\")\n",
        "  print(f\"Confidence: {topic['confidence']} \\n\")\n",
        "  convos_small[i].add_meta(\"detected_topic\", topic[\"topic\"])\n",
        "  convos_small[i].add_meta(\"topic_confidence\", topic[\"confidence\"])\n",
        "  convos_small[i].add_meta(\"topic_scores\", topic[\"all_scores\"])\n",
        "  i += 1\n",
        "\n",
        "corpus_small.dump(\"/content/drive/MyDrive/MScProject/Corpora/corpus_small\")\n"
      ],
      "metadata": {
        "id": "PxXbHWRrMbDK",
        "collapsed": true
      },
      "id": "PxXbHWRrMbDK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsdRB0uXdcQp"
      },
      "id": "JsdRB0uXdcQp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}