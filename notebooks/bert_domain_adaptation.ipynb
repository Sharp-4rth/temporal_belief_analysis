{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Need to restart after:\n",
    "!pip install convokit[llm]\n",
    "!pip install convokit"
   ],
   "id": "55edda2b57f0546e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
    "print(\"Changed working directory to:\", os.getcwd())\n",
    "\n",
    "# Absolute path to src directory\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ],
   "id": "729be76f70432f3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import time\n",
    "!pip install gdown\n",
    "import zipfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from convokit import Corpus, download\n",
    "import convokit\n",
    "from temporal_belief.core.timeline_building import TimelineBuilder"
   ],
   "id": "eb72f903280d92dd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download and unzip with python (Dataloading):\n",
    "# !gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/1DLFY6JLMZqNjwvNRZmhlV4-rnoQP_eyH/view?usp=sharing\" -O \"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/1nWaj5N8nsG7u5homv_kAh4CLPDv01M_Z/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/15NMRXEkGRoGjK6TXFBHIMOPjkTyZ0keP/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances200000_llm.zip\" --fuzzy\n",
    "# !gdown \"https://drive.google.com/file/d/15nVf6Js0KsDxA9HaB0zCXhc8VdcC-Fy-/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances75000_llm.zip\" --fuzzy\n",
    "!gdown \"https://drive.google.com/file/d/1dOUvQmtjFrXq0hJvnOsP_ZLqdGEyOVNJ/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_llm.zip\" --fuzzy\n",
    "\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances200000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "# zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances75000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_llm.zip\").extractall(\"/content/temporal_belief_analysis\")"
   ],
   "id": "c8b97a9d177cd0bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_llm\")",
   "id": "95578f869b9ff523"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 0) Inputs: a ConvoKit Corpus ===\n",
    "# from convokit import Corpus\n",
    "# corpus = Corpus(\"path_or_url\")\n",
    "\n",
    "STANCE2ID = {\"neutral\":0, \"left-leaning\":1, \"right-leaning\":2}\n",
    "NORMALIZE = {\n",
    "    \"neutral\":\"neutral\",\n",
    "    \"left\":\"left-leaning\", \"left-leaning\":\"left-leaning\",\n",
    "    \"right\":\"right-leaning\",\"right-leaning\":\"right-leaning\",\n",
    "}\n",
    "VALID = set(STANCE2ID.keys())\n",
    "\n",
    "utterances, labels, utt_ids, user_ids, topics = [], [], [], [], []\n",
    "\n",
    "for u in corpus.iter_utterances():\n",
    "    txt = (u.text or \"\").strip()\n",
    "    stance = u.meta.get('detected_stance')\n",
    "    main_post_id = u.conversation_id\n",
    "    main_post = corpus.get_utterance(main_post_id)\n",
    "    conv = corpus.get_conversation(main_post_id)\n",
    "\n",
    "    conf_raw = u.meta.get('stance_confidence')\n",
    "    # normalize confidence\n",
    "    try:\n",
    "        conf = float(conf_raw)\n",
    "    except (TypeError, ValueError):\n",
    "        conf = None\n",
    "\n",
    "    # --------- SKIP problematic utterances ----------\n",
    "    # missing/empty main post or duplicate of main post\n",
    "    if not txt or txt in {'[removed]', '[deleted]', '.'}:\n",
    "        continue\n",
    "\n",
    "    if not main_post.text or txt == main_post.text:\n",
    "        continue\n",
    "\n",
    "    if 'stance_error' in u.meta.keys() and stance == 'neutral':\n",
    "        continue\n",
    "\n",
    "    if stance not in {'left-leaning', 'right-leaning', 'neutral'}:\n",
    "        continue\n",
    "\n",
    "    # confidence threshold depends on stance\n",
    "    if stance == 'neutral':\n",
    "        if conf is None or conf < 0.9:\n",
    "            continue\n",
    "    elif stance == 'left-leaning':\n",
    "        if conf is None or conf < 0.9:\n",
    "            continue\n",
    "    elif stance == 'right-leaning':\n",
    "        if conf is None or conf < 0.9:\n",
    "            continue\n",
    "\n",
    "    # --- EDIT HERE: pull topic if you have it, else use None/\"\" ---\n",
    "\n",
    "    raw = u.meta.get(\"detected_stance\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "\n",
    "    # Okay also check this from runpod\n",
    "\n",
    "    if not raw:\n",
    "        continue\n",
    "    lab = NORMALIZE.get(str(raw).strip().lower())  # map aliases\n",
    "    if lab not in VALID:                           # filters Unknown / other\n",
    "        continue\n",
    "\n",
    "    # --- EDIT HERE: pull topic if you have it, else use None/\"\" ---\n",
    "    topic = u.meta.get(\"topic\")  # or compute from your mapping\n",
    "    # --------------------------------------------------------------\n",
    "\n",
    "    utterances.append(txt)\n",
    "    labels.append(lab)\n",
    "    utt_ids.append(u.id)\n",
    "    user_ids.append(u.speaker.id if u.speaker else \"unknown\")\n",
    "    topics.append(topic)"
   ],
   "id": "3cafed28e28a2aed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Cap max utterances per label ---\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Set your per-label maximums here:\n",
    "MAX_PER_LABEL = {\n",
    "    \"neutral\": 1000,\n",
    "    \"left-leaning\": 1800,\n",
    "    \"right-leaning\": 2000,\n",
    "}\n",
    "\n",
    "# Shuffle indices first for randomness\n",
    "all_idx = np.arange(len(labels))\n",
    "rng = np.random.default_rng(42)\n",
    "rng.shuffle(all_idx)\n",
    "\n",
    "# Collect capped indices\n",
    "label_counts = defaultdict(int)\n",
    "keep_idx = []\n",
    "\n",
    "for i in all_idx:\n",
    "    lab = labels[i]\n",
    "    if lab in MAX_PER_LABEL and label_counts[lab] < MAX_PER_LABEL[lab]:\n",
    "        keep_idx.append(i)\n",
    "        label_counts[lab] += 1\n",
    "\n",
    "# Apply filtering\n",
    "utterances = [utterances[i] for i in keep_idx]\n",
    "labels     = [labels[i] for i in keep_idx]\n",
    "utt_ids    = [utt_ids[i] for i in keep_idx]\n",
    "user_ids   = [user_ids[i] for i in keep_idx]\n",
    "topics     = [topics[i] for i in keep_idx]\n",
    "\n",
    "print(\"Final counts per label:\")\n",
    "from collections import Counter\n",
    "print(Counter(labels))"
   ],
   "id": "11362b5f669438b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# make a user-based split\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(42)\n",
    "uniq_users = np.array(sorted(set(user_ids)))\n",
    "rng.shuffle(uniq_users)\n",
    "cut = int(0.8 * len(uniq_users))\n",
    "train_users = set(uniq_users[:cut])\n",
    "val_users   = set(uniq_users[cut:])\n",
    "\n",
    "train_idx = np.array([i for i,u in enumerate(user_ids) if u in train_users])\n",
    "val_idx   = np.array([i for i,u in enumerate(user_ids) if u in val_users])\n",
    "\n",
    "# Sanity\n",
    "assert len(utterances) == len(labels) == len(utt_ids) == len(user_ids)\n",
    "\n",
    "print(f\"Kept {len(utterances)} labeled utterances.\")"
   ],
   "id": "b18006c0e326e315"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "order = ['left-leaning', 'neutral', 'right-leaning']  # desired print order\n",
    "\n",
    "# --- overall counts ---\n",
    "all_counts = Counter(labels)\n",
    "total = len(labels)\n",
    "print(\"Overall:\")\n",
    "for k in order:\n",
    "    c = all_counts.get(k, 0)\n",
    "    print(f\"  {k:13s}: {c:6d} ({c/total:.1%})\")\n",
    "\n",
    "# --- per-split counts (uses your train_idx / val_idx) ---\n",
    "def counts_for_idx(idx):\n",
    "    return Counter(labels[i] for i in idx)\n",
    "\n",
    "print(\"\\nTrain split:\")\n",
    "train_counts = counts_for_idx(train_idx)\n",
    "for k in order:\n",
    "    c = train_counts.get(k, 0)\n",
    "    print(f\"  {k:13s}: {c:6d} ({c/len(train_idx):.1%})\")\n",
    "\n",
    "print(\"\\nVal split:\")\n",
    "val_counts = counts_for_idx(val_idx)\n",
    "for k in order:\n",
    "    c = val_counts.get(k, 0)\n",
    "    print(f\"  {k:13s}: {c:6d} ({c/len(val_idx):.1%})\")\n",
    "\n",
    "# --- optional: class weights aligned with STANCE2ID (for weighted loss) ---\n",
    "num_classes = len(STANCE2ID)\n",
    "class_weights = np.zeros(num_classes, dtype=np.float32)\n",
    "for stance, idx in STANCE2ID.items():\n",
    "    freq = all_counts.get(stance, 0)\n",
    "    class_weights[idx] = (total / (num_classes * max(freq, 1)))  # inverse frequency\n",
    "\n",
    "print(\"\\nClass weights (index order per STANCE2ID):\", class_weights)"
   ],
   "id": "5d752fd0afc4aa37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch, numpy as np\n",
    "from transformers import EarlyStoppingCallback\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler  # <-- add this\n",
    "from collections import Counter\n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import Trainer\n",
    "import torch.nn as nn\n",
    "\n",
    "# STANCE2ID = {\"neutral\":0, \"left-leaning\":1, \"right-leaning\":2}\n",
    "ID2STANCE = {v:k for k,v in STANCE2ID.items()}\n",
    "MAX_LEN = 128\n",
    "\n",
    "# ==== you provide ====\n",
    "# utterances: list[str]; labels: list[str] aligned with utterances\n",
    "# Prefer split by USER so test utterances come from unseen users.\n",
    "utterances = utterances   # texts\n",
    "labels     = labels\n",
    "train_idx, val_idx = train_idx, val_idx # indices for your split (ideally user-based)\n",
    "# =====================\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", num_labels=3, id2label=ID2STANCE, label2id=STANCE2ID\n",
    ")\n",
    "\n",
    "class StanceDS(Dataset):\n",
    "    def __init__(self, texts, labs):\n",
    "        self.enc = tok(texts, truncation=True, padding=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "        self.y = torch.tensor([STANCE2ID[l] for l in labs], dtype=torch.long)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, i):\n",
    "        item = {k:v[i] for k,v in self.enc.items()}\n",
    "        item[\"labels\"] = self.y[i]\n",
    "        return item\n",
    "\n",
    "train_ds = StanceDS([utterances[i] for i in train_idx], [labels[i] for i in train_idx])\n",
    "val_ds   = StanceDS([utterances[i] for i in val_idx],   [labels[i] for i in val_idx])\n",
    "\n",
    "# train_counts = Counter(labels[i] for i in train_idx)\n",
    "# num_classes = len(STANCE2ID)\n",
    "# total_train = len(train_idx)\n",
    "\n",
    "# weights_np = np.zeros(num_classes, dtype=np.float32)\n",
    "# for stance, idx in STANCE2ID.items():\n",
    "#     freq = train_counts.get(stance, 1)\n",
    "#     weights_np[idx] = total_train / (num_classes * freq)  # inverse frequency\n",
    "\n",
    "# class_weights = torch.tensor(weights_np, dtype=torch.float)\n",
    "# # after building torch tensor class_weights\n",
    "# class_weights = class_weights / class_weights.mean()\n",
    "# class_weights = torch.clamp(class_weights, 0.9, 1.2)  # softer spread\n",
    "\n",
    "# class WeightedTrainer(Trainer):\n",
    "#     def __init__(self, *args, class_weights=None, **kwargs):\n",
    "#         super().__init__(*args, **kwargs)\n",
    "#         # make sure we store a torch tensor\n",
    "#         if isinstance(class_weights, np.ndarray):\n",
    "#             class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "#         elif class_weights is not None and not isinstance(class_weights, torch.Tensor):\n",
    "#             class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "#         self.class_weights = class_weights\n",
    "\n",
    "#     # accept **kwargs for newer HF versions\n",
    "#     def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "#         labels = inputs.pop(\"labels\")\n",
    "#         outputs = model(**inputs)\n",
    "#         logits = outputs.logits\n",
    "\n",
    "#         # ---- FIX: move weights to same device & dtype as logits ----\n",
    "#         if self.class_weights is not None:\n",
    "#             w = self.class_weights.to(device=logits.device, dtype=logits.dtype)\n",
    "#         else:\n",
    "#             w = None\n",
    "#         # ------------------------------------------------------------\n",
    "\n",
    "#         loss_fct = torch.nn.CrossEntropyLoss(weight=w, label_smoothing=0.00)\n",
    "#         loss = loss_fct(logits, labels)\n",
    "\n",
    "#         inputs[\"labels\"] = labels  # optional: put back for HF internals\n",
    "#         return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# class SamplerWeightedTrainer(WeightedTrainer):\n",
    "#     \"\"\"Same as WeightedTrainer, but oversamples RIGHT in the train dataloader.\"\"\"\n",
    "#     def get_train_dataloader(self):\n",
    "#         ds = self.train_dataset\n",
    "#         # ds.y must be a torch.LongTensor of label ids (you have this in StanceDS)\n",
    "#         y = ds.y\n",
    "#         # STANCE2ID order: [neutral=0, left=1, right=2]\n",
    "#         class_boost = torch.tensor([1.0, 1.0, 1.0], dtype=torch.float)  # tune 1.5â€“3.0\n",
    "#         sample_weights = class_boost[y]\n",
    "#         sampler = WeightedRandomSampler(sample_weights,\n",
    "#                                         num_samples=len(sample_weights),\n",
    "#                                         replacement=True)\n",
    "#         return DataLoader(\n",
    "#             ds,\n",
    "#             batch_size=self.args.per_device_train_batch_size,\n",
    "#             sampler=sampler,\n",
    "#             collate_fn=self.data_collator,\n",
    "#             pin_memory=True,\n",
    "#             drop_last=self.args.dataloader_drop_last,\n",
    "#         )\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, y_true = eval_pred\n",
    "    y_pred = logits.argmax(axis=-1)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\", zero_division=0\n",
    "    )\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_precision\": p,\n",
    "        \"macro_recall\": r,\n",
    "        \"macro_f1\": f1,\n",
    "    }\n",
    "\n",
    "# init trainining argument\n",
    "args = TrainingArguments(\n",
    "    \"stance-clf\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=9,                 # allow up to 5 but early-stop\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",   # <-- change\n",
    "    greater_is_better=True,             # <-- change\n",
    "    warmup_ratio=0.01,\n",
    "    weight_decay=0.005,\n",
    "    max_grad_norm=1.0,\n",
    "    report_to=[],\n",
    "    logging_strategy=\"epoch\",       # <-- add this\n",
    "    logging_first_step=True\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tok,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # optional\n",
    ")\n",
    "trainer.train()\n",
    "trainer.save_model(\"stance-clf-best\")\n",
    "tok.save_pretrained(\"stance-clf-best\")"
   ],
   "id": "9cbab9abfaaab061"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "out = trainer.predict(val_ds)\n",
    "y_pred = np.argmax(out.predictions, axis=1)\n",
    "y_true = out.label_ids\n",
    "\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    target_names=[\"neutral\",\"left-leaning\",\"right-leaning\"],\n",
    "    digits=2\n",
    "))\n",
    "print(\"Confusion matrix (rows=true, cols=pred):\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ],
   "id": "3191ddb3d088be61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5ff307c191cd278d"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
