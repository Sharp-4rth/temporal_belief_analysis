{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Need to restart after:\n",
    "!pip install convokit[llm]\n",
    "!pip install convokit"
   ],
   "id": "f31f60c33c386f57"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download file from Google Drive to colab directory\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "!pip install gdown\n",
    "import zipfile\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from convokit import Corpus, download\n",
    "import convokit\n",
    "from temporal_belief.core.timeline_building import TimelineBuilder\n",
    "from temporal_belief.core.change_detection import ChangeDetector\n",
    "from temporal_belief.core.window_extraction import WindowExtractor\n",
    "from temporal_belief.core.op_path_pairing import OpPathPairer\n",
    "from temporal_belief.data.preprocessors import ChangeDetectorPreprocessor\n",
    "from temporal_belief.data.preprocessors import PairPreprocessor\n",
    "from temporal_belief.core.interplay import Interplay"
   ],
   "id": "719bb8c1568bba9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download and unzip with python (Dataloaders):\n",
    "!gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\" --fuzzy\n",
    "!gdown \"https://drive.google.com/file/d/1DLFY6JLMZqNjwvNRZmhlV4-rnoQP_eyH/view?usp=sharing\" -O \"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\" --fuzzy\n",
    "!gdown \"https://drive.google.com/file/d/1nWaj5N8nsG7u5homv_kAh4CLPDv01M_Z/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\" --fuzzy\n",
    "\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/merged_corpus_checkpoint_5.zip\").extractall(\"/content/temporal_belief_analysis\")\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics.zip\").extractall(\"/content/temporal_belief_analysis\")"
   ],
   "id": "32cc484b68d1ecdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load a corpus:\n",
    "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_topics\")"
   ],
   "id": "f771600a48d1cc04"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "timeline_builder = TimelineBuilder(corpus)\n",
    "timelines = timeline_builder.build_timelines()"
   ],
   "id": "683adccaa471a6a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "change_detector = ChangeDetector()\n",
    "groups = change_detector.get_two_groups(timelines)"
   ],
   "id": "791631c501d996c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "window_extractor = WindowExtractor(corpus, timelines)\n",
    "window_extractor.user_conversations_cache = window_extractor.build_global_user_conversations_index()"
   ],
   "id": "a88d55750fc6e31c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "op_path_pairer = OpPathPairer(corpus, timelines)\n",
    "pair_preprocessor = PairPreprocessor()"
   ],
   "id": "1ce48e0fc8365e82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "persuasion_analyzer = Interplay()",
   "id": "395b7d2bc77fbe69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load English stop words\n",
    "stop_words_set = set(stopwords.words('english'))\n",
    "\n",
    "# use the groups\n",
    "groups = change_detector.get_two_groups(timelines)\n",
    "groups_tuple = (groups['with_changes'], groups['no_changes'])\n",
    "\n",
    "# Init\n",
    "i = 0\n",
    "group_means = [] # Initialize as a list to append means\n",
    "group_scores = []\n",
    "utts_num = 0\n",
    "\n",
    "# For each group\n",
    "for group in groups_tuple:\n",
    "    current_group_scores = []\n",
    "\n",
    "    for user_id, topic_timelines in group.items():\n",
    "        user_start_time = time.time()\n",
    "        user_change_points = 0\n",
    "\n",
    "        for topic_timeline in topic_timelines.values():\n",
    "\n",
    "            for change_point in topic_timeline.keys(): # Iterate through change points (keys)\n",
    "                print(f'User: {user_id}, topic: {topic_timeline}, change point {change_point}')\n",
    "                utts_num += 1\n",
    "\n",
    "                user_change_points += 1\n",
    "\n",
    "                # TIME: Window extraction\n",
    "                start_time = time.time()\n",
    "                try:\n",
    "                    candidate_convos = window_extractor.get_conversations_around_change_point(\n",
    "                        change_point=change_point, corpus=corpus\n",
    "                    )\n",
    "                    window_time = time.time() - start_time\n",
    "                    print(f'⏱️ Window extraction: {window_time:.3f}s')\n",
    "                except ValueError as e:\n",
    "                    print(f\"Skipping change point {change_point}: {e}\")\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # TIME: Path extraction\n",
    "                start_time = time.time()\n",
    "                op_path_pairs = []\n",
    "                for candidate_convo in candidate_convos:\n",
    "                    try:\n",
    "                        op_path_pairs.extend(op_path_pairer.extract_rooted_path_from_candidate_convos(\n",
    "                            [candidate_convo], user_id\n",
    "                        ))\n",
    "                    except ValueError as e:\n",
    "                        print(f\"Skipping conversation {candidate_convo.id}: {e}\")\n",
    "                        continue\n",
    "                path_time = time.time() - start_time\n",
    "                print(f'⏱️ Path extraction: {path_time:.3f}s')\n",
    "\n",
    "\n",
    "                # TIME: Preprocessing\n",
    "                start_time = time.time()\n",
    "                preprocessed_pairs = pair_preprocessor.concatenate_path_in_all_pairs(op_path_pairs)\n",
    "                preprocess_time = time.time() - start_time\n",
    "                print(f'⏱️ Preprocessing: {preprocess_time:.3f}s')\n",
    "\n",
    "\n",
    "                # TIME: Feature extraction\n",
    "                start_time = time.time()\n",
    "                features_list = []\n",
    "                for op, paths in preprocessed_pairs:\n",
    "                    for k, concatenated_utts in paths.items():\n",
    "                        interplay_features = persuasion_analyzer.calculate_interplay_features(\n",
    "                            op.text, concatenated_utts, stop_words_set\n",
    "                        )\n",
    "                        features_list.append(interplay_features)\n",
    "                feature_time = time.time() - start_time\n",
    "                print(f'⏱️ Feature extraction: {feature_time:.3f}s')\n",
    "\n",
    "\n",
    "                # TIME: Scoring\n",
    "                start_time = time.time()\n",
    "                scores = []\n",
    "                for interplay_features in features_list:\n",
    "                    score = persuasion_analyzer.calculate_persuasion_score(interplay_features)\n",
    "                    scores.append(score)\n",
    "                scoring_time = time.time() - start_time\n",
    "                print(f'⏱️ Scoring: {scoring_time:.3f}s')\n",
    "                total_time = window_time + path_time + preprocess_time + feature_time + scoring_time\n",
    "                print(f'🔥 TOTAL for change point: {total_time:.3f}s\\n')\n",
    "\n",
    "                # Print total time for this change point\n",
    "                total_time = window_time + path_time + preprocess_time + feature_time + scoring_time\n",
    "                print(f'🔥 TOTAL for change point: {total_time:.3f}s\\n')\n",
    "\n",
    "                current_group_scores.extend(scores)\n",
    "\n",
    "        # TIME: End timing this user\n",
    "        user_total_time = time.time() - user_start_time\n",
    "        print(f'👤 USER {user_id} TOTAL: {user_total_time:.3f}s ({user_change_points} change points)')\n",
    "        print(f'📊 Average per change point: {user_total_time/max(1, user_change_points):.3f}s\\n')\n",
    "\n",
    "    # Calculate mean for this group\n",
    "    total = 0\n",
    "    num_of_scores = 0\n",
    "    for score in current_group_scores: # Iterate through individual scores\n",
    "        total += score\n",
    "        num_of_scores += 1\n",
    "\n",
    "    group_mean = total / num_of_scores if num_of_scores > 0 else 0 # Handle division by zero\n",
    "    group_means.append(group_mean) # Append mean to the list\n",
    "\n",
    "# Print the calculated group means\n",
    "print(f'Group Means: {group_means}')"
   ],
   "id": "668ebf37f0d3de52"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
