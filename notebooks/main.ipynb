{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F8sjSohXnld3",
      "metadata": {
        "id": "F8sjSohXnld3"
      },
      "outputs": [],
      "source": [
        "# Clone Repo:\n",
        "!git clone https://github.com/Sharp-4rth/temporal_belief_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31f60c33c386f57",
      "metadata": {
        "id": "f31f60c33c386f57"
      },
      "outputs": [],
      "source": [
        "# Need to restart after:\n",
        "!pip install convokit[llm]\n",
        "!pip install convokit\n",
        "!pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "524995afbe8f262c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "524995afbe8f262c",
        "outputId": "80940810-6fa7-4c8f-f674-c05443fb4fd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
        "print(\"Changed working directory to:\", os.getcwd())\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "719bb8c1568bba9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "719bb8c1568bba9a",
        "outputId": "1d15dba0-59fe-44fc-cf1c-b758887735d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.19.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2025.8.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "An error occurred: Unsloth currently only works on NVIDIA GPUs and Intel GPUs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/convokit/__init__.py:36: UserWarning: If you are using ConvoKit with Google Colab, incorrect versions of some packages (ex. scipy) may be imported while runtime start. To fix the issue, restart the session and run all codes again. Thank you!\n",
            "  warnings.warn(\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import time\n",
        "!pip install gdown\n",
        "import zipfile\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from convokit import Corpus, download\n",
        "import convokit\n",
        "from temporal_belief.core.timeline_building import TimelineBuilder\n",
        "from temporal_belief.core.change_detection import ChangeDetector\n",
        "from temporal_belief.core.window_extraction import WindowExtractor\n",
        "from temporal_belief.core.op_path_pairing import OpPathPairer\n",
        "from temporal_belief.data.preprocessors import ChangeDetectorPreprocessor\n",
        "from temporal_belief.data.preprocessors import PairPreprocessor\n",
        "from temporal_belief.data.preprocessors import ExtractFeatures\n",
        "from temporal_belief.data.preprocessors import GroupPreprocessor\n",
        "from temporal_belief.core.interplay import Interplay\n",
        "import numpy as np\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "import logging\n",
        "from typing import Dict, List, Tuple, Any, Optional\n",
        "\n",
        "\n",
        "class ChangeDetector:\n",
        "    \"\"\"CUSUM-based change detection for political stance shifts.\n",
        "\n",
        "    Focuses on detecting changes between 'left-leaning' and 'right-leaning' positions,\n",
        "    ignoring neutral stances. Uses cumulative sum control charts to identify\n",
        "    significant shifts in political orientation over time.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, threshold=6.0, drift=0.5, min_change_separation=5):\n",
        "        \"\"\"Initialize CUSUM detector with control parameters.\n",
        "\n",
        "        Args:\n",
        "            threshold: Detection threshold for CUSUM statistic (higher = less sensitive)\n",
        "            drift: Reference drift value for change detection (typically 0.5-1.0)\n",
        "            min_change_separation: Minimum posts between detected changes\n",
        "        \"\"\"\n",
        "        self.threshold = threshold\n",
        "        self.drift = drift\n",
        "        self.min_change_separation = min_change_separation\n",
        "\n",
        "        # Map stances to numeric values for CUSUM\n",
        "        self.stance_values = {\n",
        "            'left-leaning': -1.0,\n",
        "            'neutral': 0.0,  # Will be filtered out\n",
        "            'right-leaning': 1.0\n",
        "        }\n",
        "\n",
        "        self.all_change_points = []\n",
        "        self.all_no_change_points = []\n",
        "\n",
        "        # Logging setup\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _to_probs(self, item):\n",
        "        \"\"\"Convert various input formats to probability tuple (pL, pN, pR).\"\"\"\n",
        "        if isinstance(item, str):\n",
        "            if item == 'left-leaning':  return (1.0, 0.0, 0.0)\n",
        "            if item == 'neutral':       return (0.0, 1.0, 0.0)\n",
        "            if item == 'right-leaning': return (0.0, 0.0, 1.0)\n",
        "            return (0.0, 1.0, 0.0)\n",
        "        if isinstance(item, dict):\n",
        "            return (float(item.get('pL', 0.0)), float(item.get('pN', 0.0)), float(item.get('pR', 0.0)))\n",
        "        if isinstance(item, (list, tuple)) and len(item) == 3:\n",
        "            pL, pN, pR = item\n",
        "            return (float(pL), float(pN), float(pR))\n",
        "        return (0.0, 1.0, 0.0)\n",
        "\n",
        "    def _get_political_signal(self, prob_tuple, conf_threshold=0.6):\n",
        "        \"\"\"Extract political signal from probability tuple, ignoring neutral.\n",
        "\n",
        "        Args:\n",
        "            prob_tuple: (pL, pN, pR) probability tuple\n",
        "            conf_threshold: Minimum confidence to consider stance reliable\n",
        "\n",
        "        Returns:\n",
        "            Float value: -1.0 (left), +1.0 (right), or None (neutral/uncertain)\n",
        "        \"\"\"\n",
        "        pL, pN, pR = prob_tuple\n",
        "\n",
        "        # Only consider if we have sufficient confidence in left or right\n",
        "        if pL >= conf_threshold:\n",
        "            return -1.0  # left-leaning\n",
        "        elif pR >= conf_threshold:\n",
        "            return 1.0  # right-leaning\n",
        "        else:\n",
        "            return None  # neutral or uncertain - ignore for CUSUM\n",
        "\n",
        "    def detect_cusum_changes(self, topic_timeline, conf_threshold=0.6):\n",
        "        \"\"\"Detect political stance changes using CUSUM algorithm.\n",
        "\n",
        "        Args:\n",
        "            topic_timeline: List of (utterance_id, stance_data) tuples\n",
        "            conf_threshold: Minimum confidence for reliable stance detection\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with change_points and no_change_points lists\n",
        "        \"\"\"\n",
        "        if not topic_timeline:\n",
        "            return {'change_points': [], 'no_change_points': []}\n",
        "\n",
        "        # Extract political signals, filtering out neutral/uncertain\n",
        "        signals = []\n",
        "        valid_utterances = []\n",
        "\n",
        "        for utt_id, stance_data in topic_timeline:\n",
        "            prob_tuple = self._to_probs(stance_data)\n",
        "            signal = self._get_political_signal(prob_tuple, conf_threshold)\n",
        "\n",
        "            if signal is not None:\n",
        "                signals.append(signal)\n",
        "                valid_utterances.append(utt_id)\n",
        "\n",
        "        if len(signals) < 3:\n",
        "            self.logger.warning(f\"Insufficient political signals for CUSUM: {len(signals)}\")\n",
        "            return {'change_points': [], 'no_change_points': [utt_id for utt_id, _ in topic_timeline]}\n",
        "\n",
        "        # CUSUM change detection\n",
        "        change_indices = self._cusum_detect_changes(signals)\n",
        "\n",
        "        # Convert indices back to utterance IDs\n",
        "        change_points = [valid_utterances[idx] for idx in change_indices if idx < len(valid_utterances)]\n",
        "\n",
        "        # All other utterances are no-change points\n",
        "        change_set = set(change_points)\n",
        "        no_change_points = [utt_id for utt_id, _ in topic_timeline if utt_id not in change_set]\n",
        "\n",
        "        # Store for aggregate statistics\n",
        "        self.all_change_points.extend(change_points)\n",
        "        self.all_no_change_points.extend(no_change_points)\n",
        "\n",
        "        return {\n",
        "            'change_points': change_points,\n",
        "            'no_change_points': no_change_points\n",
        "        }\n",
        "\n",
        "    def _cusum_detect_changes(self, signals):\n",
        "        \"\"\"Core CUSUM algorithm for detecting mean shifts in political stance.\n",
        "\n",
        "        Args:\n",
        "            signals: List of political stance values (-1.0 or +1.0)\n",
        "\n",
        "        Returns:\n",
        "            List of indices where significant changes were detected\n",
        "        \"\"\"\n",
        "        if len(signals) < 2:\n",
        "            return []\n",
        "\n",
        "        signals = np.array(signals)\n",
        "        n = len(signals)\n",
        "        change_points = []\n",
        "\n",
        "        # Calculate overall mean for reference\n",
        "        overall_mean = np.mean(signals)\n",
        "\n",
        "        # Initialize CUSUM statistics\n",
        "        cusum_pos = 0.0  # Positive CUSUM (detecting upward shifts)\n",
        "        cusum_neg = 0.0  # Negative CUSUM (detecting downward shifts)\n",
        "\n",
        "        for i in range(1, n):\n",
        "            # Calculate deviations from reference mean\n",
        "            deviation = signals[i] - overall_mean\n",
        "\n",
        "            # Update CUSUM statistics\n",
        "            cusum_pos = max(0, cusum_pos + deviation - self.drift)\n",
        "            cusum_neg = max(0, cusum_neg - deviation - self.drift)\n",
        "\n",
        "            # Check for threshold crossings\n",
        "            change_detected = False\n",
        "\n",
        "            if cusum_pos > self.threshold:\n",
        "                # Positive shift detected (towards right-leaning)\n",
        "                change_points.append(i)\n",
        "                cusum_pos = 0.0  # Reset after detection\n",
        "                change_detected = True\n",
        "                self.logger.debug(f\"CUSUM: Positive shift detected at index {i}\")\n",
        "\n",
        "            elif cusum_neg > self.threshold:\n",
        "                # Negative shift detected (towards left-leaning)\n",
        "                change_points.append(i)\n",
        "                cusum_neg = 0.0  # Reset after detection\n",
        "                change_detected = True\n",
        "                self.logger.debug(f\"CUSUM: Negative shift detected at index {i}\")\n",
        "\n",
        "            # Enforce minimum separation between changes\n",
        "            if change_detected and len(change_points) > 1:\n",
        "                if i - change_points[-2] < self.min_change_separation:\n",
        "                    change_points.pop()  # Remove this change point\n",
        "                    self.logger.debug(f\"CUSUM: Removed change point at {i} due to minimum separation\")\n",
        "\n",
        "        return change_points\n",
        "\n",
        "    def detect_cusum_changes_advanced(self, topic_timeline, conf_threshold=0.6,\n",
        "                                      adaptive_threshold=True):\n",
        "        \"\"\"Advanced CUSUM with adaptive thresholding and confidence weighting.\n",
        "\n",
        "        Args:\n",
        "            topic_timeline: List of (utterance_id, stance_data) tuples\n",
        "            conf_threshold: Minimum confidence for reliable stance detection\n",
        "            adaptive_threshold: Whether to adapt threshold based on signal variance\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with change_points and no_change_points lists\n",
        "        \"\"\"\n",
        "        if not topic_timeline:\n",
        "            return {'change_points': [], 'no_change_points': []}\n",
        "\n",
        "        # Extract weighted political signals\n",
        "        signals = []\n",
        "        confidences = []\n",
        "        valid_utterances = []\n",
        "\n",
        "        for utt_id, stance_data in topic_timeline:\n",
        "            prob_tuple = self._to_probs(stance_data)\n",
        "            signal = self._get_political_signal(prob_tuple, conf_threshold)\n",
        "\n",
        "            if signal is not None:\n",
        "                signals.append(signal)\n",
        "                # Extract confidence from stance_data if available\n",
        "                confidence = self._extract_confidence(stance_data)\n",
        "                confidences.append(confidence)\n",
        "                valid_utterances.append(utt_id)\n",
        "\n",
        "        if len(signals) < 3:\n",
        "            return {'change_points': [], 'no_change_points': [utt_id for utt_id, _ in topic_timeline]}\n",
        "\n",
        "        # Adaptive threshold based on signal variance\n",
        "        threshold = self.threshold\n",
        "        if adaptive_threshold:\n",
        "            signal_std = np.std(signals)\n",
        "            threshold = max(self.threshold, 2.0 * signal_std)\n",
        "            self.logger.debug(f\"CUSUM: Adaptive threshold set to {threshold:.2f}\")\n",
        "\n",
        "        # Confidence-weighted CUSUM\n",
        "        change_indices = self._cusum_detect_changes_weighted(signals, confidences, threshold)\n",
        "\n",
        "        change_points = [valid_utterances[idx] for idx in change_indices if idx < len(valid_utterances)]\n",
        "        change_set = set(change_points)\n",
        "        no_change_points = [utt_id for utt_id, _ in topic_timeline if utt_id not in change_set]\n",
        "\n",
        "        self.all_change_points.extend(change_points)\n",
        "        self.all_no_change_points.extend(no_change_points)\n",
        "\n",
        "        return {\n",
        "            'change_points': change_points,\n",
        "            'no_change_points': no_change_points\n",
        "        }\n",
        "\n",
        "    def _cusum_detect_changes_weighted(self, signals, confidences, threshold):\n",
        "        \"\"\"CUSUM with confidence weighting for more reliable change detection.\"\"\"\n",
        "        signals = np.array(signals)\n",
        "        confidences = np.array(confidences)\n",
        "        n = len(signals)\n",
        "        change_points = []\n",
        "\n",
        "        # Confidence-weighted mean\n",
        "        weighted_mean = np.average(signals, weights=confidences)\n",
        "\n",
        "        # Initialize CUSUM with confidence weighting\n",
        "        cusum_pos = 0.0\n",
        "        cusum_neg = 0.0\n",
        "\n",
        "        for i in range(1, n):\n",
        "            # Weight deviation by confidence\n",
        "            deviation = (signals[i] - weighted_mean) * confidences[i]\n",
        "\n",
        "            # Update CUSUM statistics\n",
        "            cusum_pos = max(0, cusum_pos + deviation - self.drift)\n",
        "            cusum_neg = max(0, cusum_neg - deviation - self.drift)\n",
        "\n",
        "            # Detection with separation enforcement\n",
        "            if cusum_pos > threshold or cusum_neg > threshold:\n",
        "                if not change_points or i - change_points[-1] >= self.min_change_separation:\n",
        "                    change_points.append(i)\n",
        "                    cusum_pos = 0.0\n",
        "                    cusum_neg = 0.0\n",
        "\n",
        "                    direction = \"right\" if cusum_pos > cusum_neg else \"left\"\n",
        "                    self.logger.debug(\n",
        "                        f\"CUSUM: {direction} shift detected at index {i}, confidence={confidences[i]:.2f}\")\n",
        "\n",
        "        return change_points\n",
        "\n",
        "    def _extract_confidence(self, stance_data):\n",
        "        \"\"\"Extract confidence score from stance data.\"\"\"\n",
        "        if isinstance(stance_data, dict):\n",
        "            return stance_data.get('confidence', 1.0)\n",
        "        elif isinstance(stance_data, (list, tuple)) and len(stance_data) == 3:\n",
        "            # Use max probability as confidence\n",
        "            return max(stance_data)\n",
        "        else:\n",
        "            return 1.0  # Default confidence\n",
        "\n",
        "    def _get_political_signal(self, prob_tuple, conf_threshold=0.6):\n",
        "        \"\"\"Extract political signal, ignoring neutral positions.\"\"\"\n",
        "        pL, pN, pR = prob_tuple\n",
        "\n",
        "        # Only consider confident left/right positions\n",
        "        if pL >= conf_threshold:\n",
        "            return -1.0  # left-leaning\n",
        "        elif pR >= conf_threshold:\n",
        "            return 1.0  # right-leaning\n",
        "        else:\n",
        "            return None  # neutral/uncertain - ignore\n",
        "\n",
        "    def get_two_groups(self, timelines, method='cusum', conf_threshold=0.6,\n",
        "                       advanced=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Group users into with/without changes using CUSUM detection.\n",
        "\n",
        "        Args:\n",
        "            timelines: Dictionary of {user_id: {topic: timeline}} data\n",
        "            method: Detection method ('cusum' or 'cusum_advanced')\n",
        "            conf_threshold: Minimum confidence for reliable stance detection\n",
        "            advanced: Whether to use confidence-weighted CUSUM\n",
        "            **kwargs: Additional parameters (threshold, drift, etc.)\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with 'with_changes' and 'no_changes' user groups\n",
        "        \"\"\"\n",
        "        with_changes = {}\n",
        "        no_changes = {}\n",
        "\n",
        "        # Update detector parameters from kwargs\n",
        "        if 'threshold' in kwargs:\n",
        "            self.threshold = kwargs['threshold']\n",
        "        if 'drift' in kwargs:\n",
        "            self.drift = kwargs['drift']\n",
        "        if 'min_change_separation' in kwargs:\n",
        "            self.min_change_separation = kwargs['min_change_separation']\n",
        "\n",
        "        # Select detection method\n",
        "        if advanced:\n",
        "            detect_func = lambda tl: self.detect_cusum_changes_advanced(\n",
        "                tl, conf_threshold=conf_threshold, **kwargs\n",
        "            )\n",
        "        else:\n",
        "            detect_func = lambda tl: self.detect_cusum_changes(\n",
        "                tl, conf_threshold=conf_threshold\n",
        "            )\n",
        "\n",
        "        self.logger.info(f\"Starting CUSUM change detection with threshold={self.threshold}, \"\n",
        "                         f\"drift={self.drift}, advanced={advanced}\")\n",
        "\n",
        "        for user_id, topic_timelines in timelines.items():\n",
        "            if user_id == '[deleted]':\n",
        "                continue\n",
        "\n",
        "            user_has_changes = False\n",
        "\n",
        "            for topic_name, topic_timeline in topic_timelines.items():\n",
        "                # Convert to list format expected by detection methods\n",
        "                topic_timeline_list = list(topic_timeline.items())\n",
        "\n",
        "                # Run CUSUM change detection\n",
        "                changes = detect_func(topic_timeline_list)\n",
        "\n",
        "                if changes['change_points']:\n",
        "                    user_has_changes = True\n",
        "                    if user_id not in with_changes:\n",
        "                        with_changes[user_id] = {}\n",
        "\n",
        "                    # Store change points with their stance data\n",
        "                    with_changes[user_id][topic_name] = {\n",
        "                        utt_id: topic_timeline[utt_id]\n",
        "                        for utt_id in changes['change_points']\n",
        "                    }\n",
        "\n",
        "            # Users without any detected changes\n",
        "            if not user_has_changes:\n",
        "                no_changes[user_id] = topic_timelines\n",
        "\n",
        "        # Log summary statistics\n",
        "        self.logger.info(f\"CUSUM Results: {len(with_changes)} users with changes, \"\n",
        "                         f\"{len(no_changes)} users without changes\")\n",
        "        self.logger.info(f\"Total change points detected: {len(self.all_change_points)}\")\n",
        "\n",
        "        return {\n",
        "            'with_changes': with_changes,\n",
        "            'no_changes': no_changes,\n",
        "            'summary': {\n",
        "                'users_with_changes': len(with_changes),\n",
        "                'users_without_changes': len(no_changes),\n",
        "                'total_change_points': len(self.all_change_points),\n",
        "                'detection_parameters': {\n",
        "                    'threshold': self.threshold,\n",
        "                    'drift': self.drift,\n",
        "                    'min_separation': self.min_change_separation,\n",
        "                    'conf_threshold': conf_threshold\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def analyze_change_patterns(self, with_changes_data):\n",
        "        \"\"\"Analyze patterns in detected political stance changes.\n",
        "\n",
        "        Args:\n",
        "            with_changes_data: Users with detected changes from get_two_groups()\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing change pattern analysis\n",
        "        \"\"\"\n",
        "        all_changes = []\n",
        "\n",
        "        for user_id, topics in with_changes_data.items():\n",
        "            for topic_name, change_points in topics.items():\n",
        "                for utt_id, stance_data in change_points.items():\n",
        "                    prob_tuple = self._to_probs(stance_data)\n",
        "                    signal = self._get_political_signal(prob_tuple)\n",
        "\n",
        "                    if signal is not None:\n",
        "                        all_changes.append({\n",
        "                            'user_id': user_id,\n",
        "                            'topic': topic_name,\n",
        "                            'utterance_id': utt_id,\n",
        "                            'direction': 'left_shift' if signal < 0 else 'right_shift',\n",
        "                            'magnitude': abs(signal),\n",
        "                            'confidence': self._extract_confidence(stance_data)\n",
        "                        })\n",
        "\n",
        "        if not all_changes:\n",
        "            return {'total_changes': 0}\n",
        "\n",
        "        # Analyze patterns\n",
        "        change_directions = [c['direction'] for c in all_changes]\n",
        "        change_magnitudes = [c['magnitude'] for c in all_changes]\n",
        "        change_confidences = [c['confidence'] for c in all_changes]\n",
        "\n",
        "        direction_counts = Counter(change_directions)\n",
        "\n",
        "        return {\n",
        "            'total_changes': len(all_changes),\n",
        "            'direction_distribution': dict(direction_counts),\n",
        "            'average_magnitude': np.mean(change_magnitudes),\n",
        "            'average_confidence': np.mean(change_confidences),\n",
        "            'left_shifts': direction_counts.get('left_shift', 0),\n",
        "            'right_shifts': direction_counts.get('right_shift', 0),\n",
        "            'most_common_direction': direction_counts.most_common(1)[0] if direction_counts else None\n",
        "        }\n",
        "\n",
        "    def tune_cusum_parameters(self, validation_timeline, known_changes=None):\n",
        "        \"\"\"Tune CUSUM parameters for optimal performance on validation data.\n",
        "\n",
        "        Args:\n",
        "            validation_timeline: Timeline with known change points for tuning\n",
        "            known_changes: List of known change points for comparison\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with optimal parameters and performance metrics\n",
        "        \"\"\"\n",
        "        # Parameter grid for tuning\n",
        "        threshold_values = [1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0]\n",
        "        drift_values = [0.3, 0.5, 0.7, 1.0]\n",
        "\n",
        "        best_params = None\n",
        "        best_score = -1.0\n",
        "        results = []\n",
        "\n",
        "        for threshold in threshold_values:\n",
        "            for drift in drift_values:\n",
        "                # Temporarily set parameters\n",
        "                original_threshold = self.threshold\n",
        "                original_drift = self.drift\n",
        "\n",
        "                self.threshold = threshold\n",
        "                self.drift = drift\n",
        "\n",
        "                # Test detection\n",
        "                detected = self.detect_cusum_changes(validation_timeline)\n",
        "\n",
        "                # Calculate performance metrics\n",
        "                if known_changes:\n",
        "                    precision, recall, f1 = self._calculate_detection_metrics(\n",
        "                        detected['change_points'], known_changes\n",
        "                    )\n",
        "                    score = f1\n",
        "                else:\n",
        "                    # Use change detection rate as proxy metric\n",
        "                    score = len(detected['change_points']) / max(1, len(validation_timeline))\n",
        "\n",
        "                results.append({\n",
        "                    'threshold': threshold,\n",
        "                    'drift': drift,\n",
        "                    'score': score,\n",
        "                    'change_points': len(detected['change_points'])\n",
        "                })\n",
        "\n",
        "                if score > best_score:\n",
        "                    best_score = score\n",
        "                    best_params = {'threshold': threshold, 'drift': drift}\n",
        "\n",
        "                # Restore original parameters\n",
        "                self.threshold = original_threshold\n",
        "                self.drift = original_drift\n",
        "\n",
        "        # Set best parameters\n",
        "        if best_params:\n",
        "            self.threshold = best_params['threshold']\n",
        "            self.drift = best_params['drift']\n",
        "\n",
        "        self.logger.info(f\"CUSUM tuning complete. Best params: {best_params}, Score: {best_score:.3f}\")\n",
        "\n",
        "        return {\n",
        "            'best_parameters': best_params,\n",
        "            'best_score': best_score,\n",
        "            'all_results': results\n",
        "        }\n",
        "\n",
        "    def _calculate_detection_metrics(self, detected_changes, known_changes):\n",
        "        \"\"\"Calculate precision, recall, and F1 for change detection.\"\"\"\n",
        "        detected_set = set(detected_changes)\n",
        "        known_set = set(known_changes)\n",
        "\n",
        "        true_positives = len(detected_set & known_set)\n",
        "        false_positives = len(detected_set - known_set)\n",
        "        false_negatives = len(known_set - detected_set)\n",
        "\n",
        "        precision = true_positives / max(1, true_positives + false_positives)\n",
        "        recall = true_positives / max(1, true_positives + false_negatives)\n",
        "        f1 = 2 * precision * recall / max(1, precision + recall)\n",
        "\n",
        "        return precision, recall, f1\n",
        "\n",
        "    def get_change_statistics(self):\n",
        "        \"\"\"Get aggregate statistics across all processed timelines.\"\"\"\n",
        "        total_points = len(self.all_change_points) + len(self.all_no_change_points)\n",
        "        change_rate = len(self.all_change_points) / max(1, total_points)\n",
        "\n",
        "        return {\n",
        "            'total_change_points': len(self.all_change_points),\n",
        "            'total_no_change_points': len(self.all_no_change_points),\n",
        "            'overall_change_rate': change_rate,\n",
        "            'detection_parameters': {\n",
        "                'threshold': self.threshold,\n",
        "                'drift': self.drift,\n",
        "                'min_separation': self.min_change_separation\n",
        "            }\n",
        "        }"
      ],
      "metadata": {
        "id": "p1yR-kaIlnRd"
      },
      "id": "p1yR-kaIlnRd",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32cc484b68d1ecdc",
      "metadata": {
        "id": "32cc484b68d1ecdc"
      },
      "outputs": [],
      "source": [
        "# Download and unzip with python (Dataloading):\n",
        "!gdown \"https://drive.google.com/file/d/1AIrstrzE259fcVyxJQW4-RwvAkoUyK1x/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\" --fuzzy\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned.zip\").extractall(\"/content/temporal_belief_analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f771600a48d1cc04",
      "metadata": {
        "id": "f771600a48d1cc04"
      },
      "outputs": [],
      "source": [
        "CORPUS_PATH = \"/content/temporal_belief_analysis/pd_corpus_with_stances_fine_tuned\"\n",
        "corpus = Corpus(filename=CORPUS_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "95fdf3ac90e87037",
      "metadata": {
        "id": "95fdf3ac90e87037",
        "outputId": "adaa8d27-b257-4296-fccf-85b4eecb05f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-01 18:53:25,234 - temporal_belief.core.timeline_building - INFO - timeline_building:73 - Built timelines for 122040 users\n",
            "INFO:temporal_belief.core.timeline_building:Built timelines for 122040 users\n"
          ]
        }
      ],
      "source": [
        "timeline_builder = TimelineBuilder(corpus)\n",
        "timelines = timeline_builder.build_timelines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "09d52765-1092-4f84-b7b2-e709ba96827f",
      "metadata": {
        "id": "09d52765-1092-4f84-b7b2-e709ba96827f",
        "outputId": "29389295-4789-4d70-fabc-e22532f2c3e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building global user conversations index...\n",
            "Processing 102848 conversations...\n",
            "Sorting conversations for 122040 users...\n",
            "Index built for 122040 users!\n"
          ]
        }
      ],
      "source": [
        "window_extractor = WindowExtractor(corpus, timelines)\n",
        "window_extractor.build_global_user_conversations_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7bc910c2-d764-41b9-8a3d-bf828d771426",
      "metadata": {
        "id": "7bc910c2-d764-41b9-8a3d-bf828d771426"
      },
      "outputs": [],
      "source": [
        "op_path_pairer = OpPathPairer(corpus, timelines)\n",
        "pair_preprocessor = PairPreprocessor()\n",
        "feature_extractor = ExtractFeatures()\n",
        "persuasion_analyzer = Interplay()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5a8331b1-c6f4-45ab-9009-842fc20ff011",
      "metadata": {
        "id": "5a8331b1-c6f4-45ab-9009-842fc20ff011"
      },
      "outputs": [],
      "source": [
        "change_detector = ChangeDetector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f99538a9f1bb861",
      "metadata": {
        "id": "f99538a9f1bb861"
      },
      "outputs": [],
      "source": [
        "groups_preprocessor = GroupPreprocessor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c9dadb85-ef97-418a-abb8-354808a28b00",
      "metadata": {
        "scrolled": true,
        "id": "c9dadb85-ef97-418a-abb8-354808a28b00"
      },
      "outputs": [],
      "source": [
        "groups = change_detector.get_two_groups(timelines)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyEeRhHoqbvs"
      },
      "id": "LyEeRhHoqbvs",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from scipy.stats import mannwhitneyu, levene, shapiro\n",
        "import pandas as pd\n",
        "\n",
        "class StancePreprocessor:\n",
        "    \"\"\"Preprocess r/PoliticalDiscussion dataset for stance detection.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_text(text):\n",
        "        clean_text = text.strip()\n",
        "        if len(clean_text) > 500:\n",
        "            clean_text = clean_text[:500] + \"...\"\n",
        "        return clean_text\n",
        "\n",
        "    @staticmethod\n",
        "    def get_contextual_framing_for_topic(topic, text):\n",
        "        if topic:\n",
        "            contextual_text = f\"In a discussion about {topic}, this comment states: {text}\"\n",
        "        else:\n",
        "            contextual_text = f\"In a political discussion, this comment states: {text}\"\n",
        "        return contextual_text\n",
        "\n",
        "    @staticmethod\n",
        "    def mark_quotes(text):\n",
        "        \"\"\"Replace ConvoKit quote markers with standard quotation marks.\"\"\"\n",
        "\n",
        "        # Split text into lines for processing\n",
        "        lines = text.split('\\n')\n",
        "        result_lines = []\n",
        "        in_quote = False\n",
        "\n",
        "        for line in lines:\n",
        "            # Check if line starts a quote (begins with &gt;)\n",
        "            if line.strip().startswith('&gt;'):\n",
        "                if not in_quote:\n",
        "                    # Start of new quote - replace &gt; with opening quote\n",
        "                    cleaned_line = line.replace('&gt;', '\"', 1).lstrip()\n",
        "                    result_lines.append(cleaned_line)\n",
        "                    in_quote = True\n",
        "                else:\n",
        "                    # Continuation of quote - just remove &gt;\n",
        "                    cleaned_line = line.replace('&gt;', '', 1).lstrip()\n",
        "                    result_lines.append(cleaned_line)\n",
        "\n",
        "            # Check if we're ending a quote (empty line or no more &gt; markers)\n",
        "            elif in_quote and (line.strip() == '' or not line.strip().startswith('&gt;')):\n",
        "                # End the quote by adding closing quote to previous line\n",
        "                if result_lines and not result_lines[-1].strip().endswith('\"'):\n",
        "                    result_lines[-1] = result_lines[-1].rstrip() + '\"'\n",
        "\n",
        "                # Add current line if it's not empty\n",
        "                if line.strip():\n",
        "                    result_lines.append(line)\n",
        "                else:\n",
        "                    result_lines.append(line)  # Keep empty lines\n",
        "\n",
        "                in_quote = False\n",
        "\n",
        "            else:\n",
        "                # Regular line, not in quote\n",
        "                result_lines.append(line)\n",
        "\n",
        "        # Handle case where quote goes to end of text\n",
        "        if in_quote and result_lines and not result_lines[-1].strip().endswith('\"'):\n",
        "            result_lines[-1] = result_lines[-1].rstrip() + '\"'\n",
        "\n",
        "        return '\\n'.join(result_lines)\n",
        "\n",
        "\n",
        "class ChangeDetectorPreprocessor:\n",
        "    \"\"\"Filtering timelines for change detection.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2, min_confidence=0.0):\n",
        "        \"\"\"Filter timelines to only include users/topics suitable for change detection\"\"\"\n",
        "        filtered_timelines = {}\n",
        "\n",
        "        for user_id, user_timeline in timelines.items():\n",
        "            filtered_user_timeline = {}\n",
        "\n",
        "            for topic, topic_posts in user_timeline.items():\n",
        "                # Filter by confidence (if you have access to corpus here)\n",
        "                reliable_posts = {}\n",
        "                for utt_id, stance in topic_posts.items():\n",
        "                    # You'd need to pass corpus or confidence scores here\n",
        "                    # For now, assume all posts are reliable\n",
        "                    reliable_posts[utt_id] = stance\n",
        "\n",
        "                # Check minimum posts per topic\n",
        "                if len(reliable_posts) >= min_posts_per_topic:\n",
        "                    filtered_user_timeline[topic] = reliable_posts\n",
        "\n",
        "            # Check minimum topics per user\n",
        "            if len(filtered_user_timeline) >= min_topics_per_user:\n",
        "                filtered_timelines[user_id] = filtered_user_timeline\n",
        "\n",
        "        return filtered_timelines\n",
        "\n",
        "\n",
        "class PairPreprocessor:\n",
        "\n",
        "    def tokenize_quotes(self, utterance_text):\n",
        "        lines = utterance_text.split('\\n')\n",
        "        processed_lines = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line.startswith('&gt;') or line.startswith('>'):\n",
        "                processed_lines.append('[QUOTE]')\n",
        "            else:\n",
        "                processed_lines.append(line)\n",
        "\n",
        "        return '\\n'.join(processed_lines)\n",
        "\n",
        "    def concatenate_path(self, paths):\n",
        "        concatenated_paths = {}\n",
        "        for key, utt_list in paths.items():\n",
        "            path_text = ''\n",
        "            for utt in utt_list:\n",
        "                utt_text_quoted = self.tokenize_quotes(utt.text)\n",
        "                path_text += utt_text_quoted + ' '\n",
        "            concatenated_paths[key] = path_text.strip()\n",
        "        return concatenated_paths\n",
        "\n",
        "    def tokenize_and_lower(self, op_text, reply_path_text, stop_words_set):\n",
        "        op_words = op_text.lower().split()\n",
        "        reply_words = reply_path_text.lower().split()\n",
        "\n",
        "        return (op_words, reply_words)\n",
        "\n",
        "    # This pattern keeps letters, numbers, whitespace, and apostrophes (for contractions)\n",
        "    def remove_punctuation(self, op_text, reply_path_text):\n",
        "        op_text = re.sub(r\"[^\\w\\s']\", '', op_text)\n",
        "        reply_path_text = re.sub(r\"[^\\w\\s']\", '', reply_path_text)\n",
        "\n",
        "        return op_text, reply_path_text\n",
        "\n",
        "    def remove_quotes_from_all(self, op_path_pairs):\n",
        "        marked_pairs = []\n",
        "        for op_path_pair in op_path_pairs:\n",
        "            # Process the OP utterance\n",
        "            op_text = self.tokenize_quotes(op_path_pair[0].text)\n",
        "\n",
        "            # Process each utterance path\n",
        "            processed_paths = []\n",
        "            for utterances in op_path_pair[1].values():\n",
        "                path = [self.tokenize_quotes(utt.text) for utt in utterances]\n",
        "                processed_paths.append(path)\n",
        "\n",
        "            marked_pairs.append((op_text, processed_paths))\n",
        "\n",
        "        return marked_pairs\n",
        "\n",
        "    def concatenate_path_in_pair(self, pair):\n",
        "        op = pair[0]\n",
        "        paths = pair[1]\n",
        "\n",
        "        concatenated_paths = self.concatenate_path(paths)\n",
        "\n",
        "        return (op, concatenated_paths)\n",
        "\n",
        "    def concatenate_path_in_all_pairs(self, op_path_pairs):\n",
        "        # op_path_pairs_quoted = self.remove_quotes_from_all(op_path_pairs)\n",
        "        preprocessed_pairs = []\n",
        "        for pair in op_path_pairs:\n",
        "            pair = self.concatenate_path_in_pair(pair)\n",
        "            preprocessed_pairs.append(pair)\n",
        "\n",
        "        return preprocessed_pairs\n",
        "\n",
        "    def clean_and_tokenize(self, op_text, reply_path_text):\n",
        "        # Step 1: Remove punctuation\n",
        "        op_text, reply_path_text = self.remove_punctuation(op_text, reply_path_text)\n",
        "\n",
        "        # Step 2: Tokenize and lowercase\n",
        "        op_words, reply_words = self.tokenize_and_lower(op_text, reply_path_text)\n",
        "\n",
        "        return op_words, reply_words\n",
        "\n",
        "class ExtractFeatures:\n",
        "\n",
        "    # Feature extraction functions (return features, not scores)\n",
        "    def get_politeness_features(self, concatenated_path_text):\n",
        "        \"\"\"Fast regex-based approximation - good enough for thesis analysis\"\"\"\n",
        "        text_lower = concatenated_path_text.lower()\n",
        "\n",
        "        return {\n",
        "            'politeness_gratitude': len(\n",
        "                re.findall(r'\\b(thank|thanks|grateful|appreciate|gratitude)\\b', text_lower)),\n",
        "            'politeness_apologizing': len(\n",
        "                re.findall(r'\\b(sorry|apolog|excuse me|my bad|my mistake)\\b', text_lower)),\n",
        "            'politeness_please': len(re.findall(r'\\bplease\\b', text_lower)),\n",
        "            'politeness_indirect_greeting': len(re.findall(r'\\b(hello|hi|hey|greetings)\\b', text_lower)),\n",
        "            'politeness_please_start': 1 if re.match(r'^\\s*please\\b', text_lower) else 0,\n",
        "            'politeness_hashedge': len(\n",
        "                re.findall(r'\\b(maybe|perhaps|might|could|would|possibly|probably|seems|appears)\\b', text_lower)),\n",
        "            'politeness_deference': len(\n",
        "                re.findall(r'\\b(sir|madam|mr\\.|mrs\\.|ms\\.|dr\\.|professor|respectfully)\\b', text_lower)),\n",
        "        }\n",
        "\n",
        "    def extract_argument_complexity_features(self, text):\n",
        "        words = text.split()\n",
        "        sentences = [s for s in text.split('.') if s.strip()]\n",
        "        subordinating = ['because', 'since', 'although', 'while', 'whereas', 'if']\n",
        "\n",
        "        return {\n",
        "            'word_count': len(words),\n",
        "            'unique_words': len(set(words)),\n",
        "            'sentence_count': len(sentences),\n",
        "            'subordinating_count': sum(text.lower().count(word) for word in subordinating)\n",
        "        }\n",
        "\n",
        "    def extract_evidence_features(self, text):\n",
        "        import re\n",
        "        evidence_patterns = [\n",
        "            r'http[s]?://\\S+',\n",
        "            r'according to',\n",
        "            r'research shows',\n",
        "            r'studies indicate',\n",
        "            r'data suggests',\n",
        "            r'statistics show',\n",
        "            r'survey found',\n",
        "            r'report states'\n",
        "        ]\n",
        "\n",
        "        evidence_counts = {}\n",
        "        for i, pattern in enumerate(evidence_patterns):\n",
        "            evidence_counts[f'evidence_type_{i}'] = len(re.findall(pattern, text.lower()))\n",
        "\n",
        "        return evidence_counts\n",
        "\n",
        "    def extract_hedging_features(self, text):\n",
        "        hedges = [\n",
        "            'might', 'could', 'perhaps', 'possibly', 'probably', 'likely',\n",
        "            'seems', 'appears', 'suggests', 'indicates', 'tends to',\n",
        "            'generally', 'usually', 'often', 'sometimes', 'may'\n",
        "        ]\n",
        "\n",
        "        hedge_counts = {}\n",
        "        for hedge in hedges:\n",
        "            hedge_counts[f'hedge_{hedge}'] = text.lower().count(hedge)\n",
        "\n",
        "        return {\n",
        "            'hedge_counts': hedge_counts,\n",
        "            'total_words': len(text.split())\n",
        "        }\n",
        "\n",
        "    # Scoring functions (take features, return single score)\n",
        "    def calculate_complexity_score(self, features):\n",
        "        if features['word_count'] == 0:\n",
        "            return 0\n",
        "\n",
        "        lexical_diversity = features['unique_words'] / features['word_count']\n",
        "        avg_sentence_length = features['word_count'] / max(1, features['sentence_count'])\n",
        "        subordinating_ratio = features['subordinating_count'] / features['word_count']\n",
        "\n",
        "        return lexical_diversity + (avg_sentence_length / 100) + subordinating_ratio\n",
        "\n",
        "    def calculate_evidence_score(self, features):\n",
        "        return sum(features.values())\n",
        "\n",
        "    def calculate_hedging_score_from_features(self, features):\n",
        "        total_hedges = sum(features['hedge_counts'].values())\n",
        "        return total_hedges / max(1, features['total_words'])\n",
        "\n",
        "class GroupPreprocessor:\n",
        "\n",
        "    def filter_groups(self, groups, groups_tuple):\n",
        "        # Calculate activity per user in treatment group\n",
        "        treatment_total = 0\n",
        "        control_total = 0\n",
        "        for group_idx, group in enumerate(tqdm(groups_tuple, desc=\"Processing groups\")):\n",
        "            for user_id, topic_timelines in group.items():\n",
        "                for topic_timeline in topic_timelines.values():\n",
        "                    for change_point in topic_timeline.keys():\n",
        "                        if group_idx == 0:  # Iterate through change points (keys)\n",
        "                            treatment_total += 1\n",
        "                        elif group_idx == 1:\n",
        "                            control_total += 1\n",
        "\n",
        "        print(f\"treatment: {treatment_total}\")\n",
        "        # print(f\"Control: {control_total}\")\n",
        "\n",
        "        treatment_activity = []\n",
        "        for user_id, timelines in groups['with_changes'].items():\n",
        "            total_points = sum(len(timeline) for timeline in timelines.values())\n",
        "            treatment_activity.append(total_points)\n",
        "\n",
        "        target_activity = sum(treatment_activity) // len(treatment_activity)  # Average activity\n",
        "        target_total = treatment_total  # Match treatment group size\n",
        "\n",
        "        # Filter control group users by similar activity level\n",
        "        filtered_control = {}\n",
        "        control_total = 0\n",
        "\n",
        "        for user_id, timelines in groups['no_changes'].items():\n",
        "            user_activity = sum(len(timeline) for timeline in timelines.values())\n",
        "\n",
        "            # Keep users with similar activity level\n",
        "            if target_activity * 0.5 <= user_activity <= target_activity * 2:\n",
        "                filtered_control[user_id] = timelines\n",
        "                control_total += user_activity\n",
        "\n",
        "                # Stop when we reach target total\n",
        "                if control_total >= target_total:\n",
        "                    break\n",
        "\n",
        "        # Replace control group\n",
        "        groups_tuple = (groups['with_changes'], filtered_control)\n",
        "        print(f\"Filtered control group: {len(filtered_control)} users, ~{control_total} total points\")\n",
        "\n",
        "        return groups_tuple\n",
        "\n",
        "    def get_target(self, groups_tuple):\n",
        "        # Calculate the number of utterances in each group\n",
        "        print(\"Calculating group sizes...\")\n",
        "        group_sizes = []\n",
        "\n",
        "        for group_idx, group in enumerate(tqdm(groups_tuple, desc=\"Counting utterances in groups\")):\n",
        "            utterance_count = 0\n",
        "\n",
        "            for user_id, topic_timelines in group.items():\n",
        "                for topic_timeline in topic_timelines.values():\n",
        "                    utterance_count += len(topic_timeline.keys())  # Each key is a change point/utterance\n",
        "\n",
        "            group_sizes.append(utterance_count)\n",
        "            print(f\"Group {group_idx + 1}: {utterance_count} utterances\")\n",
        "\n",
        "        # Set target_utterances to the smallest group size\n",
        "        target_utterances = min(group_sizes)\n",
        "        print(f\"\\nSmallest group has {target_utterances} utterances\")\n",
        "        print(f\"Setting target_utterances = {target_utterances}\")\n",
        "\n",
        "        # Show the sampling strategy\n",
        "        print(f\"\\nSampling strategy:\")\n",
        "        for group_idx, size in enumerate(group_sizes):\n",
        "            print(\n",
        "                f\"Group {group_idx + 1}: {size} total  {target_utterances} sampled ({target_utterances / size * 100:.1f}%)\")\n",
        "\n",
        "        return target_utterances\n",
        "\n",
        "    def run_statistical_comparison(self, group_scores, alpha=0.05):\n",
        "\n",
        "\n",
        "        def cohen_d(group1, group2):\n",
        "            \"\"\"Calculate Cohen's d for effect size\"\"\"\n",
        "            n1, n2 = len(group1), len(group2)\n",
        "            pooled_std = np.sqrt(\n",
        "                ((n1 - 1) * np.var(group1, ddof=1) + (n2 - 1) * np.var(group2, ddof=1)) / (n1 + n2 - 2))\n",
        "            return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
        "\n",
        "        def interpret_effect_size(d):\n",
        "            \"\"\"Interpret Cohen's d effect size\"\"\"\n",
        "            abs_d = abs(d)\n",
        "            if abs_d < 0.2:\n",
        "                return \"Negligible\"\n",
        "            elif abs_d < 0.5:\n",
        "                return \"Small\"\n",
        "            elif abs_d < 0.8:\n",
        "                return \"Medium\"\n",
        "            else:\n",
        "                return \"Large\"\n",
        "\n",
        "        print(\"=== STATISTICAL SIGNIFICANCE TESTING ===\\n\")\n",
        "\n",
        "        if len(group_scores) < 2:\n",
        "            print(\"Error: Need at least 2 groups for comparison\")\n",
        "        else:\n",
        "            # Extract scores for the two groups\n",
        "            group1_scores = group_scores[0]\n",
        "            group2_scores = group_scores[1]\n",
        "\n",
        "            # Results storage\n",
        "            results_df = []\n",
        "\n",
        "            print(f\"Group 1 sample sizes: {[len(scores) for scores in group1_scores.values()]}\")\n",
        "            print(f\"Group 2 sample sizes: {[len(scores) for scores in group2_scores.values()]}\")\n",
        "            print()\n",
        "\n",
        "            # Test each predictor\n",
        "            for predictor in group1_scores.keys():\n",
        "                print(f\"=== {predictor.upper()} ===\")\n",
        "\n",
        "                # Get scores for both groups\n",
        "                g1_scores = np.array(group1_scores[predictor])\n",
        "                g2_scores = np.array(group2_scores[predictor])\n",
        "\n",
        "                # Skip if either group has no scores\n",
        "                if len(g1_scores) == 0 or len(g2_scores) == 0:\n",
        "                    print(f\"Skipping {predictor}: One or both groups have no scores\\n\")\n",
        "                    continue\n",
        "\n",
        "                # Basic descriptive statistics\n",
        "                g1_mean, g1_std = np.mean(g1_scores), np.std(g1_scores, ddof=1)\n",
        "                g2_mean, g2_std = np.mean(g2_scores), np.std(g2_scores, ddof=1)\n",
        "\n",
        "                print(f\"Group 1:  = {g1_mean:.4f},  = {g1_std:.4f}, n = {len(g1_scores)}\")\n",
        "                print(f\"Group 2:  = {g2_mean:.4f},  = {g2_std:.4f}, n = {len(g2_scores)}\")\n",
        "\n",
        "                # Calculate difference and percentage change\n",
        "                difference = g1_mean - g2_mean\n",
        "                percent_change = (difference / g2_mean * 100) if g2_mean != 0 else 0\n",
        "                print(f\"Difference: {difference:.4f} ({percent_change:+.1f}%)\")\n",
        "\n",
        "                # Test for normality (if sample size allows)\n",
        "                normal_g1 = normal_g2 = None\n",
        "                if len(g1_scores) >= 3:\n",
        "                    _, p_norm_g1 = shapiro(g1_scores[:5000] if len(g1_scores) > 5000 else g1_scores)\n",
        "                    normal_g1 = p_norm_g1 > 0.05\n",
        "                if len(g2_scores) >= 3:\n",
        "                    _, p_norm_g2 = shapiro(g2_scores[:5000] if len(g2_scores) > 5000 else g2_scores)\n",
        "                    normal_g2 = p_norm_g2 > 0.05\n",
        "\n",
        "                # Test for equal variances\n",
        "                equal_var = None\n",
        "                if len(g1_scores) >= 2 and len(g2_scores) >= 2:\n",
        "                    _, p_levene = levene(g1_scores, g2_scores)\n",
        "                    equal_var = p_levene > 0.05\n",
        "\n",
        "                print(f\"Normality: G1={normal_g1}, G2={normal_g2}\")\n",
        "                print(f\"Equal variances: {equal_var}\")\n",
        "\n",
        "                # Choose appropriate test\n",
        "                if normal_g1 and normal_g2 and equal_var:\n",
        "                    # Two-sample t-test (equal variances)\n",
        "                    t_stat, p_value = stats.ttest_ind(g1_scores, g2_scores, equal_var=True)\n",
        "                    test_used = \"Two-sample t-test (equal var)\"\n",
        "                elif normal_g1 and normal_g2 and not equal_var:\n",
        "                    # Welch's t-test (unequal variances)\n",
        "                    t_stat, p_value = stats.ttest_ind(g1_scores, g2_scores, equal_var=False)\n",
        "                    test_used = \"Welch's t-test (unequal var)\"\n",
        "                else:\n",
        "                    # Mann-Whitney U test (non-parametric)\n",
        "                    u_stat, p_value = mannwhitneyu(g1_scores, g2_scores, alternative='two-sided')\n",
        "                    test_used = \"Mann-Whitney U test\"\n",
        "                    t_stat = u_stat\n",
        "\n",
        "                # Effect size (Cohen's d)\n",
        "                effect_size = cohen_d(g1_scores, g2_scores)\n",
        "                effect_interpretation = interpret_effect_size(effect_size)\n",
        "\n",
        "                # Significance interpretation\n",
        "                if p_value < 0.001:\n",
        "                    significance = \"***\"\n",
        "                    sig_text = \"p < 0.001\"\n",
        "                elif p_value < 0.01:\n",
        "                    significance = \"**\"\n",
        "                    sig_text = \"p < 0.01\"\n",
        "                elif p_value < 0.05:\n",
        "                    significance = \"*\"\n",
        "                    sig_text = \"p < 0.05\"\n",
        "                elif p_value < 0.1:\n",
        "                    significance = \".\"\n",
        "                    sig_text = \"p < 0.1 (marginal)\"\n",
        "                else:\n",
        "                    significance = \"\"\n",
        "                    sig_text = \"not significant\"\n",
        "\n",
        "                print(f\"Test used: {test_used}\")\n",
        "                print(f\"Test statistic: {t_stat:.4f}\")\n",
        "                print(f\"p-value: {p_value:.6f} {significance}\")\n",
        "                print(f\"Result: {sig_text}\")\n",
        "                print(f\"Effect size (Cohen's d): {effect_size:.4f} ({effect_interpretation})\")\n",
        "\n",
        "                # Store results\n",
        "                results_df.append({\n",
        "                    'Predictor': predictor,\n",
        "                    'Group_1_Mean': g1_mean,\n",
        "                    'Group_1_SD': g1_std,\n",
        "                    'Group_1_N': len(g1_scores),\n",
        "                    'Group_2_Mean': g2_mean,\n",
        "                    'Group_2_SD': g2_std,\n",
        "                    'Group_2_N': len(g2_scores),\n",
        "                    'Difference': difference,\n",
        "                    'Percent_Change': percent_change,\n",
        "                    'Test_Used': test_used,\n",
        "                    'Test_Statistic': t_stat,\n",
        "                    'P_Value': p_value,\n",
        "                    'Significance': significance,\n",
        "                    'Effect_Size_d': effect_size,\n",
        "                    'Effect_Interpretation': effect_interpretation,\n",
        "                    'Significant': p_value < 0.05\n",
        "                })\n",
        "\n",
        "                print(\"-\" * 50)\n",
        "                print()\n",
        "\n",
        "            # Create summary table\n",
        "            results_df = pd.DataFrame(results_df)\n",
        "\n",
        "            print(\"=== SUMMARY TABLE ===\")\n",
        "            summary_table = results_df[['Predictor', 'Group_1_Mean', 'Group_2_Mean', 'Difference',\n",
        "                                        'P_Value', 'Significance', 'Effect_Size_d', 'Effect_Interpretation']]\n",
        "            print(summary_table.to_string(index=False, float_format='%.4f'))\n",
        "\n",
        "            print(f\"\\n=== OVERALL RESULTS ===\")\n",
        "            significant_predictors = results_df[results_df['Significant'] == True]\n",
        "            print(f\"Significant predictors (p < 0.05): {len(significant_predictors)}/{len(results_df)}\")\n",
        "\n",
        "            if len(significant_predictors) > 0:\n",
        "                print(\"\\nSignificant findings:\")\n",
        "                for _, row in significant_predictors.iterrows():\n",
        "                    direction = \"higher\" if row['Difference'] > 0 else \"lower\"\n",
        "                    print(f\"   {row['Predictor']}: Group 1 {direction} than Group 2\")\n",
        "                    print(f\"    Difference: {row['Difference']:.4f} ({row['Percent_Change']:+.1f}%)\")\n",
        "                    print(\n",
        "                        f\"    p = {row['P_Value']:.6f}, d = {row['Effect_Size_d']:.4f} ({row['Effect_Interpretation']})\")\n",
        "\n",
        "            # Multiple comparison correction (Bonferroni)\n",
        "            n_tests = len(results_df)\n",
        "            bonferroni_alpha = 0.05 / n_tests\n",
        "            bonferroni_significant = results_df[results_df['P_Value'] < bonferroni_alpha]\n",
        "\n",
        "            print(f\"\\n=== MULTIPLE COMPARISON CORRECTION ===\")\n",
        "            print(f\"Bonferroni corrected  = 0.05/{n_tests} = {bonferroni_alpha:.6f}\")\n",
        "            print(f\"Significant after correction: {len(bonferroni_significant)}/{len(results_df)}\")\n",
        "\n",
        "            if len(bonferroni_significant) > 0:\n",
        "                print(\"\\nBonferroni-corrected significant findings:\")\n",
        "                for _, row in bonferroni_significant.iterrows():\n",
        "                    direction = \"higher\" if row['Difference'] > 0 else \"lower\"\n",
        "                    print(f\"   {row['Predictor']}: Group 1 {direction} than Group 2\")\n",
        "                    print(f\"    p = {row['P_Value']:.6f} < {bonferroni_alpha:.6f}\")\n",
        "\n",
        "            # Store results for later use\n",
        "            globals()['statistical_results'] = results_df\n",
        "            print(f\"\\nResults saved to 'statistical_results' DataFrame\")\n",
        "\n",
        "        return results_df"
      ],
      "metadata": {
        "id": "EegHuV9io6Vx"
      },
      "id": "EegHuV9io6Vx",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f8fc02f1-6c9d-49e6-bb0e-a79b5bcda76e",
      "metadata": {
        "id": "f8fc02f1-6c9d-49e6-bb0e-a79b5bcda76e",
        "outputId": "2dac7a8e-ef1e-4d68-fc28-cc8200e345e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing groups: 100%|| 2/2 [00:01<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "treatment: 2280\n",
            "Filtered control group: 1826 users, ~2280 total points\n",
            "Calculating group sizes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Counting utterances in groups: 100%|| 2/2 [00:00<00:00, 744.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Group 1: 2280 utterances\n",
            "Group 2: 2280 utterances\n",
            "\n",
            "Smallest group has 2280 utterances\n",
            "Setting target_utterances = 2280\n",
            "\n",
            "Sampling strategy:\n",
            "Group 1: 2280 total  2280 sampled (100.0%)\n",
            "Group 2: 2280 total  2280 sampled (100.0%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "groups_tuple = (groups['with_changes'], groups['no_changes'])\n",
        "groups_tuple = groups_preprocessor.filter_groups(groups, groups_tuple)\n",
        "target_utterances = groups_preprocessor.get_target(groups_tuple)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_utterances = 5"
      ],
      "metadata": {
        "id": "T-gb7Jolqf8W"
      },
      "id": "T-gb7Jolqf8W",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "668ebf37f0d3de52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "668ebf37f0d3de52",
        "outputId": "f2adfb97-88e0-4536-e8d0-5c412abbec26",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing groups:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window extraction: 0.000s\n",
            "Path extraction: 0.031s\n",
            "Preprocessing: 0.000s\n",
            "Utterance c4w912m: 31 paths -> 1 mean score\n",
            "Group 1: 1/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.040s\n",
            "\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.211s\n",
            "Preprocessing: 0.018s\n",
            "Utterance caqzidp: 293 paths -> 1 mean score\n",
            "Group 1: 2/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.779s\n",
            "\n",
            "Window extraction: 0.000s\n",
            "Skipping conversation 1jcj4v: Conversation failed integrity check. It is either missing an utterance in the reply-to chain and/or has multiple root nodes. Run check_integrity() to diagnose issues.\n",
            "Path extraction: 0.066s\n",
            "Preprocessing: 0.001s\n",
            "Utterance cbfq2p4: 44 paths -> 1 mean score\n",
            "Group 1: 3/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.087s\n",
            "\n",
            "USER HardCoreModerate: 0.906s (3 utterances)\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.024s\n",
            "Preprocessing: 0.002s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing groups: 100%|| 2/2 [00:01<00:00,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utterance c7i4p5r: 214 paths -> 1 mean score\n",
            "Group 1: 4/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.158s\n",
            "\n",
            "Window extraction: 0.001s\n",
            "Path extraction: 0.020s\n",
            "Preprocessing: 0.001s\n",
            "Utterance ccncxn3: 148 paths -> 1 mean score\n",
            "Group 1: 5/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.076s\n",
            "\n",
            "USER kingvitaman: 0.234s (2 utterances)\n",
            "\n",
            "Group 1 final sample sizes:\n",
            "  interplay: n=5\n",
            "  politeness: n=5\n",
            "  argument_complexity: n=5\n",
            "  evidence_markers: n=5\n",
            "  hedging: n=5\n",
            "Group 1: Processed exactly 5 utterances\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.001s\n",
            "Preprocessing: 0.001s\n",
            "Utterance ny6mh: 93 paths -> 1 mean score\n",
            "Group 2: 1/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.037s\n",
            "\n",
            "USER amade183: 0.037s (1 utterances)\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.000s\n",
            "Preprocessing: 0.000s\n",
            "Utterance o0395: 16 paths -> 1 mean score\n",
            "Group 2: 2/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.003s\n",
            "\n",
            "USER TheBromanticOne: 0.003s (1 utterances)\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.000s\n",
            "Preprocessing: 0.000s\n",
            "Utterance nzbhp: 9 paths -> 1 mean score\n",
            "Group 2: 3/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.004s\n",
            "\n",
            "USER endswithpizza: 0.004s (1 utterances)\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.000s\n",
            "Preprocessing: 0.000s\n",
            "Utterance o1qtw: 21 paths -> 1 mean score\n",
            "Group 2: 4/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.005s\n",
            "\n",
            "Window extraction: 0.000s\n",
            "Path extraction: 0.020s\n",
            "Preprocessing: 0.000s\n",
            "Utterance d5p51xn: 21 paths -> 1 mean score\n",
            "Group 2: 5/5 utterances processed\n",
            "Scoring: 0.000s\n",
            "TOTAL for utterance: 0.025s\n",
            "\n",
            "USER colbert_for_prez: 0.031s (2 utterances)\n",
            "\n",
            "Group 2 final sample sizes:\n",
            "  interplay: n=5\n",
            "  politeness: n=5\n",
            "  argument_complexity: n=5\n",
            "  evidence_markers: n=5\n",
            "  hedging: n=5\n",
            "Group 2: Processed exactly 5 utterances\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "stop_words_set = set(stopwords.words('english'))\n",
        "\n",
        "group_means = []\n",
        "group_scores = []\n",
        "\n",
        "\n",
        "# For each group\n",
        "for group_idx, group in enumerate(tqdm(groups_tuple, desc=\"Processing groups\")):\n",
        "    # Initialize dictionary for this group's scores (one score per utterance)\n",
        "    current_group_scores = {\n",
        "        'interplay': [],\n",
        "        'politeness': [],\n",
        "        'argument_complexity': [],\n",
        "        'evidence_markers': [],\n",
        "        'hedging': []\n",
        "    }\n",
        "\n",
        "    utterances_processed = 0\n",
        "    target_reached = False  # Flag to control all nested loops\n",
        "\n",
        "    for user_id, topic_timelines in group.items():\n",
        "        if target_reached:  # Check flag at user level\n",
        "            break\n",
        "\n",
        "        user_start_time = time.time()\n",
        "        user_change_points = 0\n",
        "\n",
        "        for topic_timeline in topic_timelines.values():\n",
        "            if target_reached:  # Check flag at topic level\n",
        "                break\n",
        "\n",
        "            for change_point in topic_timeline.keys():  # Each utterance/change point\n",
        "                if utterances_processed >= target_utterances:\n",
        "                    target_reached = True  # Set flag instead of just breaking\n",
        "                    break\n",
        "\n",
        "                # utts_num += 1\n",
        "                user_change_points += 1\n",
        "                utterances_processed += 1\n",
        "\n",
        "                # Window extraction\n",
        "                start_time = time.time()\n",
        "                try:\n",
        "                    candidate_convos = window_extractor.get_conversations_around_change_point(\n",
        "                        change_point=change_point, corpus=corpus, test=True\n",
        "                    )\n",
        "                    window_time = time.time() - start_time\n",
        "                    print(f'Window extraction: {window_time:.3f}s')\n",
        "                except ValueError as e:\n",
        "                    print(f\"Skipping change point {change_point}: {e}\")\n",
        "                    continue\n",
        "\n",
        "                # Path extraction\n",
        "                start_time = time.time()\n",
        "                timeout_duration = 0.25\n",
        "                op_path_pairs = []\n",
        "\n",
        "                for candidate_convo in candidate_convos:\n",
        "                    if time.time() - start_time > timeout_duration:\n",
        "                        print(f\"Path extraction timeout reached ({timeout_duration}s)\")\n",
        "                        break\n",
        "\n",
        "                    try:\n",
        "                        op_path_pairs.extend(op_path_pairer.extract_rooted_path_from_candidate_convos(\n",
        "                            [candidate_convo], user_id\n",
        "                        ))\n",
        "                    except ValueError as e:\n",
        "                        print(f\"Skipping conversation {candidate_convo.id}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                path_time = time.time() - start_time\n",
        "                print(f'Path extraction: {path_time:.3f}s')\n",
        "\n",
        "                # Preprocessing\n",
        "                start_time = time.time()\n",
        "                preprocessed_pairs = pair_preprocessor.concatenate_path_in_all_pairs(op_path_pairs)\n",
        "                preprocess_time = time.time() - start_time\n",
        "                print(f'Preprocessing: {preprocess_time:.3f}s')\n",
        "\n",
        "                # Feature extraction - collect ALL scores for this utterance\n",
        "                start_time = time.time()\n",
        "                utterance_interplay_scores = []\n",
        "                utterance_politeness_scores = []\n",
        "                utterance_complexity_scores = []\n",
        "                utterance_evidence_scores = []\n",
        "                utterance_hedging_scores = []\n",
        "\n",
        "                for op, paths in preprocessed_pairs:\n",
        "                    for k, concatenated_utts in paths.items():\n",
        "                        # Extract features\n",
        "                        interplay_features = persuasion_analyzer.calculate_interplay_features(\n",
        "                            op.text, concatenated_utts, stop_words_set\n",
        "                        )\n",
        "                        politeness_features = feature_extractor.get_politeness_features(concatenated_utts)\n",
        "                        complexity_features = feature_extractor.extract_argument_complexity_features(concatenated_utts)\n",
        "                        evidence_features = feature_extractor.extract_evidence_features(concatenated_utts)\n",
        "                        hedging_features = feature_extractor.extract_hedging_features(concatenated_utts)\n",
        "\n",
        "                        # Calculate scores\n",
        "                        interplay_score = persuasion_analyzer.calculate_persuasion_score(interplay_features)\n",
        "                        politeness_score = sum(politeness_features.values())\n",
        "                        complexity_score = feature_extractor.calculate_complexity_score(complexity_features)\n",
        "                        evidence_score = feature_extractor.calculate_evidence_score(evidence_features)\n",
        "                        hedging_score = feature_extractor.calculate_hedging_score_from_features(hedging_features)\n",
        "\n",
        "                        # Collect all scores for this utterance\n",
        "                        utterance_interplay_scores.append(interplay_score)\n",
        "                        utterance_politeness_scores.append(politeness_score)\n",
        "                        utterance_complexity_scores.append(complexity_score)\n",
        "                        utterance_evidence_scores.append(evidence_score)\n",
        "                        utterance_hedging_scores.append(hedging_score)\n",
        "\n",
        "                feature_time = time.time() - start_time\n",
        "\n",
        "                # Take mean across all paths for this single utterance\n",
        "                start_time = time.time()\n",
        "                if utterance_interplay_scores:  # Only if we have scores\n",
        "                    # One score per utterance (mean of all conversation paths)\n",
        "                    utterance_mean_interplay = np.mean(utterance_interplay_scores)\n",
        "                    utterance_mean_politeness = np.mean(utterance_politeness_scores)\n",
        "                    utterance_mean_complexity = np.mean(utterance_complexity_scores)\n",
        "                    utterance_mean_evidence = np.mean(utterance_evidence_scores)\n",
        "                    utterance_mean_hedging = np.mean(utterance_hedging_scores)\n",
        "\n",
        "                    # Add ONE score per utterance to group scores\n",
        "                    current_group_scores['interplay'].append(utterance_mean_interplay)\n",
        "                    current_group_scores['politeness'].append(utterance_mean_politeness)\n",
        "                    current_group_scores['argument_complexity'].append(utterance_mean_complexity)\n",
        "                    current_group_scores['evidence_markers'].append(utterance_mean_evidence)\n",
        "                    current_group_scores['hedging'].append(utterance_mean_hedging)\n",
        "\n",
        "                    print(f\"Utterance {change_point}: {len(utterance_interplay_scores)} paths -> 1 mean score\")\n",
        "                    print(f\"Group {group_idx + 1}: {utterances_processed}/{target_utterances} utterances processed\")\n",
        "                else:\n",
        "                    print(f\"Utterance {change_point}: No valid paths found, skipping\")\n",
        "\n",
        "                scoring_time = time.time() - start_time\n",
        "                print(f'Scoring: {scoring_time:.3f}s')\n",
        "\n",
        "                # Print total time for this change point\n",
        "                total_time = window_time + path_time + preprocess_time + feature_time + scoring_time\n",
        "                print(f'TOTAL for utterance: {total_time:.3f}s\\n')\n",
        "\n",
        "        user_total_time = time.time() - user_start_time\n",
        "        if user_change_points > 0:  # Only print if user had utterances\n",
        "            print(f'USER {user_id}: {user_total_time:.3f}s ({user_change_points} utterances)')\n",
        "\n",
        "    # Calculate means for each predictor for this group\n",
        "    group_mean = {}\n",
        "    for predictor_name, scores in current_group_scores.items():\n",
        "        if scores:\n",
        "            group_mean[predictor_name] = np.mean(scores)\n",
        "        else:\n",
        "            group_mean[predictor_name] = 0\n",
        "\n",
        "    print(f\"\\nGroup {group_idx + 1} final sample sizes:\")\n",
        "    for predictor_name, scores in current_group_scores.items():\n",
        "        print(f\"  {predictor_name}: n={len(scores)}\")\n",
        "\n",
        "    print(f\"Group {group_idx + 1}: Processed exactly {utterances_processed} utterances\")\n",
        "\n",
        "    group_means.append(group_mean)\n",
        "    group_scores.append(current_group_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "-01zn5RzLYD1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-01zn5RzLYD1",
        "outputId": "6c107261-9d98-446d-b5e3-8db4784e02df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== STATISTICAL SIGNIFICANCE TESTING ===\n",
            "\n",
            "Group 1 sample sizes: [5, 5, 5, 5, 5]\n",
            "Group 2 sample sizes: [5, 5, 5, 5, 5]\n",
            "\n",
            "=== INTERPLAY ===\n",
            "Group 1:  = 0.8026,  = 0.0481, n = 5\n",
            "Group 2:  = 0.8059,  = 0.0257, n = 5\n",
            "Difference: -0.0033 (-0.4%)\n",
            "Normality: G1=True, G2=True\n",
            "Equal variances: True\n",
            "Test used: Two-sample t-test (equal var)\n",
            "Test statistic: -0.1339\n",
            "p-value: 0.896825 \n",
            "Result: not significant\n",
            "Effect size (Cohen's d): -0.0847 (Negligible)\n",
            "--------------------------------------------------\n",
            "\n",
            "=== POLITENESS ===\n",
            "Group 1:  = 2.5522,  = 2.8822, n = 5\n",
            "Group 2:  = 1.0757,  = 0.7485, n = 5\n",
            "Difference: 1.4765 (+137.3%)\n",
            "Normality: G1=True, G2=True\n",
            "Equal variances: True\n",
            "Test used: Two-sample t-test (equal var)\n",
            "Test statistic: 1.1087\n",
            "p-value: 0.299764 \n",
            "Result: not significant\n",
            "Effect size (Cohen's d): 0.7012 (Medium)\n",
            "--------------------------------------------------\n",
            "\n",
            "=== ARGUMENT_COMPLEXITY ===\n",
            "Group 1:  = 0.9369,  = 0.1097, n = 5\n",
            "Group 2:  = 0.9909,  = 0.0187, n = 5\n",
            "Difference: -0.0540 (-5.4%)\n",
            "Normality: G1=True, G2=True\n",
            "Equal variances: True\n",
            "Test used: Two-sample t-test (equal var)\n",
            "Test statistic: -1.0848\n",
            "p-value: 0.309625 \n",
            "Result: not significant\n",
            "Effect size (Cohen's d): -0.6861 (Medium)\n",
            "--------------------------------------------------\n",
            "\n",
            "=== EVIDENCE_MARKERS ===\n",
            "Group 1:  = 0.8918,  = 1.0474, n = 5\n",
            "Group 2:  = 0.3546,  = 0.2743, n = 5\n",
            "Difference: 0.5372 (+151.5%)\n",
            "Normality: G1=True, G2=True\n",
            "Equal variances: True\n",
            "Test used: Two-sample t-test (equal var)\n",
            "Test statistic: 1.1094\n",
            "p-value: 0.299504 \n",
            "Result: not significant\n",
            "Effect size (Cohen's d): 0.7016 (Medium)\n",
            "--------------------------------------------------\n",
            "\n",
            "=== HEDGING ===\n",
            "Group 1:  = 0.0054,  = 0.0024, n = 5\n",
            "Group 2:  = 0.0056,  = 0.0050, n = 5\n",
            "Difference: -0.0002 (-2.9%)\n",
            "Normality: G1=True, G2=True\n",
            "Equal variances: True\n",
            "Test used: Two-sample t-test (equal var)\n",
            "Test statistic: -0.0649\n",
            "p-value: 0.949821 \n",
            "Result: not significant\n",
            "Effect size (Cohen's d): -0.0411 (Negligible)\n",
            "--------------------------------------------------\n",
            "\n",
            "=== SUMMARY TABLE ===\n",
            "          Predictor  Group_1_Mean  Group_2_Mean  Difference  P_Value Significance  Effect_Size_d Effect_Interpretation\n",
            "          interplay        0.8026        0.8059     -0.0033   0.8968                     -0.0847            Negligible\n",
            "         politeness        2.5522        1.0757      1.4765   0.2998                      0.7012                Medium\n",
            "argument_complexity        0.9369        0.9909     -0.0540   0.3096                     -0.6861                Medium\n",
            "   evidence_markers        0.8918        0.3546      0.5372   0.2995                      0.7016                Medium\n",
            "            hedging        0.0054        0.0056     -0.0002   0.9498                     -0.0411            Negligible\n",
            "\n",
            "=== OVERALL RESULTS ===\n",
            "Significant predictors (p < 0.05): 0/5\n",
            "\n",
            "=== MULTIPLE COMPARISON CORRECTION ===\n",
            "Bonferroni corrected  = 0.05/5 = 0.010000\n",
            "Significant after correction: 0/5\n",
            "\n",
            "Results saved to 'statistical_results' DataFrame\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Predictor  Group_1_Mean  Group_1_SD  Group_1_N  Group_2_Mean  \\\n",
              "0            interplay      0.802586    0.048109          5      0.805852   \n",
              "1           politeness      2.552196    2.882187          5      1.075698   \n",
              "2  argument_complexity      0.936922    0.109729          5      0.990922   \n",
              "3     evidence_markers      0.891782    1.047418          5      0.354608   \n",
              "4              hedging      0.005434    0.002426          5      0.005595   \n",
              "\n",
              "   Group_2_SD  Group_2_N  Difference  Percent_Change  \\\n",
              "0    0.025719          5   -0.003266       -0.405227   \n",
              "1    0.748486          5    1.476499      137.259638   \n",
              "2    0.018698          5   -0.054000       -5.449451   \n",
              "3    0.274310          5    0.537174      151.483756   \n",
              "4    0.005005          5   -0.000162       -2.886773   \n",
              "\n",
              "                       Test_Used  Test_Statistic   P_Value Significance  \\\n",
              "0  Two-sample t-test (equal var)       -0.133853  0.896825                \n",
              "1  Two-sample t-test (equal var)        1.108725  0.299764                \n",
              "2  Two-sample t-test (equal var)       -1.084779  0.309625                \n",
              "3  Two-sample t-test (equal var)        1.109366  0.299504                \n",
              "4  Two-sample t-test (equal var)       -0.064933  0.949821                \n",
              "\n",
              "   Effect_Size_d Effect_Interpretation  Significant  \n",
              "0      -0.084656            Negligible        False  \n",
              "1       0.701220                Medium        False  \n",
              "2      -0.686075                Medium        False  \n",
              "3       0.701625                Medium        False  \n",
              "4      -0.041067            Negligible        False  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa5b1406-1261-4eaf-b083-bed1806e68ed\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictor</th>\n",
              "      <th>Group_1_Mean</th>\n",
              "      <th>Group_1_SD</th>\n",
              "      <th>Group_1_N</th>\n",
              "      <th>Group_2_Mean</th>\n",
              "      <th>Group_2_SD</th>\n",
              "      <th>Group_2_N</th>\n",
              "      <th>Difference</th>\n",
              "      <th>Percent_Change</th>\n",
              "      <th>Test_Used</th>\n",
              "      <th>Test_Statistic</th>\n",
              "      <th>P_Value</th>\n",
              "      <th>Significance</th>\n",
              "      <th>Effect_Size_d</th>\n",
              "      <th>Effect_Interpretation</th>\n",
              "      <th>Significant</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>interplay</td>\n",
              "      <td>0.802586</td>\n",
              "      <td>0.048109</td>\n",
              "      <td>5</td>\n",
              "      <td>0.805852</td>\n",
              "      <td>0.025719</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.003266</td>\n",
              "      <td>-0.405227</td>\n",
              "      <td>Two-sample t-test (equal var)</td>\n",
              "      <td>-0.133853</td>\n",
              "      <td>0.896825</td>\n",
              "      <td></td>\n",
              "      <td>-0.084656</td>\n",
              "      <td>Negligible</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>politeness</td>\n",
              "      <td>2.552196</td>\n",
              "      <td>2.882187</td>\n",
              "      <td>5</td>\n",
              "      <td>1.075698</td>\n",
              "      <td>0.748486</td>\n",
              "      <td>5</td>\n",
              "      <td>1.476499</td>\n",
              "      <td>137.259638</td>\n",
              "      <td>Two-sample t-test (equal var)</td>\n",
              "      <td>1.108725</td>\n",
              "      <td>0.299764</td>\n",
              "      <td></td>\n",
              "      <td>0.701220</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>argument_complexity</td>\n",
              "      <td>0.936922</td>\n",
              "      <td>0.109729</td>\n",
              "      <td>5</td>\n",
              "      <td>0.990922</td>\n",
              "      <td>0.018698</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.054000</td>\n",
              "      <td>-5.449451</td>\n",
              "      <td>Two-sample t-test (equal var)</td>\n",
              "      <td>-1.084779</td>\n",
              "      <td>0.309625</td>\n",
              "      <td></td>\n",
              "      <td>-0.686075</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>evidence_markers</td>\n",
              "      <td>0.891782</td>\n",
              "      <td>1.047418</td>\n",
              "      <td>5</td>\n",
              "      <td>0.354608</td>\n",
              "      <td>0.274310</td>\n",
              "      <td>5</td>\n",
              "      <td>0.537174</td>\n",
              "      <td>151.483756</td>\n",
              "      <td>Two-sample t-test (equal var)</td>\n",
              "      <td>1.109366</td>\n",
              "      <td>0.299504</td>\n",
              "      <td></td>\n",
              "      <td>0.701625</td>\n",
              "      <td>Medium</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hedging</td>\n",
              "      <td>0.005434</td>\n",
              "      <td>0.002426</td>\n",
              "      <td>5</td>\n",
              "      <td>0.005595</td>\n",
              "      <td>0.005005</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.000162</td>\n",
              "      <td>-2.886773</td>\n",
              "      <td>Two-sample t-test (equal var)</td>\n",
              "      <td>-0.064933</td>\n",
              "      <td>0.949821</td>\n",
              "      <td></td>\n",
              "      <td>-0.041067</td>\n",
              "      <td>Negligible</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa5b1406-1261-4eaf-b083-bed1806e68ed')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa5b1406-1261-4eaf-b083-bed1806e68ed button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa5b1406-1261-4eaf-b083-bed1806e68ed');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2217bb79-2bc8-455f-aca7-a25cd72e0a7f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2217bb79-2bc8-455f-aca7-a25cd72e0a7f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2217bb79-2bc8-455f-aca7-a25cd72e0a7f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_8c48c9c0-664e-4abc-9de5-4ceea7a074d5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('statistical_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8c48c9c0-664e-4abc-9de5-4ceea7a074d5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('statistical_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "statistical_results",
              "summary": "{\n  \"name\": \"statistical_results\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Predictor\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"politeness\",\n          \"hedging\",\n          \"argument_complexity\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_1_Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.928170135047028,\n        \"min\": 0.005433790135913321,\n        \"max\": 2.5521963331387014,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.5521963331387014,\n          0.005433790135913321,\n          0.9369220909175461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_1_SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.232177210508603,\n        \"min\": 0.002426169390727405,\n        \"max\": 2.8821871175097287,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.8821871175097287,\n          0.002426169390727405,\n          0.1097287230645361\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_1_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_2_Mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45392446595320624,\n        \"min\": 0.005595314172891737,\n        \"max\": 1.0756976446492577,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.0756976446492577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_2_SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31881906267412674,\n        \"min\": 0.0050053432071715314,\n        \"max\": 0.7484855328624511,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.7484855328624511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Group_2_N\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 5,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Difference\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6530986498366375,\n        \"min\": -0.0539998008271082,\n        \"max\": 1.4764986884894438,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.4764986884894438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_Change\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 80.84787093087454,\n        \"min\": -5.449450786886353,\n        \"max\": 151.48375555771835,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          137.25963757881718\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Used\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Two-sample t-test (equal var)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Test_Statistic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9332972528542924,\n        \"min\": -1.0847790510167608,\n        \"max\": 1.1093658602912133,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1.1087254160936086\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P_Value\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3403250983178909,\n        \"min\": 0.2995039241249533,\n        \"max\": 0.9498208150835139,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.2997641709361457\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Significance\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Effect_Size_d\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5902690105995296,\n        \"min\": -0.6860745118497914,\n        \"max\": 0.7016245753904758,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.701219522914742\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Effect_Interpretation\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Medium\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Significant\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "groups_preprocessor.run_statistical_comparison(group_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bIXojYlryRqw",
      "metadata": {
        "id": "bIXojYlryRqw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}