{
 "cells": [
  {
   "cell_type": "code",
   "id": "ecbdb0ca-91d4-4a79-bb7e-107fbba420be",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Absolute path to src directory\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfca0265e767d",
   "metadata": {
    "id": "8ecfca0265e767d"
   },
   "outputs": [],
   "source": [
    "# Install convokit (Restart after)\n",
    "!pip install convokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9mcx9qMoUA68",
   "metadata": {
    "id": "9mcx9qMoUA68"
   },
   "outputs": [],
   "source": [
    "# For colab:\n",
    "import unsloth\n",
    "import unsloth_zoo\n",
    "from convokit import Corpus, download\n",
    "import convokit\n",
    "from temporal_belief.models.bart_classifier import BARTZeroShotClassifier\n",
    "from temporal_belief.utils.config import POLITICAL_TOPICS, ProjectConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vPF-AwIWUxJe",
   "metadata": {
    "id": "vPF-AwIWUxJe"
   },
   "outputs": [],
   "source": [
    "\"\"\"Topic detection functionality for conversation analysis.\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import List, Dict, Any, Optional\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TopicDetector:\n",
    "    \"\"\"Detect topics in ConvoKit conversations using BART.\"\"\"\n",
    "\n",
    "    def __init__(self, topics: Optional[List[str]] = None,\n",
    "                 config: ProjectConfig = None):\n",
    "        \"\"\"Initialize topic detector.\"\"\"\n",
    "        self.config = config or ProjectConfig()\n",
    "        self.classifier = BARTZeroShotClassifier(self.config.bart_model_name)\n",
    "        self.topics = topics or POLITICAL_TOPICS\n",
    "        logger.info(f\"Initialized topic detector with {len(self.topics)} topics\")\n",
    "\n",
    "    def detect_conversation_topic(self, conversation) -> Dict[str, Any]:\n",
    "        \"\"\"Detect topic for a single conversation.\"\"\"\n",
    "        utterances = list(conversation.iter_utterances())\n",
    "        \n",
    "        # Safe attribute access\n",
    "        title = conversation.meta.get('title', '')\n",
    "        \n",
    "        # Safe utterance handling\n",
    "        first_utterance = utterances[0] if utterances else None\n",
    "        original_post = first_utterance.text if first_utterance else ''\n",
    "        \n",
    "        if not original_post and not title:\n",
    "            logger.warning(f\"No utterances or title found in conversation {conversation.id}\")\n",
    "            return {\"topic\": \"unknown\", \"confidence\": 0.0}\n",
    "\n",
    "        # Truncate long texts to prevent memory issues\n",
    "        combined_text = f\"Title: {title}. Original Post: {original_post}\"[:2000]\n",
    "        result = self.classifier.classify_text(combined_text, self.topics)\n",
    "\n",
    "        return {\n",
    "            \"topic\": result[\"label\"],\n",
    "            \"confidence\": result[\"confidence\"],\n",
    "            \"all_scores\": result[\"all_scores\"],\n",
    "            \"text_length\": len(original_post),\n",
    "            \"num_utterances\": len(utterances)\n",
    "        }\n",
    "\n",
    "    def process_corpus(self, corpus, batch_size: int = 50,  # Balanced batch size\n",
    "                    save_path: Optional[str] = None) -> None:\n",
    "        \"\"\"Process entire corpus for topic detection.\"\"\"\n",
    "        conversations = list(corpus.iter_conversations())\n",
    "        logger.info(f\"Processing {len(conversations)} conversations for topic detection\")\n",
    "\n",
    "        for i in tqdm(range(0, len(conversations), batch_size),\n",
    "                      desc=\"Processing conversations\"):\n",
    "            batch = conversations[i:i + batch_size]\n",
    "\n",
    "            # Prepare all texts for batch processing\n",
    "            batch_texts = []\n",
    "            valid_conversations = []\n",
    "\n",
    "            for conv in batch:\n",
    "                try:\n",
    "                    # Safe attribute access\n",
    "                    title = conv.meta.get('title', '')\n",
    "                    utterances = list(conv.iter_utterances())\n",
    "                    \n",
    "                    # Safe utterance handling\n",
    "                    first_utterance = utterances[0] if utterances else None\n",
    "                    original_post = first_utterance.text if first_utterance else ''\n",
    "                    \n",
    "                    if not original_post and not title:\n",
    "                        logger.warning(f\"No utterances or title found in conversation {conv.id}\")\n",
    "                        # Set metadata for empty conversations\n",
    "                        conv.add_meta(\"detected_topic\", \"unknown\")\n",
    "                        conv.add_meta(\"topic_confidence\", 0.0)\n",
    "                        conv.add_meta(\"topic_scores\", {})\n",
    "                        continue\n",
    "\n",
    "                    # Truncate long texts\n",
    "                    combined_text = f\"{title}. {original_post}\"[:2000]\n",
    "                    batch_texts.append(combined_text)\n",
    "                    valid_conversations.append(conv)\n",
    "\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to prepare conversation {conv.id}: {e}\")\n",
    "                    conv.add_meta(\"detected_topic\", \"unknown\")\n",
    "                    conv.add_meta(\"topic_confidence\", 0.0)\n",
    "                    conv.add_meta(\"topic_scores\", {})\n",
    "\n",
    "            # Process entire batch at once\n",
    "            if batch_texts:\n",
    "                try:\n",
    "                    print(f\"üöÄ Attempting batch of {len(batch_texts)} texts...\")\n",
    "                    import time\n",
    "                    start = time.time()\n",
    "                    \n",
    "                    batch_results = self.classifier.classify_batch(batch_texts, self.topics)\n",
    "                    \n",
    "                    end = time.time()\n",
    "                    print(f\"‚úÖ Batch completed in {end-start:.2f}s ({(end-start)/len(batch_texts):.3f}s per text)\")\n",
    "\n",
    "                    # Apply results back to conversations\n",
    "                    for conv, result in zip(valid_conversations, batch_results):\n",
    "                        conv.add_meta(\"detected_topic\", result[\"label\"])\n",
    "                        conv.add_meta(\"topic_confidence\", result[\"confidence\"])\n",
    "                        conv.add_meta(\"topic_scores\", result[\"all_scores\"])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Batch processing failed: {e}\")\n",
    "                    logger.error(f\"Batch classification failed: {e}\")\n",
    "                    \n",
    "                    # Fallback to individual processing\n",
    "                    for conv in valid_conversations:\n",
    "                        try:\n",
    "                            topic_result = self.detect_conversation_topic(conv)\n",
    "                            conv.add_meta(\"detected_topic\", topic_result[\"topic\"])\n",
    "                            conv.add_meta(\"topic_confidence\", topic_result[\"confidence\"])\n",
    "                            conv.add_meta(\"topic_scores\", topic_result[\"all_scores\"])\n",
    "                        except Exception as e2:\n",
    "                            logger.error(f\"Individual fallback failed for {conv.id}: {e2}\")\n",
    "                            conv.add_meta(\"detected_topic\", \"unknown\")\n",
    "                            conv.add_meta(\"topic_confidence\", 0.0)\n",
    "                            conv.add_meta(\"topic_scores\", {})\n",
    "\n",
    "        if save_path:\n",
    "            corpus.dump(save_path)\n",
    "            logger.info(f\"Saved processed corpus to {save_path}\")\n",
    "\n",
    "        logger.info(\"Topic detection processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K8oYk7YLM_oW",
   "metadata": {
    "id": "K8oYk7YLM_oW"
   },
   "outputs": [],
   "source": [
    "# Testing 'process_corpus()'\n",
    "SAVE_PATH = \"/workspace/temporal_belief_analysis/pd_corpus_with_topics2\"\n",
    "topic_detector = TopicDetector()\n",
    "topic_detector.process_corpus(corpus, save_path=SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bad1190-19c0-48fc-ab44-70e17f93aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_small.dump(\"/workspace/temporal_belief_analysis/corpus_small_save_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38623a2c-6af8-4edd-b2f7-044708597fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if metadata gets added\n",
    "conversations = list(corpus.iter_conversations())\n",
    "\n",
    "# Check first conversation\n",
    "first_conv = conversations[1]\n",
    "print(f\"First conversation ID: {first_conv.id}\")\n",
    "print(f\"Has topic metadata: {'detected_topic' in first_conv.meta}\")\n",
    "if 'detected_topic' in first_conv.meta:\n",
    "    print(f\"Topic: {first_conv.meta['detected_topic']}\")\n",
    "    print(f\"Confidence: {first_conv.meta['topic_confidence']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PxXbHWRrMbDK",
   "metadata": {
    "id": "PxXbHWRrMbDK"
   },
   "outputs": [],
   "source": [
    "# Testing 'detect_conversation_topic()' and 'dump()'\n",
    "corpus_small = Corpus(filename=download(\"reddit-corpus-small\"))\n",
    "\n",
    "i = 0\n",
    "convos_small = list(corpus_small.iter_conversations())\n",
    "topic_detector = TopicDetector()\n",
    "for i in range(3):\n",
    "  utterances = list(convos_small[i].iter_utterances())\n",
    "  title = convos_small[i].meta['title']\n",
    "  og_post = utterances[0].text\n",
    "  # print(100*'-')\n",
    "  # print(f\"Title: {title} \\n\")\n",
    "  # print(f\"OG post: {og_post} \\n\")\n",
    "  topic = topic_detector.detect_conversation_topic(convos_small[i])\n",
    "  # print(f\"Detected topic: {topic['topic']} \\n\")\n",
    "  # print(f\"Confidence: {topic['confidence']} \\n\")\n",
    "  convos_small[i].add_meta(\"detected_topic\", topic[\"topic\"])\n",
    "  convos_small[i].add_meta(\"topic_confidence\", topic[\"confidence\"])\n",
    "  convos_small[i].add_meta(\"topic_scores\", topic[\"all_scores\"])\n",
    "  i += 1\n",
    "\n",
    "# corpus_small.dump_info(obj_type=\"corpus\", fields=[\"meta\"])\n",
    "corpus_small.dump(\"/workspace/temporal_belief_analysis/processed_corpus_small_other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "695b3110-8e5f-4bec-a37b-6bf1390a40fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = Corpus(filename=\"/workspace/temporal_belief_analysis/processed_corpus_small_other\")\n",
    "\n",
    "# processed_convos = list(processed_corpus.iter_conversations())\n",
    "# convos_small = list(corpus_small.iter_conversations())\n",
    "# print(f'Processed: {processed_convos[0].meta}\\n')\n",
    "# print(f'Not processed: {convos_small[0].meta}')\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c647fd0e-e52d-49b3-be3e-2514a1100377",
   "metadata": {},
   "source": [
    "corpus_with_topics = Corpus(filename=\"/workspace/temporal_belief_analysis/pd_corpus_with_topics2\")\n",
    "# convos_with_topics = list(processed_corpus.iter_conversations())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea46bc4-7644-4834-bd6f-21fc055cda23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
