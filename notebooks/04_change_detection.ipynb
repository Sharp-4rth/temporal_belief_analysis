{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:09:51.278612Z",
          "start_time": "2025-07-14T08:08:08.657634Z"
        },
        "id": "bbad0be784b4869a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c58a941-9a83-4b84-8a66-ec9ea4c7b02a"
      },
      "cell_type": "code",
      "source": [
        "# Need to restart after:\n",
        "!pip install convokit"
      ],
      "id": "bbad0be784b4869a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit\n",
            "  Downloading convokit-3.3.0.tar.gz (206 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/206.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m143.4/206.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.2/206.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.10.0)\n",
            "Requirement already satisfied: scipy>1.14 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.16.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.2.2)\n",
            "Requirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.0.2)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: spacy>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.8.7)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.9.1)\n",
            "Requirement already satisfied: dill>=0.2.9 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.3.8)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.5.1)\n",
            "Collecting clean-text>=0.6.0 (from convokit)\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (4.67.1)\n",
            "Collecting pymongo>=4.0 (from convokit)\n",
            "  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from convokit) (6.0.2)\n",
            "Collecting dnspython>=1.16.0 (from convokit)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (8.3.6)\n",
            "Collecting h5py==3.12.1 (from convokit)\n",
            "  Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: numexpr>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.11.0)\n",
            "Requirement already satisfied: ruff>=0.4.8 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.12.5)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from convokit) (1.4.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from convokit) (1.9.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from convokit) (0.16.0)\n",
            "Collecting bitsandbytes (from convokit)\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from convokit) (4.54.0)\n",
            "Collecting unsloth (from convokit)\n",
            "  Downloading unsloth-2025.8.1-py3-none-any.whl.metadata (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trl>=0.12.2 (from convokit)\n",
            "  Downloading trl-0.20.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.18.0)\n",
            "Requirement already satisfied: tf-keras<3.0.0,>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.18.0)\n",
            "Collecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (2.9.0.post0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.4->convokit) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.4->convokit) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->convokit) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.8.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.37.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl>=0.12.2->convokit) (4.0.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (0.34.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->convokit) (3.18.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->convokit) (0.21.2)\n",
            "Collecting unsloth_zoo>=2025.8.1 (from unsloth->convokit)\n",
            "  Downloading unsloth_zoo-2025.8.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth->convokit)\n",
            "  Downloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (3.2.0)\n",
            "Collecting tyro (from unsloth->convokit)\n",
            "  Downloading tyro-0.9.27-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets>=3.0.0 (from trl>=0.12.2->convokit)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.45.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.34.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (18.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2025.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate->convokit) (1.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (3.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (3.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate->convokit) (1.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.8.1->unsloth->convokit)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.8.1->unsloth->convokit)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (7.3.0.post1)\n",
            "Collecting torch>=2.0.0 (from accelerate->convokit)\n",
            "  Downloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.0.0->accelerate->convokit)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth->convokit)\n",
            "  Downloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth->convokit) (8.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.8.2->convokit) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth->convokit)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth->convokit) (0.17.0)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth->convokit)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth->convokit) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (3.12.14)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (2.19.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth->convokit) (3.23.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.1.2)\n",
            "Downloading h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.20.0-py3-none-any.whl (504 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m504.6/504.6 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.8.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.8/299.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.8.1-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.31.post1-cp39-abi3-manylinux_2_28_x86_64.whl (117.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.1-cp311-cp311-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m141.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.27-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.3.0-py3-none-any.whl size=244589 sha256=9635d5c39b581e1b2812157ac4cf87b867b408c649a1f69916266f4594519de1\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/3e/be/94bc7971d7d693926eb00d2c566b746770870f70d7c1680650\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=418d9d78ad92d867e20376da7da44464e66d9699dc46fd091d89994c02180f32\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/22/e5/b69726d5e1a19795ecd3b3e7464b16c0f1d019aa94ff1c8578\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: nvidia-cusparselt-cu12, emoji, unidecode, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, msgpack-numpy, h5py, ftfy, dnspython, pymongo, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, clean-text, tyro, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth, convokit\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.14.0\n",
            "    Uninstalling h5py-3.14.0:\n",
            "      Successfully uninstalled h5py-3.14.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.46.1 clean-text-0.6.0 convokit-3.3.0 cut_cross_entropy-25.1.1 datasets-3.6.0 dnspython-2.7.0 emoji-1.7.0 ftfy-6.3.1 h5py-3.12.1 msgpack-numpy-0.4.8 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 pymongo-4.13.2 shtab-1.7.2 sympy-1.14.0 torch-2.7.1 torchvision-0.22.1 triton-3.3.1 trl-0.20.0 tyro-0.9.27 unidecode-1.4.0 unsloth-2025.8.1 unsloth_zoo-2025.8.1 xformers-0.0.31.post1\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# Download file from Google Drive to colab directory\n",
        "!pip install gdown\n",
        "file_id = \"1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\"\n",
        "!gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\" --fuzzy"
      ],
      "metadata": {
        "id": "oJ1WKmwwZQYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e73a1a0a-04f3-4a8c-e193-2e99318960e6"
      },
      "id": "oJ1WKmwwZQYL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\n",
            "From (redirected): https://drive.google.com/uc?id=1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0&confirm=t&uuid=178229c8-aeb6-45c5-8810-6afadafc769c\n",
            "To: /content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\n",
            "100% 841M/841M [00:07<00:00, 112MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip with python:\n",
        "import zipfile\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")"
      ],
      "metadata": {
        "id": "B2PlEx8QYzgg"
      },
      "id": "B2PlEx8QYzgg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For runpod-jupyter or local (run twice)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Change to the correct working directory (workspace if runpod, content if colab)\n",
        "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
        "print(\"Changed working directory to:\", os.getcwd())\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Comment out if in colab:\n",
        "from temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "_yv_LVXGjggY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add1a663-a877-4561-ac6e-9a5c03a0f402"
      },
      "id": "_yv_LVXGjggY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from temporal_belief_analysis.src.temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "3sIZWUc9i5WL"
      },
      "id": "3sIZWUc9i5WL",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22220bf09f61753c",
        "outputId": "a0e5eda6-2792-45d5-f0f8-557f93197a25"
      },
      "cell_type": "code",
      "source": [
        "# Run twice\n",
        "# import unsloth\n",
        "# import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit"
      ],
      "id": "22220bf09f61753c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error from Unsloth: NotImplementedError: Unsloth currently only works on NVIDIA GPUs and Intel GPUs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/convokit/utterance_simulator/unslothUtteranceSimulatorModel.py:2: UserWarning: WARNING: Unsloth should be imported before transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
            "\n",
            "Please restructure your imports with 'import unsloth' at the top of your file.\n",
            "  import unsloth\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "781d4e0509ad3c21",
        "outputId": "60a0b792-c22e-4ce7-9b35-672030de3499"
      },
      "cell_type": "code",
      "source": [
        "# Load a corpus:\n",
        "# corpus = Corpus(filename=\"/Users/leonidas/.convokit/saved-corpora/pd_corpus_with_stances1000_chronological\")\n",
        "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological\")"
      ],
      "id": "781d4e0509ad3c21",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "model_directory: ~/.convokit/saved-models\n",
            "default_backend: mem\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:17:28.390010Z",
          "start_time": "2025-07-14T08:17:20.788691Z"
        },
        "id": "ad611eb7998835c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install statsmodels"
      ],
      "id": "ad611eb7998835c2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.170080Z",
          "start_time": "2025-07-14T10:26:41.164333Z"
        },
        "id": "de0d75b2335f7dce"
      },
      "cell_type": "code",
      "source": [
        "def filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2, min_confidence=0.0):\n",
        "    \"\"\"Filter timelines to only include users/topics suitable for change detection\"\"\"\n",
        "    filtered_timelines = {}\n",
        "\n",
        "    for user_id, user_timeline in timelines.items():\n",
        "        filtered_user_timeline = {}\n",
        "\n",
        "        for topic, topic_posts in user_timeline.items():\n",
        "            # Filter by confidence (if you have access to corpus here)\n",
        "            reliable_posts = {}\n",
        "            for utt_id, stance in topic_posts.items():\n",
        "                # You'd need to pass corpus or confidence scores here\n",
        "                # For now, assume all posts are reliable\n",
        "                reliable_posts[utt_id] = stance\n",
        "\n",
        "            # Check minimum posts per topic\n",
        "            if len(reliable_posts) >= min_posts_per_topic:\n",
        "                filtered_user_timeline[topic] = reliable_posts\n",
        "\n",
        "        # Check minimum topics per user\n",
        "        if len(filtered_user_timeline) >= min_topics_per_user:\n",
        "            filtered_timelines[user_id] = filtered_user_timeline\n",
        "\n",
        "    return filtered_timelines"
      ],
      "id": "de0d75b2335f7dce",
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationWindowExtractor:\n",
        "    def __init__(self, corpus, timelines):\n",
        "        self.corpus = corpus\n",
        "        self.timelines = timelines\n",
        "\n",
        "    def get_user_conversations_chronological(self, corpus, speaker_id):\n",
        "      \"\"\"Get all conversations for a user in chronological order.\"\"\"\n",
        "\n",
        "      # Get all conversations where the speaker participated\n",
        "      user_conversations = [convo for convo in corpus.iter_conversations()\n",
        "                          if speaker_id in [utt.speaker.id for utt in convo.iter_utterances()]]\n",
        "\n",
        "      # Sort conversations by their earliest timestamp\n",
        "      user_conversations.sort(key=lambda convo: min(utt.timestamp for utt in convo.iter_utterances()))\n",
        "\n",
        "      return user_conversations\n",
        "\n",
        "    def get_conversation_around_change_point(self, corpus, change_points):\n",
        "      prior_convos = []\n",
        "\n",
        "      # Get utterance by ID, then get its speaker ID\n",
        "      utterance = corpus.get_utterance(change_points[0][1])\n",
        "      speaker_id = utterance.speaker.id\n",
        "\n",
        "      # put conversations in chronological order in a list\n",
        "      user_conversations = self.get_user_conversations_chronological(corpus, speaker_id)\n",
        "\n",
        "      # get conversation id from utterance\n",
        "      conversation = corpus.get_conversation(conversation_id)\n",
        "      conversation_id = conversation.id\n",
        "\n",
        "      # find the index of the convo, and return the convo id of the 3 prior convos\n",
        "      for i, convo in enumerate(user_conversations):\n",
        "        if conversation_id == user_conversations[i].id:\n",
        "          prior_convos.append(user_conversations[i-2])\n",
        "          prior_convos.append(user_conversations[i-1])\n",
        "\n",
        "      prior_convos.append(conversation_id)\n",
        "\n",
        "      return prior_convos\n",
        "\n",
        "    def get_conversations_around_change(self, user_id, topic, change, window_size=3):\n",
        "        \"\"\"\n",
        "        Get conversations before/after a belief change based on conversation count\n",
        "\n",
        "        Args:\n",
        "            user_id: The user who had the belief change\n",
        "            topic: The topic where change occurred\n",
        "            change: The significant change object from detect_changes_with_significance()\n",
        "            window_size: Number of conversations before AND after change to include\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                'before_change': [conversation_data, ...],\n",
        "                'after_change': [conversation_data, ...],\n",
        "                'change_position': int,\n",
        "                'change_utterance_id': str\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # Get ordered timeline for this user/topic\n",
        "        topic_timeline = self.timelines[user_id][topic]\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "\n",
        "        # Find position of the change utterance\n",
        "        change_utterance_id = change['utterance_id']\n",
        "        change_position = None\n",
        "\n",
        "        for i, (utterance_id, stance) in enumerate(timeline_items):\n",
        "            if utterance_id == change_utterance_id:\n",
        "                change_position = i\n",
        "                break\n",
        "\n",
        "        if change_position is None:\n",
        "            print(f\"Warning: Change utterance {change_utterance_id} not found in timeline\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Found change at position {change_position} of {len(timeline_items)} total utterances\")\n",
        "\n",
        "        # Extract conversations in window\n",
        "        before_conversations = []\n",
        "        after_conversations = []\n",
        "\n",
        "        # Get conversations BEFORE change\n",
        "        start_before = max(0, change_position - window_size)\n",
        "        print(f\"Looking for conversations before change: positions {start_before} to {change_position-1}\")\n",
        "\n",
        "        for i in range(start_before, change_position):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                before_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation before: {conv_data['conversation_id']}\")\n",
        "\n",
        "        # Get conversations AFTER change\n",
        "        end_after = min(len(timeline_items), change_position + window_size + 1)\n",
        "        print(f\"Looking for conversations after change: positions {change_position+1} to {end_after-1}\")\n",
        "\n",
        "        for i in range(change_position + 1, end_after):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                after_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation after: {conv_data['conversation_id']}\")\n",
        "\n",
        "        return {\n",
        "            'before_change': before_conversations,\n",
        "            'after_change': after_conversations,\n",
        "            'change_position': change_position,\n",
        "            'change_utterance_id': change_utterance_id,\n",
        "            'total_timeline_length': len(timeline_items),\n",
        "            'window_size': window_size\n",
        "        }\n",
        "\n",
        "    def _extract_conversation_from_utterance(self, utterance_id, user_id):\n",
        "        \"\"\"Extract conversation data from a specific utterance\"\"\"\n",
        "        try:\n",
        "            utterance = self.corpus.get_utterance(utterance_id)\n",
        "            if not utterance:\n",
        "                return None\n",
        "\n",
        "            conversation = utterance.get_conversation()\n",
        "            if not conversation:\n",
        "                return None\n",
        "\n",
        "            op_post = conversation.get_root()\n",
        "            if not op_post:\n",
        "                return None\n",
        "\n",
        "            user_replies = []\n",
        "\n",
        "            # Get ALL user replies in this conversation (not just the target utterance)\n",
        "            for utt in conversation.iter_utterances():\n",
        "                if utt.speaker.id == user_id and utt.id != op_post.id:\n",
        "                    user_replies.append(utt)\n",
        "\n",
        "            if not user_replies:\n",
        "                return None\n",
        "\n",
        "            return {\n",
        "                'conversation_id': conversation.id,\n",
        "                'op_post': op_post,\n",
        "                'user_replies': user_replies,\n",
        "                'target_utterance_id': utterance_id,  # Which utterance led us to this conversation\n",
        "                'topic': conversation.meta.get('detected_topic', 'unknown') if conversation.meta else 'unknown'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting conversation for utterance {utterance_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_rooted_path_units_from_window(self, window_data):\n",
        "        \"\"\"\n",
        "        Extract rooted path units from conversations around a belief change.\n",
        "        Uses your existing conversation extraction approach.\n",
        "        \"\"\"\n",
        "        def process_conversations(conversations):\n",
        "            processed = []\n",
        "\n",
        "            for conv_data in conversations:\n",
        "                # Use the conversation you ALREADY extracted in your working method\n",
        "                conversation = conv_data['op_post'].get_conversation()  # Your existing approach\n",
        "\n",
        "                if not conversation:\n",
        "                    continue\n",
        "\n",
        "                # Extract rooted path units for this conversation\n",
        "                rooted_units = self._extract_rooted_units_from_conversation(conversation)\n",
        "\n",
        "                # Get OP text\n",
        "                op_text = conv_data['op_post'].text if conv_data['op_post'] else \"\"\n",
        "\n",
        "                processed.append({\n",
        "                    'conversation_id': conv_data['conversation_id'],\n",
        "                    'rooted_units': rooted_units,\n",
        "                    'op_text': op_text,\n",
        "                    'topic': conv_data.get('topic', 'unknown'),\n",
        "                    'original_conv_data': conv_data\n",
        "                })\n",
        "\n",
        "            return processed\n",
        "\n",
        "        return {\n",
        "            'before_change': process_conversations(window_data['before_change']),\n",
        "            'after_change': process_conversations(window_data['after_change']),\n",
        "            'change_info': {\n",
        "                'change_position': window_data['change_position'],\n",
        "                'change_utterance_id': window_data['change_utterance_id']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _extract_rooted_units_from_conversation(self, conversation):\n",
        "        \"\"\"\n",
        "        Extract rooted path units from a single conversation.\n",
        "        Every speaker gets their own rooted path unit.\n",
        "\n",
        "        Returns:\n",
        "            dict: {speaker_id: [list_of_utterances]}\n",
        "        \"\"\"\n",
        "        rooted_units = {}\n",
        "\n",
        "        for utterance in conversation.iter_utterances():\n",
        "            speaker_id = utterance.speaker.id\n",
        "\n",
        "            if speaker_id not in rooted_units:\n",
        "                rooted_units[speaker_id] = []\n",
        "\n",
        "            rooted_units[speaker_id].append(utterance)\n",
        "\n",
        "        return rooted_units\n",
        "\n",
        "    def preprocess_rooted_units_for_interplay(self, rooted_units_data):\n",
        "        \"\"\"\n",
        "        Preprocess rooted path units for linguistic interplay calculation.\n",
        "\n",
        "        Args:\n",
        "            rooted_units_data: Output from extract_rooted_path_units_from_window()\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                'before_change': [\n",
        "                    {\n",
        "                        'conversation_id': str,\n",
        "                        'interplay_pairs': [\n",
        "                            {\n",
        "                                'speaker_id': str,\n",
        "                                'unit_text': str,  # Combined text of all speaker's utterances\n",
        "                                'op_text': str,    # Original post text\n",
        "                                'num_utterances': int\n",
        "                            }, ...\n",
        "                        ]\n",
        "                    }, ...\n",
        "                ],\n",
        "                'after_change': [...] # same structure\n",
        "            }\n",
        "        \"\"\"\n",
        "        def process_rooted_units(conversations_with_units):\n",
        "            processed = []\n",
        "\n",
        "            for conv_data in conversations_with_units:\n",
        "                interplay_pairs = []\n",
        "\n",
        "                for speaker_id, utterances in conv_data['rooted_units'].items():\n",
        "                    # Combine all utterances from this speaker\n",
        "                    unit_text = self._combine_utterances_text(utterances)\n",
        "\n",
        "                    interplay_pairs.append({\n",
        "                        'speaker_id': speaker_id,\n",
        "                        'unit_text': unit_text,\n",
        "                        'op_text': conv_data['op_text'],\n",
        "                        'num_utterances': len(utterances)\n",
        "                    })\n",
        "\n",
        "                processed.append({\n",
        "                    'conversation_id': conv_data['conversation_id'],\n",
        "                    'topic': conv_data['topic'],\n",
        "                    'interplay_pairs': interplay_pairs\n",
        "                })\n",
        "\n",
        "            return processed\n",
        "\n",
        "        return {\n",
        "            'before_change': process_rooted_units(rooted_units_data['before_change']),\n",
        "            'after_change': process_rooted_units(rooted_units_data['after_change']),\n",
        "            'change_info': rooted_units_data['change_info']\n",
        "        }\n",
        "\n",
        "    def _combine_utterances_text(self, utterances):\n",
        "        \"\"\"\n",
        "        Combine all utterances from a speaker into one text block.\n",
        "\n",
        "        Args:\n",
        "            utterances: List of ConvoKit utterances\n",
        "\n",
        "        Returns:\n",
        "            str: Combined text\n",
        "        \"\"\"\n",
        "        return \" \".join([utt.text for utt in utterances])\n",
        "\n",
        "\n",
        "    def print_window_summary(self, window_data):\n",
        "        \"\"\"Helper method to print a summary of extracted conversations\"\"\"\n",
        "        if not window_data:\n",
        "            print(\"No window data to summarize\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n=== Conversation Window Summary ===\")\n",
        "        print(f\"Change occurred at position {window_data['change_position']} of {window_data['total_timeline_length']} utterances\")\n",
        "        print(f\"Change utterance ID: {window_data['change_utterance_id']}\")\n",
        "        print(f\"Window size: {window_data.get('window_size', 'unknown')}\")\n",
        "\n",
        "        print(f\"\\nConversations BEFORE change: {len(window_data['before_change'])}\")\n",
        "        for i, conv in enumerate(window_data['before_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")\n",
        "\n",
        "        print(f\"\\nConversations AFTER change: {len(window_data['after_change'])}\")\n",
        "        for i, conv in enumerate(window_data['after_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")"
      ],
      "metadata": {
        "id": "zj51bpjrpjTd"
      },
      "id": "zj51bpjrpjTd",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.492540Z",
          "start_time": "2025-07-14T10:26:41.473273Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "from statsmodels.stats.multitest import fdrcorrection\n",
        "from collections import Counter\n",
        "import logging\n",
        "\n",
        "class ChangeDetector:\n",
        "    \"\"\"Sliding window change detection with proper statistical significance.\"\"\"\n",
        "\n",
        "    def __init__(self, window_size=3, significance_level=0.05):\n",
        "        self.window_size = window_size\n",
        "        self.alpha = significance_level\n",
        "        self.stance_values = {\n",
        "            'strongly_against': -2, 'moderately_against': -1,\n",
        "            'neutral': 0, 'moderately_favor': 1, 'strongly_favor': 2\n",
        "        }\n",
        "\n",
        "    def detect_simple_stance_changes(self, topic_timeline):\n",
        "\n",
        "        if len(topic_timeline) < 2:\n",
        "            return []\n",
        "\n",
        "        changes = []\n",
        "        timeline_items = list(topic_timeline.items())  # Convert to list of (utterance_id, stance) pairs\n",
        "\n",
        "        for i in range(1, len(timeline_items)):\n",
        "            current_utterance_id, current_stance = timeline_items[i]\n",
        "            previous_utterance_id, previous_stance = timeline_items[i-1]\n",
        "\n",
        "            # Check if stance changed\n",
        "            if current_stance != previous_stance:\n",
        "                change = {\n",
        "                    'position': i,\n",
        "                    'current_utterance_id': current_utterance_id,\n",
        "                    'previous_utterance_id': previous_utterance_id,\n",
        "                    'from_stance': previous_stance,\n",
        "                    'to_stance': current_stance,\n",
        "                    'change_type': self._classify_change_direction(previous_stance, current_stance),\n",
        "                    'change_magnitude': self._calculate_simple_magnitude(previous_stance, current_stance)\n",
        "                }\n",
        "                changes.append(change)\n",
        "\n",
        "        return changes\n",
        "\n",
        "    def detect_persistent_changes(self, topic_timeline):\n",
        "        \"\"\"Detect persistent changes in stance.\"\"\"\n",
        "\n",
        "        # Convert to (utt_id, detected_stance) tuple\n",
        "        topic_timeline_list = list(topic_timeline.items())\n",
        "\n",
        "        # Collect the tuples where the stance is persistent across n utterances\n",
        "        change_points = []\n",
        "\n",
        "        for i in range(len(topic_timeline)):\n",
        "          # if current stance is different than prior\n",
        "          if topic_timeline[i][1] != topic_timeline[i-1][1]:\n",
        "            # Check if change persists for more than 1 post\n",
        "            if topic_timeline[i][1] == topic_timeline[i+1][1]:\n",
        "              change_index = i\n",
        "              utt_id = topic_timeline[i][0]\n",
        "              change_point = (change_index, utt_id)\n",
        "              change_points.append(change_point)\n",
        "              print(f\"Current:{topic_timeline[i][1]}, Previous: {topic_timeline[i-1][1]} and Next:{topic_timeline[i+1][1]}\")\n",
        "              # remove break\n",
        "              break\n",
        "\n",
        "        return change_points\n",
        "\n",
        "    def _classify_change_direction(self, from_stance, to_stance):\n",
        "        \"\"\"Classify the direction of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "\n",
        "        if to_value > from_value:\n",
        "            return 'more_favorable'\n",
        "        elif to_value < from_value:\n",
        "            return 'less_favorable'\n",
        "        else:\n",
        "            return 'neutral_shift'\n",
        "\n",
        "    def _calculate_simple_magnitude(self, from_stance, to_stance):\n",
        "        \"\"\"Calculate the magnitude of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "        return abs(to_value - from_value)\n",
        "\n",
        "    def detect_changes_with_significance(self, topic_timeline):\n",
        "        \"\"\"Detect changes with statistical significance testing.\"\"\"\n",
        "\n",
        "        if len(topic_timeline) < self.window_size * 2:\n",
        "            return [], [], []\n",
        "\n",
        "        # Convert to lists to maintain order and get IDs\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "        stance_sequence = [self.stance_values.get(stance, 0) for _, stance in timeline_items]\n",
        "\n",
        "        potential_changes = []\n",
        "        p_values = []\n",
        "\n",
        "        # Sliding window approach\n",
        "        for i in range(self.window_size, len(stance_sequence) - self.window_size):\n",
        "\n",
        "            # Left window (before potential change)\n",
        "            left_window = stance_sequence[i - self.window_size:i]\n",
        "\n",
        "            # Right window (after potential change)\n",
        "            right_window = stance_sequence[i:i + self.window_size]\n",
        "\n",
        "            # Statistical test: Are these two windows significantly different?\n",
        "            statistic, p_value = self.two_sample_test(left_window, right_window)\n",
        "\n",
        "            p_values.append(p_value)\n",
        "\n",
        "            # Store potential change info with just the key utterance ID\n",
        "            change_magnitude = abs(np.mean(right_window) - np.mean(left_window))\n",
        "            potential_changes.append({\n",
        "                'position': i,\n",
        "                'utterance_id': timeline_items[i][0],  # The utterance where change detected\n",
        "                'p_value': p_value,\n",
        "                'test_statistic': statistic,\n",
        "                'magnitude': change_magnitude,\n",
        "                'left_mean': np.mean(left_window),\n",
        "                'right_mean': np.mean(right_window),\n",
        "                'left_window': left_window.copy(),\n",
        "                'right_window': right_window.copy()\n",
        "            })\n",
        "\n",
        "        # Apply FDR correction to all p-values\n",
        "        if not p_values:\n",
        "            return [], [], []\n",
        "\n",
        "        rejected, p_corrected = self.multiple_testing_correction(p_values)\n",
        "\n",
        "        # Keep only changes that survive FDR correction\n",
        "        significant_changes = []\n",
        "        for i, change in enumerate(potential_changes):\n",
        "            if rejected[i]:  # Survives FDR correction\n",
        "                change.update({\n",
        "                    'p_corrected': p_corrected[i],\n",
        "                    'statistically_significant': True,\n",
        "                    'survives_fdr_correction': True,\n",
        "                    'significance_level': self.alpha\n",
        "                })\n",
        "                significant_changes.append(change)\n",
        "\n",
        "        return significant_changes, p_values, p_corrected\n",
        "\n",
        "    def two_sample_test(self, left_window, right_window):\n",
        "        \"\"\"Statistical test for difference between two windows.\"\"\"\n",
        "        # Use Mann-Whitney U test (non-parametric, more robust)\n",
        "        try:\n",
        "            statistic, p_value = mannwhitneyu(left_window, right_window,\n",
        "                                            alternative='two-sided')\n",
        "            return statistic, p_value\n",
        "        except ValueError:\n",
        "            # Fallback to t-test if Mann-Whitney fails\n",
        "            statistic, p_value = ttest_ind(left_window, right_window)\n",
        "            return statistic, p_value\n",
        "\n",
        "    def multiple_testing_correction(self, p_values):\n",
        "        \"\"\"Correct for multiple testing using Benjamini-Hochberg.\"\"\"\n",
        "        rejected, p_corrected = fdrcorrection(p_values, alpha=self.alpha)\n",
        "        return rejected, p_corrected\n",
        "\n",
        "    # def analyze_user_belief_changes(self, user_timeline):\n",
        "    #     \"\"\"Analyze belief changes across all topics for a user.\"\"\"\n",
        "    #     all_changes = {}\n",
        "    #\n",
        "    #     for topic, topic_timeline in user_timeline.items():\n",
        "    #         changes = self.detect_changes_with_significance(topic_timeline)\n",
        "    #         all_changes[topic] = changes\n",
        "    #\n",
        "    #     return all_changes\n",
        "\n",
        "    def analyze_user_belief_changes(self, user_timeline):\n",
        "        \"\"\"Analyze belief changes across all topics for a user.\n",
        "\n",
        "        Args:\n",
        "            user_timeline: Dict of {topic: {utterance_id: stance}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by topic and total count\n",
        "        \"\"\"\n",
        "        all_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for topic, topic_timeline in user_timeline.items():\n",
        "            significant_changes, p_values, p_corrected = self.detect_changes_with_significance(topic_timeline)\n",
        "            all_changes[topic] = significant_changes\n",
        "            total_changes += len(significant_changes)\n",
        "\n",
        "        return {\n",
        "            'changes_by_topic': all_changes,\n",
        "            'total_changes': total_changes\n",
        "        }\n",
        "\n",
        "    def analyze_all_users_belief_changes(self, timelines):\n",
        "        \"\"\"Analyze belief changes across all users.\n",
        "\n",
        "        Args:\n",
        "            timelines: Dict of {user_id: {topic: {utterance_id: stance}}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by user and total count\n",
        "        \"\"\"\n",
        "        all_user_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for user_id, user_timeline in timelines.items():\n",
        "            user_result = self.analyze_user_belief_changes(user_timeline)\n",
        "            all_user_changes[user_id] = user_result\n",
        "            total_changes += user_result['total_changes']\n",
        "\n",
        "        return {\n",
        "            'changes_by_user': all_user_changes,\n",
        "            'total_changes': total_changes\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P9oCLaSGrER"
      },
      "id": "7P9oCLaSGrER",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock corpus-like objects for testing\n",
        "class MockUtterance:\n",
        "    def __init__(self, id, speaker_id, text, timestamp, conversation):\n",
        "        self.id = id\n",
        "        self.speaker = MockSpeaker(speaker_id)\n",
        "        self.text = text\n",
        "        self.timestamp = timestamp\n",
        "        self._conversation = conversation\n",
        "\n",
        "    def get_conversation(self):\n",
        "        return self._conversation\n",
        "\n",
        "class MockSpeaker:\n",
        "    def __init__(self, speaker_id):\n",
        "        self.id = speaker_id\n",
        "\n",
        "class MockConversation:\n",
        "    def __init__(self, id, root_post, all_utterances):\n",
        "        self.id = id\n",
        "        self._root = root_post\n",
        "        self._utterances = all_utterances\n",
        "        self.meta = {'detected_topic': 'taxation and government spending'}\n",
        "\n",
        "    def get_root(self):\n",
        "        return self._root\n",
        "\n",
        "    def iter_utterances(self):\n",
        "        return iter(self._utterances)\n",
        "\n",
        "class MockCorpus:\n",
        "    def __init__(self):\n",
        "        # Create mock conversations with realistic political discussion\n",
        "        self.utterances = {}\n",
        "        self.conversations = {}\n",
        "        self._setup_mock_data()\n",
        "\n",
        "    def get_utterance(self, utterance_id):\n",
        "        return self.utterances.get(utterance_id)\n",
        "\n",
        "    def _setup_mock_data(self):\n",
        "        # Create 3 conversations for testing\n",
        "\n",
        "        # Conversation 1: Tax policy discussion\n",
        "        conv1_utterances = []\n",
        "        op1 = MockUtterance(\n",
        "            id=\"op_conv1\",\n",
        "            speaker_id=\"original_poster_1\",\n",
        "            text=\"I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't working.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply1 = MockUtterance(\n",
        "            id=\"user_reply_conv1\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt economic growth.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv1_utterances = [op1, user_reply1]\n",
        "        conv1 = MockConversation(\"conv_1\", op1, conv1_utterances)\n",
        "\n",
        "        # Set conversation references\n",
        "        for utt in conv1_utterances:\n",
        "            utt._conversation = conv1\n",
        "\n",
        "        # Conversation 2: Healthcare spending\n",
        "        op2 = MockUtterance(\n",
        "            id=\"op_conv2\",\n",
        "            speaker_id=\"original_poster_2\",\n",
        "            text=\"Government healthcare spending is out of control. We need to cut Medicare and focus on private solutions.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply2 = MockUtterance(\n",
        "            id=\"user_reply_conv2\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without reducing benefits.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv2_utterances = [op2, user_reply2]\n",
        "        conv2 = MockConversation(\"conv_2\", op2, conv2_utterances)\n",
        "\n",
        "        for utt in conv2_utterances:\n",
        "            utt._conversation = conv2\n",
        "\n",
        "        # Conversation 3: Budget discussion\n",
        "        op3 = MockUtterance(\n",
        "            id=\"op_conv3\",\n",
        "            speaker_id=\"original_poster_3\",\n",
        "            text=\"The federal budget deficit is unsustainable. We need major spending cuts across all departments.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply3 = MockUtterance(\n",
        "            id=\"user_reply_conv3\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"You're absolutely right. Government spending is completely out of control and we need dramatic cuts immediately.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv3_utterances = [op3, user_reply3]\n",
        "        conv3 = MockConversation(\"conv_3\", op3, conv3_utterances)\n",
        "\n",
        "        for utt in conv3_utterances:\n",
        "            utt._conversation = conv3\n",
        "\n",
        "        # Store all utterances and conversations\n",
        "        all_utterances = conv1_utterances + conv2_utterances + conv3_utterances\n",
        "        for utt in all_utterances:\n",
        "            self.utterances[utt.id] = utt\n",
        "\n",
        "        self.conversations[\"conv_1\"] = conv1\n",
        "        self.conversations[\"conv_2\"] = conv2\n",
        "        self.conversations[\"conv_3\"] = conv3\n",
        "\n",
        "# Mock timeline data showing a clear stance change\n",
        "mock_timelines = {\n",
        "    \"TestUser\": {\n",
        "        \"taxation and government spending\": {\n",
        "            \"user_reply_conv1\": \"moderately_against\",  # Position 0: Against tax increases\n",
        "            \"user_reply_conv2\": \"neutral\",             # Position 1: Moderate on spending\n",
        "            \"user_reply_conv3\": \"strongly_against\"     # Position 2: Strong anti-spending (CHANGE HERE)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mock significant change (what your detector would return)\n",
        "mock_significant_change = {\n",
        "    'position': 2,\n",
        "    'utterance_id': 'user_reply_conv3',  # The utterance where change was detected\n",
        "    'p_value': 0.023,\n",
        "    'p_corrected': 0.041,\n",
        "    'magnitude': 1.5,\n",
        "    'left_mean': -0.5,   # Was moderate\n",
        "    'right_mean': -2.0,  # Became strongly against\n",
        "    'statistically_significant': True,\n",
        "    'survives_fdr_correction': True\n",
        "}\n",
        "\n",
        "print(\"Mock data created!\")\n",
        "print(\"Timeline:\", mock_timelines[\"TestUser\"][\"taxation and government spending\"])\n",
        "print(\"Significant change detected at:\", mock_significant_change['utterance_id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQw0IptDszKn",
        "outputId": "87ab9249-1b51-4a8f-df39-17889ec59bf1"
      },
      "id": "HQw0IptDszKn",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock data created!\n",
            "Timeline: {'user_reply_conv1': 'moderately_against', 'user_reply_conv2': 'neutral', 'user_reply_conv3': 'strongly_against'}\n",
            "Significant change detected at: user_reply_conv3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test WindowExtractor with mock data\n",
        "mock_corpus = MockCorpus()\n",
        "\n",
        "# Create extractor with mock data\n",
        "extractor = ConversationWindowExtractor(mock_corpus, mock_timelines)\n",
        "\n",
        "# Test extraction around the significant change\n",
        "window_data = extractor.get_conversations_around_change(\n",
        "    user_id=\"TestUser\",\n",
        "    topic=\"taxation and government spending\",\n",
        "    change=mock_significant_change,\n",
        "    window_size=2\n",
        ")\n",
        "\n",
        "rooted_units_data = extractor.extract_rooted_path_units_from_window(window_data)\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "interplay_data = extractor.preprocess_rooted_units_for_interplay(rooted_units_data)\n",
        "\n",
        "# Print results\n",
        "if window_data:\n",
        "    extractor.print_window_summary(window_data)\n",
        "\n",
        "    # Show actual conversation content\n",
        "    print(\"\\n=== Conversation Content ===\")\n",
        "\n",
        "    print(\"\\nBEFORE change conversations:\")\n",
        "    for i, conv in enumerate(window_data['before_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "    print(\"\\nAFTER change conversations:\")\n",
        "    for i, conv in enumerate(window_data['after_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "else:\n",
        "    print(\"No window data extracted - check for errors\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6bvbM-s4XZ",
        "outputId": "01f57637-ac0c-4e2f-aa0e-015361b64609"
      },
      "id": "3W6bvbM-s4XZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found change at position 2 of 3 total utterances\n",
            "Looking for conversations before change: positions 0 to 1\n",
            "  Found conversation before: conv_1\n",
            "  Found conversation before: conv_2\n",
            "Looking for conversations after change: positions 3 to 2\n",
            "\n",
            "=== Conversation Window Summary ===\n",
            "Change occurred at position 2 of 3 utterances\n",
            "Change utterance ID: user_reply_conv3\n",
            "Window size: 2\n",
            "\n",
            "Conversations BEFORE change: 2\n",
            "  1. Conversation conv_1: 1 user replies\n",
            "  2. Conversation conv_2: 1 user replies\n",
            "\n",
            "Conversations AFTER change: 0\n",
            "\n",
            "=== Conversation Content ===\n",
            "\n",
            "BEFORE change conversations:\n",
            "\n",
            "Conversation 1 (conv_1):\n",
            "OP: I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't workin...\n",
            "User: I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt e...\n",
            "\n",
            "Conversation 2 (conv_2):\n",
            "OP: Government healthcare spending is out of control. We need to cut Medicare and focus on private solut...\n",
            "User: Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without r...\n",
            "\n",
            "AFTER change conversations:\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b356989ed61b101a",
        "outputId": "c0dd02ca-66ac-42d1-9b80-4d54fe6a7ded"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-03 13:06:26,778 - temporal_belief.core.timeline_building - INFO - timeline_building:71 - Built timelines for 4781 users\n",
            "INFO:temporal_belief.core.timeline_building:Built timelines for 4781 users\n"
          ]
        }
      ],
      "execution_count": 78,
      "source": [
        "# Detect persistent changes:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Filter for analysis\n",
        "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
        "\n",
        "# Convert to list of tupples\n",
        "topic_timeline_list = list(topic_timeline.items())\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"media and political commentary\"\n",
        "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "persistence_detector = ChangeDetector()"
      ],
      "id": "b356989ed61b101a"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U6qSPADgCqTT"
      },
      "id": "U6qSPADgCqTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1MBPPOaic2F",
        "outputId": "dc51106d-434f-4ab1-ab70-fa32a9abd01f"
      },
      "id": "L1MBPPOaic2F",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_extractor = ConversationWindowExtractor(corpus, timelines=timelines)\n",
        "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)\n",
        "convos = window_extractor.get_conversation_around_change_point(change_points=change_points, corpus=corpus)\n",
        "for convo in convos:\n",
        "  print(f\"Conversation_id: {convo.id}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "18KTGg8HAEJV",
        "outputId": "a54f1a2a-4e21-485f-b84f-8e630e0b8f68"
      },
      "id": "18KTGg8HAEJV",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'conversation_id' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1645058536.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwindow_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConversationWindowExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimelines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimelines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchange_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistence_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetect_persistent_changes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_timeline_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconvos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_extractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conversation_around_change_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchange_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconvo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconvos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Conversation_id: {convo.id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-96420352.py\u001b[0m in \u001b[0;36mget_conversation_around_change_point\u001b[0;34m(self, corpus, change_points)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;31m# get conversation id from utterance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m       \u001b[0mconversation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_conversation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversation_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m       \u001b[0mconversation_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'conversation_id' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(change_points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atuQv-CBkHt6",
        "outputId": "38fc4518-a65b-4bf5-be27-fe1833efccb6"
      },
      "id": "atuQv-CBkHt6",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(141, 'c3dpsmt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(topic_timeline_list[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4ePoNkPOifg",
        "outputId": "09f7eb0b-913c-475f-a89f-f75a30f746d0"
      },
      "id": "L4ePoNkPOifg",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lnrey\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:27:22.794077Z",
          "start_time": "2025-07-14T10:27:10.717627Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5cd23a3a61604c",
        "outputId": "aac6e556-08e6-4f8f-93a4-97d5169afbc1"
      },
      "cell_type": "code",
      "source": [
        "# Detect changes with significance:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Filter for analysis\n",
        "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"media and political commentary\"\n",
        "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = ChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(significant_changes)} statistically significant stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in significant_changes:\n",
        "    print(f\"  {change['stance_before']} → {change['stance_after']} (magnitude: {change['magnitude']:.3f}, p={change['p_corrected']:.4f})\")"
      ],
      "id": "9e5cd23a3a61604c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 0 statistically significant stance changes for user HardCoreModerate on topic media and political commentary:\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Test window extractor\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]\n",
        "\n",
        "# Get significant changes\n",
        "detector = ChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "if significant_changes:\n",
        "    # Test the window extractor\n",
        "    extractor = ConversationWindowExtractor(corpus, timelines)\n",
        "    window_data = extractor.get_conversations_around_change(\n",
        "        user_id=user_id,\n",
        "        topic=topic,\n",
        "        change=significant_changes[0],\n",
        "        window_size=2  # 2 conversations before + 2 after\n",
        "    )\n",
        "\n",
        "    # Print summary\n",
        "    extractor.print_window_summary(window_data)\n",
        "else:\n",
        "    print(\"No significant changes found to test with\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkM5xlBWrl-X",
        "outputId": "94aff112-5932-44c9-d38c-2fdd9103a9eb"
      },
      "id": "XkM5xlBWrl-X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No significant changes found to test with\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:46:54.285111Z",
          "start_time": "2025-07-14T10:46:54.278201Z"
        },
        "id": "d6a1cb6bb6b62c85",
        "outputId": "cbaf6df3-ad32-4863-c995-0c67b1df0fab"
      },
      "cell_type": "code",
      "source": [
        "# Most populated topic for a user\n",
        "def topic_with_most_contributions(user_id):\n",
        "    posts_in_topic = {}\n",
        "    for topic in timelines[user_id].keys():\n",
        "      posts_in_topic[topic] = len(list(timelines[user_id][topic]))\n",
        "    # key with the largest value\n",
        "    topic = max(posts_in_topic, key=posts_in_topic.get)\n",
        "\n",
        "    return topic, posts_in_topic[topic]\n",
        "\n",
        "# Yea the number came cause the posts_in_topic was not encapsulated\n",
        "user_id = 'HardCoreModerate'\n",
        "topic, number = topic_with_most_contributions(user_id)\n",
        "print(f\"{topic}: {number}\")\n",
        "# print(posts_in_topic)"
      ],
      "id": "d6a1cb6bb6b62c85",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "media and political commentary: 145\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cd56563c479c5f7f"
      },
      "cell_type": "code",
      "source": [
        "# Total number of users with metadata (unfiltered)\n",
        "print(len(timelines))"
      ],
      "id": "cd56563c479c5f7f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:51:13.890752Z",
          "start_time": "2025-07-14T10:51:13.850561Z"
        },
        "id": "484f1d1c47361a1f"
      },
      "cell_type": "code",
      "source": [
        "# NOT WORKING\n",
        "# user with the most utterances:\n",
        "# I have to find the max between their topics and then find the overall max\n",
        "users = {}\n",
        "for user_id, data in timelines.items():\n",
        "    topic, number = topic_with_most_contributions(user_id)\n",
        "    users[user_id] = topic\n",
        "    users[user_id][topic] = number\n",
        "\n",
        "for user in users:\n",
        "    print(user)\n",
        "# user_id = max(users, key=users.get)\n",
        "# print(f\"{user_id}: {users[user_id]}\")"
      ],
      "id": "484f1d1c47361a1f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-13T14:02:24.843970Z",
          "start_time": "2025-07-13T14:02:12.281770Z"
        },
        "id": "fa8987174cfc2918",
        "outputId": "8d33f8e0-0b83-4332-df71-6ee72803ad5c"
      },
      "cell_type": "code",
      "source": [
        "# Detect simple stance change:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=3, min_topics_per_user=1)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = ChangeDetector()\n",
        "changes = detector.detect_simple_stance_changes(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(changes)} stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in changes:\n",
        "    print(f\"  {change['from_stance']} → {change['to_stance']} (magnitude: {change['change_magnitude']})\")"
      ],
      "id": "fa8987174cfc2918",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected 2 stance changes for user HardCoreModerate on topic taxation and government spending:\n",
            "  moderately_against → neutral (magnitude: 1)\n",
            "  neutral → moderately_against (magnitude: 1)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f414b5573c4a4ca6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# for user_id in"
      ],
      "id": "f414b5573c4a4ca6"
    },
    {
      "metadata": {
        "id": "ad5e6484d5f466e1"
      },
      "cell_type": "code",
      "source": [
        "# Run detection for all topics for a user - NOT TESTED:\n",
        "# Get complete user timeline\n",
        "user_timeline = timelines[\"pixel8\"]  # All topics for this user\n",
        "\n",
        "# Analyze changes across all topics\n",
        "detector = ChangeDetector()\n",
        "all_changes = detector.analyze_user_belief_changes(user_timeline)\n",
        "\n",
        "# Results\n",
        "for topic, changes in all_changes.items():\n",
        "    print(f\"Topic: {topic}\")\n",
        "    for change in changes:\n",
        "        print(f\"  Change at position {change['position']}: magnitude {change['magnitude']}\")"
      ],
      "id": "ad5e6484d5f466e1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "76049e46c5223f2d"
      },
      "cell_type": "code",
      "source": [
        "# All users that meet the criteria:\n",
        "print(\"Available users:\")\n",
        "print(list(timelines.keys())[:20])"
      ],
      "id": "76049e46c5223f2d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ba90763c4b3d61ed"
      },
      "cell_type": "code",
      "source": [
        "# What topics the users have posted about:\n",
        "for user_id in list(timelines.keys())[:20]:  # Check first 5 users\n",
        "    topics = list(timelines[user_id].keys())\n",
        "    print(f\"{user_id}: {topics}\")\n",
        "    break"
      ],
      "id": "ba90763c4b3d61ed",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-07T12:45:16.821978Z",
          "start_time": "2025-07-07T12:45:16.653806Z"
        },
        "id": "1fee47509c799599",
        "outputId": "7e5ab68d-0188-48b4-d945-0687433058f6"
      },
      "cell_type": "code",
      "source": [
        "# confidence score:\n",
        "utterances = list(corpus.iter_utterances())\n",
        "print(utterances[1].meta)"
      ],
      "id": "1fee47509c799599",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvoKitMeta({'score': 29, 'top_level_comment': None, 'retrieved_on': -1, 'gilded': -1, 'gildings': None, 'subreddit': 'PoliticalDiscussion', 'stickied': False, 'permalink': '/r/PoliticalDiscussion/comments/nz1xu/congrats_rpoliticaldiscussion_you_are_turning/', 'author_flair_text': '', 'detected_stance': 'moderately_against', 'stance_confidence': 0.8540321985880533, 'stance_scores': {'strongly_favor': 0.0016047263949682626, 'moderately_favor': 0.5134096046288809, 'neutral': 0.0072105322033166885, 'moderately_against': 0.8540321985880533, 'strongly_against': 0.3021060957883795}})\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a81d7e7fa2b05740"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "a81d7e7fa2b05740"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}