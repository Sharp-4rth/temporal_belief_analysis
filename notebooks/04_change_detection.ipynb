{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:09:51.278612Z",
          "start_time": "2025-07-14T08:08:08.657634Z"
        },
        "id": "bbad0be784b4869a"
      },
      "cell_type": "code",
      "source": [
        "# Need to restart after:\n",
        "!pip install convokit"
      ],
      "id": "bbad0be784b4869a",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Download file from Google Drive to colab directory\n",
        "!pip install gdown\n",
        "file_id = \"1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\"\n",
        "!gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\" --fuzzy"
      ],
      "metadata": {
        "id": "oJ1WKmwwZQYL"
      },
      "id": "oJ1WKmwwZQYL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip with python:\n",
        "import zipfile\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")"
      ],
      "metadata": {
        "id": "B2PlEx8QYzgg"
      },
      "id": "B2PlEx8QYzgg",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For runpod-jupyter or local (run twice)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Change to the correct working directory (same as Jupyter)\n",
        "# os.chdir('/workspace/temporal_belief_analysis/notebooks')\n",
        "# print(\"Changed working directory to:\", os.getcwd())\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Comment out if in colab:\n",
        "# from temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "_yv_LVXGjggY"
      },
      "id": "_yv_LVXGjggY",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from temporal_belief_analysis.src.temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "3sIZWUc9i5WL"
      },
      "id": "3sIZWUc9i5WL",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22220bf09f61753c"
      },
      "cell_type": "code",
      "source": [
        "# Run twice\n",
        "# import unsloth\n",
        "# import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit"
      ],
      "id": "22220bf09f61753c",
      "outputs": [],
      "execution_count": 38
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:40.933464Z",
          "start_time": "2025-07-14T10:23:26.387524Z"
        },
        "id": "781d4e0509ad3c21"
      },
      "cell_type": "code",
      "source": [
        "# Load a corpus:\n",
        "# corpus = Corpus(filename=\"/Users/leonidas/.convokit/saved-corpora/pd_corpus_with_stances1000_chronological\")\n",
        "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological\")"
      ],
      "id": "781d4e0509ad3c21",
      "outputs": [],
      "execution_count": 29
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:17:28.390010Z",
          "start_time": "2025-07-14T08:17:20.788691Z"
        },
        "id": "ad611eb7998835c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install statsmodels"
      ],
      "id": "ad611eb7998835c2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.170080Z",
          "start_time": "2025-07-14T10:26:41.164333Z"
        },
        "id": "de0d75b2335f7dce"
      },
      "cell_type": "code",
      "source": [
        "def filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2, min_confidence=0.0):\n",
        "    \"\"\"Filter timelines to only include users/topics suitable for change detection\"\"\"\n",
        "    filtered_timelines = {}\n",
        "\n",
        "    for user_id, user_timeline in timelines.items():\n",
        "        filtered_user_timeline = {}\n",
        "\n",
        "        for topic, topic_posts in user_timeline.items():\n",
        "            # Filter by confidence (if you have access to corpus here)\n",
        "            reliable_posts = {}\n",
        "            for utt_id, stance in topic_posts.items():\n",
        "                # You'd need to pass corpus or confidence scores here\n",
        "                # For now, assume all posts are reliable\n",
        "                reliable_posts[utt_id] = stance\n",
        "\n",
        "            # Check minimum posts per topic\n",
        "            if len(reliable_posts) >= min_posts_per_topic:\n",
        "                filtered_user_timeline[topic] = reliable_posts\n",
        "\n",
        "        # Check minimum topics per user\n",
        "        if len(filtered_user_timeline) >= min_topics_per_user:\n",
        "            filtered_timelines[user_id] = filtered_user_timeline\n",
        "\n",
        "    return filtered_timelines"
      ],
      "id": "de0d75b2335f7dce",
      "outputs": [],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationWindowExtractor:\n",
        "    def __init__(self, corpus, timelines):\n",
        "        self.corpus = corpus\n",
        "        self.timelines = timelines\n",
        "\n",
        "    def get_conversations_around_change(self, user_id, topic, change, window_size=3):\n",
        "        \"\"\"\n",
        "        Get conversations before/after a belief change based on conversation count\n",
        "\n",
        "        Args:\n",
        "            user_id: The user who had the belief change\n",
        "            topic: The topic where change occurred\n",
        "            change: The significant change object from detect_changes_with_significance()\n",
        "            window_size: Number of conversations before AND after change to include\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                'before_change': [conversation_data, ...],\n",
        "                'after_change': [conversation_data, ...],\n",
        "                'change_position': int,\n",
        "                'change_utterance_id': str\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # Get ordered timeline for this user/topic\n",
        "        topic_timeline = self.timelines[user_id][topic]\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "\n",
        "        # Find position of the change utterance\n",
        "        change_utterance_id = change['utterance_id']\n",
        "        change_position = None\n",
        "\n",
        "        for i, (utterance_id, stance) in enumerate(timeline_items):\n",
        "            if utterance_id == change_utterance_id:\n",
        "                change_position = i\n",
        "                break\n",
        "\n",
        "        if change_position is None:\n",
        "            print(f\"Warning: Change utterance {change_utterance_id} not found in timeline\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Found change at position {change_position} of {len(timeline_items)} total utterances\")\n",
        "\n",
        "        # Extract conversations in window\n",
        "        before_conversations = []\n",
        "        after_conversations = []\n",
        "\n",
        "        # Get conversations BEFORE change\n",
        "        start_before = max(0, change_position - window_size)\n",
        "        print(f\"Looking for conversations before change: positions {start_before} to {change_position-1}\")\n",
        "\n",
        "        for i in range(start_before, change_position):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                before_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation before: {conv_data['conversation_id']}\")\n",
        "\n",
        "        # Get conversations AFTER change\n",
        "        end_after = min(len(timeline_items), change_position + window_size + 1)\n",
        "        print(f\"Looking for conversations after change: positions {change_position+1} to {end_after-1}\")\n",
        "\n",
        "        for i in range(change_position + 1, end_after):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                after_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation after: {conv_data['conversation_id']}\")\n",
        "\n",
        "        return {\n",
        "            'before_change': before_conversations,\n",
        "            'after_change': after_conversations,\n",
        "            'change_position': change_position,\n",
        "            'change_utterance_id': change_utterance_id,\n",
        "            'total_timeline_length': len(timeline_items),\n",
        "            'window_size': window_size\n",
        "        }\n",
        "\n",
        "    def _extract_conversation_from_utterance(self, utterance_id, user_id):\n",
        "        \"\"\"Extract conversation data from a specific utterance\"\"\"\n",
        "        try:\n",
        "            utterance = self.corpus.get_utterance(utterance_id)\n",
        "            if not utterance:\n",
        "                return None\n",
        "\n",
        "            conversation = utterance.get_conversation()\n",
        "            if not conversation:\n",
        "                return None\n",
        "\n",
        "            op_post = conversation.get_root()\n",
        "            if not op_post:\n",
        "                return None\n",
        "\n",
        "            user_replies = []\n",
        "\n",
        "            # Get ALL user replies in this conversation (not just the target utterance)\n",
        "            for utt in conversation.iter_utterances():\n",
        "                if utt.speaker.id == user_id and utt.id != op_post.id:\n",
        "                    user_replies.append(utt)\n",
        "\n",
        "            if not user_replies:\n",
        "                return None\n",
        "\n",
        "            return {\n",
        "                'conversation_id': conversation.id,\n",
        "                'op_post': op_post,\n",
        "                'user_replies': user_replies,\n",
        "                'target_utterance_id': utterance_id,  # Which utterance led us to this conversation\n",
        "                'topic': conversation.meta.get('detected_topic', 'unknown') if conversation.meta else 'unknown'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting conversation for utterance {utterance_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def print_window_summary(self, window_data):\n",
        "        \"\"\"Helper method to print a summary of extracted conversations\"\"\"\n",
        "        if not window_data:\n",
        "            print(\"No window data to summarize\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n=== Conversation Window Summary ===\")\n",
        "        print(f\"Change occurred at position {window_data['change_position']} of {window_data['total_timeline_length']} utterances\")\n",
        "        print(f\"Change utterance ID: {window_data['change_utterance_id']}\")\n",
        "        print(f\"Window size: {window_data.get('window_size', 'unknown')}\")\n",
        "\n",
        "        print(f\"\\nConversations BEFORE change: {len(window_data['before_change'])}\")\n",
        "        for i, conv in enumerate(window_data['before_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")\n",
        "\n",
        "        print(f\"\\nConversations AFTER change: {len(window_data['after_change'])}\")\n",
        "        for i, conv in enumerate(window_data['after_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")"
      ],
      "metadata": {
        "id": "zj51bpjrpjTd"
      },
      "id": "zj51bpjrpjTd",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.492540Z",
          "start_time": "2025-07-14T10:26:41.473273Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "from statsmodels.stats.multitest import fdrcorrection\n",
        "from collections import Counter\n",
        "import logging\n",
        "\n",
        "class BeliefChangeDetector:\n",
        "    \"\"\"Sliding window change detection with proper statistical significance.\"\"\"\n",
        "\n",
        "    def __init__(self, window_size=3, significance_level=0.05):\n",
        "        self.window_size = window_size\n",
        "        self.alpha = significance_level\n",
        "        self.stance_values = {\n",
        "            'strongly_against': -2, 'moderately_against': -1,\n",
        "            'neutral': 0, 'moderately_favor': 1, 'strongly_favor': 2\n",
        "        }\n",
        "\n",
        "    def detect_simple_stance_changes(self, topic_timeline):\n",
        "\n",
        "        if len(topic_timeline) < 2:\n",
        "            return []\n",
        "\n",
        "        changes = []\n",
        "        timeline_items = list(topic_timeline.items())  # Convert to list of (utterance_id, stance) pairs\n",
        "\n",
        "        for i in range(1, len(timeline_items)):\n",
        "            current_utterance_id, current_stance = timeline_items[i]\n",
        "            previous_utterance_id, previous_stance = timeline_items[i-1]\n",
        "\n",
        "            # Check if stance changed\n",
        "            if current_stance != previous_stance:\n",
        "                change = {\n",
        "                    'position': i,\n",
        "                    'current_utterance_id': current_utterance_id,\n",
        "                    'previous_utterance_id': previous_utterance_id,\n",
        "                    'from_stance': previous_stance,\n",
        "                    'to_stance': current_stance,\n",
        "                    'change_type': self._classify_change_direction(previous_stance, current_stance),\n",
        "                    'change_magnitude': self._calculate_simple_magnitude(previous_stance, current_stance)\n",
        "                }\n",
        "                changes.append(change)\n",
        "\n",
        "        return changes\n",
        "\n",
        "    def _classify_change_direction(self, from_stance, to_stance):\n",
        "        \"\"\"Classify the direction of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "\n",
        "        if to_value > from_value:\n",
        "            return 'more_favorable'\n",
        "        elif to_value < from_value:\n",
        "            return 'less_favorable'\n",
        "        else:\n",
        "            return 'neutral_shift'\n",
        "\n",
        "    def _calculate_simple_magnitude(self, from_stance, to_stance):\n",
        "        \"\"\"Calculate the magnitude of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "        return abs(to_value - from_value)\n",
        "\n",
        "    def detect_changes_with_significance(self, topic_timeline):\n",
        "        \"\"\"Detect changes with statistical significance testing.\"\"\"\n",
        "\n",
        "        if len(topic_timeline) < self.window_size * 2:\n",
        "            return [], [], []\n",
        "\n",
        "        # Convert to lists to maintain order and get IDs\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "        stance_sequence = [self.stance_values.get(stance, 0) for _, stance in timeline_items]\n",
        "\n",
        "        potential_changes = []\n",
        "        p_values = []\n",
        "\n",
        "        # Sliding window approach\n",
        "        for i in range(self.window_size, len(stance_sequence) - self.window_size):\n",
        "\n",
        "            # Left window (before potential change)\n",
        "            left_window = stance_sequence[i - self.window_size:i]\n",
        "\n",
        "            # Right window (after potential change)\n",
        "            right_window = stance_sequence[i:i + self.window_size]\n",
        "\n",
        "            # Statistical test: Are these two windows significantly different?\n",
        "            statistic, p_value = self.two_sample_test(left_window, right_window)\n",
        "\n",
        "            p_values.append(p_value)\n",
        "\n",
        "            # Store potential change info with just the key utterance ID\n",
        "            change_magnitude = abs(np.mean(right_window) - np.mean(left_window))\n",
        "            potential_changes.append({\n",
        "                'position': i,\n",
        "                'utterance_id': timeline_items[i][0],  # The utterance where change detected\n",
        "                'p_value': p_value,\n",
        "                'test_statistic': statistic,\n",
        "                'magnitude': change_magnitude,\n",
        "                'left_mean': np.mean(left_window),\n",
        "                'right_mean': np.mean(right_window),\n",
        "                'left_window': left_window.copy(),\n",
        "                'right_window': right_window.copy()\n",
        "            })\n",
        "\n",
        "        # Apply FDR correction to all p-values\n",
        "        if not p_values:\n",
        "            return [], [], []\n",
        "\n",
        "        rejected, p_corrected = self.multiple_testing_correction(p_values)\n",
        "\n",
        "        # Keep only changes that survive FDR correction\n",
        "        significant_changes = []\n",
        "        for i, change in enumerate(potential_changes):\n",
        "            if rejected[i]:  # Survives FDR correction\n",
        "                change.update({\n",
        "                    'p_corrected': p_corrected[i],\n",
        "                    'statistically_significant': True,\n",
        "                    'survives_fdr_correction': True,\n",
        "                    'significance_level': self.alpha\n",
        "                })\n",
        "                significant_changes.append(change)\n",
        "\n",
        "        return significant_changes, p_values, p_corrected\n",
        "\n",
        "    def two_sample_test(self, left_window, right_window):\n",
        "        \"\"\"Statistical test for difference between two windows.\"\"\"\n",
        "        # Use Mann-Whitney U test (non-parametric, more robust)\n",
        "        try:\n",
        "            statistic, p_value = mannwhitneyu(left_window, right_window,\n",
        "                                            alternative='two-sided')\n",
        "            return statistic, p_value\n",
        "        except ValueError:\n",
        "            # Fallback to t-test if Mann-Whitney fails\n",
        "            statistic, p_value = ttest_ind(left_window, right_window)\n",
        "            return statistic, p_value\n",
        "\n",
        "    def multiple_testing_correction(self, p_values):\n",
        "        \"\"\"Correct for multiple testing using Benjamini-Hochberg.\"\"\"\n",
        "        rejected, p_corrected = fdrcorrection(p_values, alpha=self.alpha)\n",
        "        return rejected, p_corrected\n",
        "\n",
        "    # def analyze_user_belief_changes(self, user_timeline):\n",
        "    #     \"\"\"Analyze belief changes across all topics for a user.\"\"\"\n",
        "    #     all_changes = {}\n",
        "    #\n",
        "    #     for topic, topic_timeline in user_timeline.items():\n",
        "    #         changes = self.detect_changes_with_significance(topic_timeline)\n",
        "    #         all_changes[topic] = changes\n",
        "    #\n",
        "    #     return all_changes\n",
        "\n",
        "    def analyze_user_belief_changes(self, user_timeline):\n",
        "        \"\"\"Analyze belief changes across all topics for a user.\n",
        "\n",
        "        Args:\n",
        "            user_timeline: Dict of {topic: {utterance_id: stance}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by topic and total count\n",
        "        \"\"\"\n",
        "        all_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for topic, topic_timeline in user_timeline.items():\n",
        "            significant_changes, p_values, p_corrected = self.detect_changes_with_significance(topic_timeline)\n",
        "            all_changes[topic] = significant_changes\n",
        "            total_changes += len(significant_changes)\n",
        "\n",
        "        return {\n",
        "            'changes_by_topic': all_changes,\n",
        "            'total_changes': total_changes\n",
        "        }\n",
        "\n",
        "    def analyze_all_users_belief_changes(self, timelines):\n",
        "        \"\"\"Analyze belief changes across all users.\n",
        "\n",
        "        Args:\n",
        "            timelines: Dict of {user_id: {topic: {utterance_id: stance}}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by user and total count\n",
        "        \"\"\"\n",
        "        all_user_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for user_id, user_timeline in timelines.items():\n",
        "            user_result = self.analyze_user_belief_changes(user_timeline)\n",
        "            all_user_changes[user_id] = user_result\n",
        "            total_changes += user_result['total_changes']\n",
        "\n",
        "        return {\n",
        "            'changes_by_user': all_user_changes,\n",
        "            'total_changes': total_changes\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock corpus-like objects for testing\n",
        "class MockUtterance:\n",
        "    def __init__(self, id, speaker_id, text, timestamp, conversation):\n",
        "        self.id = id\n",
        "        self.speaker = MockSpeaker(speaker_id)\n",
        "        self.text = text\n",
        "        self.timestamp = timestamp\n",
        "        self._conversation = conversation\n",
        "\n",
        "    def get_conversation(self):\n",
        "        return self._conversation\n",
        "\n",
        "class MockSpeaker:\n",
        "    def __init__(self, speaker_id):\n",
        "        self.id = speaker_id\n",
        "\n",
        "class MockConversation:\n",
        "    def __init__(self, id, root_post, all_utterances):\n",
        "        self.id = id\n",
        "        self._root = root_post\n",
        "        self._utterances = all_utterances\n",
        "        self.meta = {'detected_topic': 'taxation and government spending'}\n",
        "\n",
        "    def get_root(self):\n",
        "        return self._root\n",
        "\n",
        "    def iter_utterances(self):\n",
        "        return iter(self._utterances)\n",
        "\n",
        "class MockCorpus:\n",
        "    def __init__(self):\n",
        "        # Create mock conversations with realistic political discussion\n",
        "        self.utterances = {}\n",
        "        self.conversations = {}\n",
        "        self._setup_mock_data()\n",
        "\n",
        "    def get_utterance(self, utterance_id):\n",
        "        return self.utterances.get(utterance_id)\n",
        "\n",
        "    def _setup_mock_data(self):\n",
        "        # Create 3 conversations for testing\n",
        "\n",
        "        # Conversation 1: Tax policy discussion\n",
        "        conv1_utterances = []\n",
        "        op1 = MockUtterance(\n",
        "            id=\"op_conv1\",\n",
        "            speaker_id=\"original_poster_1\",\n",
        "            text=\"I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't working.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply1 = MockUtterance(\n",
        "            id=\"user_reply_conv1\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt economic growth.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv1_utterances = [op1, user_reply1]\n",
        "        conv1 = MockConversation(\"conv_1\", op1, conv1_utterances)\n",
        "\n",
        "        # Set conversation references\n",
        "        for utt in conv1_utterances:\n",
        "            utt._conversation = conv1\n",
        "\n",
        "        # Conversation 2: Healthcare spending\n",
        "        op2 = MockUtterance(\n",
        "            id=\"op_conv2\",\n",
        "            speaker_id=\"original_poster_2\",\n",
        "            text=\"Government healthcare spending is out of control. We need to cut Medicare and focus on private solutions.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply2 = MockUtterance(\n",
        "            id=\"user_reply_conv2\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without reducing benefits.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv2_utterances = [op2, user_reply2]\n",
        "        conv2 = MockConversation(\"conv_2\", op2, conv2_utterances)\n",
        "\n",
        "        for utt in conv2_utterances:\n",
        "            utt._conversation = conv2\n",
        "\n",
        "        # Conversation 3: Budget discussion\n",
        "        op3 = MockUtterance(\n",
        "            id=\"op_conv3\",\n",
        "            speaker_id=\"original_poster_3\",\n",
        "            text=\"The federal budget deficit is unsustainable. We need major spending cuts across all departments.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply3 = MockUtterance(\n",
        "            id=\"user_reply_conv3\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"You're absolutely right. Government spending is completely out of control and we need dramatic cuts immediately.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv3_utterances = [op3, user_reply3]\n",
        "        conv3 = MockConversation(\"conv_3\", op3, conv3_utterances)\n",
        "\n",
        "        for utt in conv3_utterances:\n",
        "            utt._conversation = conv3\n",
        "\n",
        "        # Store all utterances and conversations\n",
        "        all_utterances = conv1_utterances + conv2_utterances + conv3_utterances\n",
        "        for utt in all_utterances:\n",
        "            self.utterances[utt.id] = utt\n",
        "\n",
        "        self.conversations[\"conv_1\"] = conv1\n",
        "        self.conversations[\"conv_2\"] = conv2\n",
        "        self.conversations[\"conv_3\"] = conv3\n",
        "\n",
        "# Mock timeline data showing a clear stance change\n",
        "mock_timelines = {\n",
        "    \"TestUser\": {\n",
        "        \"taxation and government spending\": {\n",
        "            \"user_reply_conv1\": \"moderately_against\",  # Position 0: Against tax increases\n",
        "            \"user_reply_conv2\": \"neutral\",             # Position 1: Moderate on spending\n",
        "            \"user_reply_conv3\": \"strongly_against\"     # Position 2: Strong anti-spending (CHANGE HERE)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mock significant change (what your detector would return)\n",
        "mock_significant_change = {\n",
        "    'position': 2,\n",
        "    'utterance_id': 'user_reply_conv3',  # The utterance where change was detected\n",
        "    'p_value': 0.023,\n",
        "    'p_corrected': 0.041,\n",
        "    'magnitude': 1.5,\n",
        "    'left_mean': -0.5,   # Was moderate\n",
        "    'right_mean': -2.0,  # Became strongly against\n",
        "    'statistically_significant': True,\n",
        "    'survives_fdr_correction': True\n",
        "}\n",
        "\n",
        "print(\"Mock data created!\")\n",
        "print(\"Timeline:\", mock_timelines[\"TestUser\"][\"taxation and government spending\"])\n",
        "print(\"Significant change detected at:\", mock_significant_change['utterance_id'])"
      ],
      "metadata": {
        "id": "HQw0IptDszKn",
        "outputId": "677f9668-0f03-4989-a60e-156ad623f3fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HQw0IptDszKn",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock data created!\n",
            "Timeline: {'user_reply_conv1': 'moderately_against', 'user_reply_conv2': 'neutral', 'user_reply_conv3': 'strongly_against'}\n",
            "Significant change detected at: user_reply_conv3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your ConversationWindowExtractor with mock data\n",
        "mock_corpus = MockCorpus()\n",
        "\n",
        "# Create extractor with mock data\n",
        "extractor = ConversationWindowExtractor(mock_corpus, mock_timelines)\n",
        "\n",
        "# Test extraction around the significant change\n",
        "window_data = extractor.get_conversations_around_change(\n",
        "    user_id=\"TestUser\",\n",
        "    topic=\"taxation and government spending\",\n",
        "    change=mock_significant_change,\n",
        "    window_size=2\n",
        ")\n",
        "\n",
        "# Print results\n",
        "if window_data:\n",
        "    extractor.print_window_summary(window_data)\n",
        "\n",
        "    # Show actual conversation content\n",
        "    print(\"\\n=== Conversation Content ===\")\n",
        "\n",
        "    print(\"\\nBEFORE change conversations:\")\n",
        "    for i, conv in enumerate(window_data['before_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "    print(\"\\nAFTER change conversations:\")\n",
        "    for i, conv in enumerate(window_data['after_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "else:\n",
        "    print(\"No window data extracted - check for errors\")"
      ],
      "metadata": {
        "id": "3W6bvbM-s4XZ",
        "outputId": "8487438a-2be7-416a-cfc4-e34847e255f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3W6bvbM-s4XZ",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found change at position 2 of 3 total utterances\n",
            "Looking for conversations before change: positions 0 to 1\n",
            "  Found conversation before: conv_1\n",
            "  Found conversation before: conv_2\n",
            "Looking for conversations after change: positions 3 to 2\n",
            "\n",
            "=== Conversation Window Summary ===\n",
            "Change occurred at position 2 of 3 utterances\n",
            "Change utterance ID: user_reply_conv3\n",
            "Window size: 2\n",
            "\n",
            "Conversations BEFORE change: 2\n",
            "  1. Conversation conv_1: 1 user replies\n",
            "  2. Conversation conv_2: 1 user replies\n",
            "\n",
            "Conversations AFTER change: 0\n",
            "\n",
            "=== Conversation Content ===\n",
            "\n",
            "BEFORE change conversations:\n",
            "\n",
            "Conversation 1 (conv_1):\n",
            "OP: I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't workin...\n",
            "User: I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt e...\n",
            "\n",
            "Conversation 2 (conv_2):\n",
            "OP: Government healthcare spending is out of control. We need to cut Medicare and focus on private solut...\n",
            "User: Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without r...\n",
            "\n",
            "AFTER change conversations:\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:27:22.794077Z",
          "start_time": "2025-07-14T10:27:10.717627Z"
        },
        "id": "9e5cd23a3a61604c",
        "outputId": "aac6e556-08e6-4f8f-93a4-97d5169afbc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "# Detect changes with significance:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Filter for analysis\n",
        "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"media and political commentary\"\n",
        "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = BeliefChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(significant_changes)} statistically significant stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in significant_changes:\n",
        "    print(f\"  {change['stance_before']} → {change['stance_after']} (magnitude: {change['magnitude']:.3f}, p={change['p_corrected']:.4f})\")"
      ],
      "id": "9e5cd23a3a61604c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 0 statistically significant stance changes for user HardCoreModerate on topic media and political commentary:\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "# Test with your existing significant change detection\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]\n",
        "\n",
        "# Get significant changes\n",
        "detector = BeliefChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "if significant_changes:\n",
        "    # Test the window extractor\n",
        "    extractor = ConversationWindowExtractor(corpus, timelines)\n",
        "    window_data = extractor.get_conversations_around_change(\n",
        "        user_id=user_id,\n",
        "        topic=topic,\n",
        "        change=significant_changes[0],\n",
        "        window_size=2  # 2 conversations before + 2 after\n",
        "    )\n",
        "\n",
        "    # Print summary\n",
        "    extractor.print_window_summary(window_data)\n",
        "else:\n",
        "    print(\"No significant changes found to test with\")"
      ],
      "metadata": {
        "id": "XkM5xlBWrl-X",
        "outputId": "94aff112-5932-44c9-d38c-2fdd9103a9eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XkM5xlBWrl-X",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No significant changes found to test with\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:46:54.285111Z",
          "start_time": "2025-07-14T10:46:54.278201Z"
        },
        "id": "d6a1cb6bb6b62c85",
        "outputId": "cbaf6df3-ad32-4863-c995-0c67b1df0fab"
      },
      "cell_type": "code",
      "source": [
        "# Most populated topic for a user\n",
        "def topic_with_most_contributions(user_id):\n",
        "    posts_in_topic = {}\n",
        "    for topic in timelines[user_id].keys():\n",
        "      posts_in_topic[topic] = len(list(timelines[user_id][topic]))\n",
        "    # key with the largest value\n",
        "    topic = max(posts_in_topic, key=posts_in_topic.get)\n",
        "\n",
        "    return topic, posts_in_topic[topic]\n",
        "\n",
        "# Yea the number came cause the posts_in_topic was not encapsulated\n",
        "user_id = 'HardCoreModerate'\n",
        "topic, number = topic_with_most_contributions(user_id)\n",
        "print(f\"{topic}: {number}\")\n",
        "# print(posts_in_topic)"
      ],
      "id": "d6a1cb6bb6b62c85",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "media and political commentary: 145\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cd56563c479c5f7f"
      },
      "cell_type": "code",
      "source": [
        "# Total number of users with metadata (unfiltered)\n",
        "print(len(timelines))"
      ],
      "id": "cd56563c479c5f7f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:51:13.890752Z",
          "start_time": "2025-07-14T10:51:13.850561Z"
        },
        "id": "484f1d1c47361a1f"
      },
      "cell_type": "code",
      "source": [
        "# NOT WORKING\n",
        "# user with the most utterances:\n",
        "# I have to find the max between their topics and then find the overall max\n",
        "users = {}\n",
        "for user_id, data in timelines.items():\n",
        "    topic, number = topic_with_most_contributions(user_id)\n",
        "    users[user_id] = topic\n",
        "    users[user_id][topic] = number\n",
        "\n",
        "for user in users:\n",
        "    print(user)\n",
        "# user_id = max(users, key=users.get)\n",
        "# print(f\"{user_id}: {users[user_id]}\")"
      ],
      "id": "484f1d1c47361a1f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-13T14:02:24.843970Z",
          "start_time": "2025-07-13T14:02:12.281770Z"
        },
        "id": "fa8987174cfc2918",
        "outputId": "8d33f8e0-0b83-4332-df71-6ee72803ad5c"
      },
      "cell_type": "code",
      "source": [
        "# Detect simple stance change:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=3, min_topics_per_user=1)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = BeliefChangeDetector()\n",
        "changes = detector.detect_simple_stance_changes(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(changes)} stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in changes:\n",
        "    print(f\"  {change['from_stance']} → {change['to_stance']} (magnitude: {change['change_magnitude']})\")"
      ],
      "id": "fa8987174cfc2918",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected 2 stance changes for user HardCoreModerate on topic taxation and government spending:\n",
            "  moderately_against → neutral (magnitude: 1)\n",
            "  neutral → moderately_against (magnitude: 1)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f414b5573c4a4ca6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# for user_id in"
      ],
      "id": "f414b5573c4a4ca6"
    },
    {
      "metadata": {
        "id": "ad5e6484d5f466e1"
      },
      "cell_type": "code",
      "source": [
        "# Run detection for all topics for a user - NOT TESTED:\n",
        "# Get complete user timeline\n",
        "user_timeline = timelines[\"pixel8\"]  # All topics for this user\n",
        "\n",
        "# Analyze changes across all topics\n",
        "detector = BeliefChangeDetector()\n",
        "all_changes = detector.analyze_user_belief_changes(user_timeline)\n",
        "\n",
        "# Results\n",
        "for topic, changes in all_changes.items():\n",
        "    print(f\"Topic: {topic}\")\n",
        "    for change in changes:\n",
        "        print(f\"  Change at position {change['position']}: magnitude {change['magnitude']}\")"
      ],
      "id": "ad5e6484d5f466e1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "76049e46c5223f2d"
      },
      "cell_type": "code",
      "source": [
        "# All users that meet the criteria:\n",
        "print(\"Available users:\")\n",
        "print(list(timelines.keys())[:20])"
      ],
      "id": "76049e46c5223f2d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ba90763c4b3d61ed"
      },
      "cell_type": "code",
      "source": [
        "# What topics the users have posted about:\n",
        "for user_id in list(timelines.keys())[:20]:  # Check first 5 users\n",
        "    topics = list(timelines[user_id].keys())\n",
        "    print(f\"{user_id}: {topics}\")\n",
        "    break"
      ],
      "id": "ba90763c4b3d61ed",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-07T12:45:16.821978Z",
          "start_time": "2025-07-07T12:45:16.653806Z"
        },
        "id": "1fee47509c799599",
        "outputId": "7e5ab68d-0188-48b4-d945-0687433058f6"
      },
      "cell_type": "code",
      "source": [
        "# confidence score:\n",
        "utterances = list(corpus.iter_utterances())\n",
        "print(utterances[1].meta)"
      ],
      "id": "1fee47509c799599",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvoKitMeta({'score': 29, 'top_level_comment': None, 'retrieved_on': -1, 'gilded': -1, 'gildings': None, 'subreddit': 'PoliticalDiscussion', 'stickied': False, 'permalink': '/r/PoliticalDiscussion/comments/nz1xu/congrats_rpoliticaldiscussion_you_are_turning/', 'author_flair_text': '', 'detected_stance': 'moderately_against', 'stance_confidence': 0.8540321985880533, 'stance_scores': {'strongly_favor': 0.0016047263949682626, 'moderately_favor': 0.5134096046288809, 'neutral': 0.0072105322033166885, 'moderately_against': 0.8540321985880533, 'strongly_against': 0.3021060957883795}})\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a81d7e7fa2b05740"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "a81d7e7fa2b05740"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}