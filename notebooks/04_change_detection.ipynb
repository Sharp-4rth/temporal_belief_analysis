{
  "cells": [
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:09:51.278612Z",
          "start_time": "2025-07-14T08:08:08.657634Z"
        },
        "id": "bbad0be784b4869a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5229595a-374e-46f9-ec25-c2212e0d9929"
      },
      "cell_type": "code",
      "source": [
        "# Need to restart after:\n",
        "!pip install convokit"
      ],
      "id": "bbad0be784b4869a",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: convokit in /usr/local/lib/python3.11/dist-packages (3.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.10.0)\n",
            "Requirement already satisfied: scipy>1.14 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.16.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.2.2)\n",
            "Requirement already satisfied: numpy>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.0.2)\n",
            "Requirement already satisfied: msgpack-numpy>=0.4.3.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.4.8)\n",
            "Requirement already satisfied: spacy>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.8.7)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.6.1)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.9.1)\n",
            "Requirement already satisfied: dill>=0.2.9 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.3.8)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.5.1)\n",
            "Requirement already satisfied: clean-text>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.6.0)\n",
            "Requirement already satisfied: unidecode>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from convokit) (1.4.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (4.67.1)\n",
            "Requirement already satisfied: pymongo>=4.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (4.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from convokit) (6.0.2)\n",
            "Requirement already satisfied: dnspython>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.7.0)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (8.3.6)\n",
            "Requirement already satisfied: h5py==3.12.1 in /usr/local/lib/python3.11/dist-packages (from convokit) (3.12.1)\n",
            "Requirement already satisfied: numexpr>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.11.0)\n",
            "Requirement already satisfied: ruff>=0.4.8 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.12.5)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from convokit) (1.4.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from convokit) (1.9.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (from convokit) (0.16.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from convokit) (0.46.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from convokit) (4.54.0)\n",
            "Requirement already satisfied: unsloth in /usr/local/lib/python3.11/dist-packages (from convokit) (2025.8.1)\n",
            "Requirement already satisfied: trl>=0.12.2 in /usr/local/lib/python3.11/dist-packages (from convokit) (0.20.0)\n",
            "Requirement already satisfied: tensorflow>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.18.0)\n",
            "Requirement already satisfied: tf-keras<3.0.0,>=2.17.0 in /usr/local/lib/python3.11/dist-packages (from convokit) (2.18.0)\n",
            "Requirement already satisfied: emoji<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from clean-text>=0.6.0->convokit) (1.7.0)\n",
            "Requirement already satisfied: ftfy<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from clean-text>=0.6.0->convokit) (6.3.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->convokit) (2.9.0.post0)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.4->convokit) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.4->convokit) (2024.11.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.0->convokit) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0->convokit) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.0.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3.8.2->convokit) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (5.29.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (1.74.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (3.8.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=2.18.0->convokit) (0.37.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.0->convokit) (0.1.5)\n",
            "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from trl>=0.12.2->convokit) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (2.7.1)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (0.34.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate->convokit) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->convokit) (3.18.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->convokit) (0.21.2)\n",
            "Requirement already satisfied: unsloth_zoo>=2025.8.1 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (2025.8.1)\n",
            "Requirement already satisfied: xformers>=0.0.27.post2 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.0.31.post1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (3.3.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.9.27)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.45.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.34.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth->convokit) (0.22.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (18.1.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl>=0.12.2->convokit) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2025.3.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.13)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate->convokit) (1.1.5)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3.8.2->convokit) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.8.2->convokit) (2025.7.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=2.18.0->convokit) (3.1.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate->convokit) (1.11.1.6)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3.8.2->convokit) (1.5.4)\n",
            "Requirement already satisfied: cut_cross_entropy in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.1->unsloth->convokit) (25.1.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.8.1->unsloth->convokit) (0.19.0)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3.8.2->convokit) (7.3.0.post1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth->convokit) (8.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=3.8.2->convokit) (3.0.2)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth->convokit) (0.17.0)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth->convokit) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth->convokit) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (3.12.14)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3.8.2->convokit) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (2.19.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate->convokit) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth->convokit) (3.23.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl>=0.12.2->convokit) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.18.0->convokit) (0.1.2)\n"
          ]
        }
      ],
      "execution_count": 88
    },
    {
      "cell_type": "code",
      "source": [
        "# Download file from Google Drive to colab directory\n",
        "!pip install gdown\n",
        "file_id = \"1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\"\n",
        "!gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\" --fuzzy"
      ],
      "metadata": {
        "id": "oJ1WKmwwZQYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e73a1a0a-04f3-4a8c-e193-2e99318960e6"
      },
      "id": "oJ1WKmwwZQYL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.7.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\n",
            "From (redirected): https://drive.google.com/uc?id=1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0&confirm=t&uuid=178229c8-aeb6-45c5-8810-6afadafc769c\n",
            "To: /content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\n",
            "100% 841M/841M [00:07<00:00, 112MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip with python:\n",
        "import zipfile\n",
        "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")"
      ],
      "metadata": {
        "id": "B2PlEx8QYzgg"
      },
      "id": "B2PlEx8QYzgg",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For runpod-jupyter or local (run twice)\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Change to the correct working directory (workspace if runpod, content if colab)\n",
        "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
        "print(\"Changed working directory to:\", os.getcwd())\n",
        "\n",
        "# Absolute path to src directory\n",
        "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
        "if src_path not in sys.path:\n",
        "    sys.path.insert(0, src_path)\n",
        "\n",
        "# Comment out if in colab:\n",
        "from temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "_yv_LVXGjggY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "add1a663-a877-4561-ac6e-9a5c03a0f402"
      },
      "id": "_yv_LVXGjggY",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For colab:\n",
        "from temporal_belief_analysis.src.temporal_belief.core.timeline_building import TimelineBuilder"
      ],
      "metadata": {
        "id": "3sIZWUc9i5WL"
      },
      "id": "3sIZWUc9i5WL",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "22220bf09f61753c"
      },
      "cell_type": "code",
      "source": [
        "# Run twice\n",
        "# import unsloth\n",
        "# import unsloth_zoo\n",
        "from convokit import Corpus, download\n",
        "import convokit"
      ],
      "id": "22220bf09f61753c",
      "outputs": [],
      "execution_count": 89
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "781d4e0509ad3c21",
        "outputId": "60a0b792-c22e-4ce7-9b35-672030de3499"
      },
      "cell_type": "code",
      "source": [
        "# Load a corpus:\n",
        "# corpus = Corpus(filename=\"/Users/leonidas/.convokit/saved-corpora/pd_corpus_with_stances1000_chronological\")\n",
        "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological\")"
      ],
      "id": "781d4e0509ad3c21",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No configuration file found at /root/.convokit/config.yml; writing with contents: \n",
            "# Default Backend Parameters\n",
            "db_host: localhost:27017\n",
            "data_directory: ~/.convokit/saved-corpora\n",
            "model_directory: ~/.convokit/saved-models\n",
            "default_backend: mem\n"
          ]
        }
      ],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus.meta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "31uKA6O37H9J",
        "outputId": "8b069b1b-1b74-4690-b2aa-591436b14b01"
      },
      "id": "31uKA6O37H9J",
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvoKitMeta({'subreddit': 'PoliticalDiscussion', 'num_posts': 102848, 'num_comments': 4553046})\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T08:17:28.390010Z",
          "start_time": "2025-07-14T08:17:20.788691Z"
        },
        "id": "ad611eb7998835c2"
      },
      "cell_type": "code",
      "source": [
        "!pip install scipy\n",
        "!pip install statsmodels"
      ],
      "id": "ad611eb7998835c2",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.170080Z",
          "start_time": "2025-07-14T10:26:41.164333Z"
        },
        "id": "de0d75b2335f7dce"
      },
      "cell_type": "code",
      "source": [
        "def filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2, min_confidence=0.0):\n",
        "    \"\"\"Filter timelines to only include users/topics suitable for change detection\"\"\"\n",
        "    filtered_timelines = {}\n",
        "\n",
        "    for user_id, user_timeline in timelines.items():\n",
        "        filtered_user_timeline = {}\n",
        "\n",
        "        for topic, topic_posts in user_timeline.items():\n",
        "            # Filter by confidence (if you have access to corpus here)\n",
        "            reliable_posts = {}\n",
        "            for utt_id, stance in topic_posts.items():\n",
        "                # You'd need to pass corpus or confidence scores here\n",
        "                # For now, assume all posts are reliable\n",
        "                reliable_posts[utt_id] = stance\n",
        "\n",
        "            # Check minimum posts per topic\n",
        "            if len(reliable_posts) >= min_posts_per_topic:\n",
        "                filtered_user_timeline[topic] = reliable_posts\n",
        "\n",
        "        # Check minimum topics per user\n",
        "        if len(filtered_user_timeline) >= min_topics_per_user:\n",
        "            filtered_timelines[user_id] = filtered_user_timeline\n",
        "\n",
        "    return filtered_timelines"
      ],
      "id": "de0d75b2335f7dce",
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "class ConversationWindowExtractor:\n",
        "    def __init__(self, corpus, timelines):\n",
        "        self.corpus = corpus\n",
        "        self.timelines = timelines\n",
        "\n",
        "    def get_user_conversations_chronological(self, corpus, speaker_id):\n",
        "      \"\"\"Get all conversations for a user in chronological order.\"\"\"\n",
        "\n",
        "      # Get all conversations where the speaker participated\n",
        "      user_conversations = [convo for convo in corpus.iter_conversations()\n",
        "                          if speaker_id in [utt.speaker.id for utt in convo.iter_utterances()]]\n",
        "\n",
        "      # Sort conversations by their earliest timestamp\n",
        "      user_conversations.sort(key=lambda convo: min(utt.timestamp for utt in convo.iter_utterances()))\n",
        "\n",
        "      return user_conversations\n",
        "\n",
        "    def get_conversation_around_change_point(self, corpus, change_points):\n",
        "\n",
        "      # Get first change (probably only one I need)\n",
        "      utterance = corpus.get_utterance(change_points[0][1])\n",
        "\n",
        "      # Find the convo this utterance belongs to:\n",
        "      conversation = utterance.get_conversation()\n",
        "\n",
        "      # Put all user's convos in a list\n",
        "      speaker_id = utterance.speaker.id\n",
        "      user_conversations = self.get_user_conversations_chronological(corpus, speaker_id)\n",
        "\n",
        "      recent_convos = []\n",
        "      # find the index of the convo, and return the convo id of the 3 prior convos\n",
        "      for i, convo in enumerate(user_conversations):\n",
        "        if conversation.id == user_conversations[i].id:\n",
        "          recent_convos.append(user_conversations[i-2])\n",
        "          recent_convos.append(user_conversations[i-1])\n",
        "\n",
        "      # Append the first convo at the end so they are in chronological order\n",
        "      recent_convos.append(conversation)\n",
        "\n",
        "      return recent_convos\n",
        "\n",
        "    def get_conversations_around_change(self, user_id, topic, change, window_size=3):\n",
        "        \"\"\"\n",
        "        Get conversations before/after a belief change based on conversation count\n",
        "\n",
        "        Args:\n",
        "            user_id: The user who had the belief change\n",
        "            topic: The topic where change occurred\n",
        "            change: The significant change object from detect_changes_with_significance()\n",
        "            window_size: Number of conversations before AND after change to include\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                'before_change': [conversation_data, ...],\n",
        "                'after_change': [conversation_data, ...],\n",
        "                'change_position': int,\n",
        "                'change_utterance_id': str\n",
        "            }\n",
        "        \"\"\"\n",
        "\n",
        "        # Get ordered timeline for this user/topic\n",
        "        topic_timeline = self.timelines[user_id][topic]\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "\n",
        "        # Find position of the change utterance\n",
        "        change_utterance_id = change['utterance_id']\n",
        "        change_position = None\n",
        "\n",
        "        for i, (utterance_id, stance) in enumerate(timeline_items):\n",
        "            if utterance_id == change_utterance_id:\n",
        "                change_position = i\n",
        "                break\n",
        "\n",
        "        if change_position is None:\n",
        "            print(f\"Warning: Change utterance {change_utterance_id} not found in timeline\")\n",
        "            return None\n",
        "\n",
        "        print(f\"Found change at position {change_position} of {len(timeline_items)} total utterances\")\n",
        "\n",
        "        # Extract conversations in window\n",
        "        before_conversations = []\n",
        "        after_conversations = []\n",
        "\n",
        "        # Get conversations BEFORE change\n",
        "        start_before = max(0, change_position - window_size)\n",
        "        print(f\"Looking for conversations before change: positions {start_before} to {change_position-1}\")\n",
        "\n",
        "        for i in range(start_before, change_position):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                before_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation before: {conv_data['conversation_id']}\")\n",
        "\n",
        "        # Get conversations AFTER change\n",
        "        end_after = min(len(timeline_items), change_position + window_size + 1)\n",
        "        print(f\"Looking for conversations after change: positions {change_position+1} to {end_after-1}\")\n",
        "\n",
        "        for i in range(change_position + 1, end_after):\n",
        "            utterance_id = timeline_items[i][0]\n",
        "            conv_data = self._extract_conversation_from_utterance(utterance_id, user_id)\n",
        "            if conv_data:\n",
        "                after_conversations.append(conv_data)\n",
        "                print(f\"  Found conversation after: {conv_data['conversation_id']}\")\n",
        "\n",
        "        return {\n",
        "            'before_change': before_conversations,\n",
        "            'after_change': after_conversations,\n",
        "            'change_position': change_position,\n",
        "            'change_utterance_id': change_utterance_id,\n",
        "            'total_timeline_length': len(timeline_items),\n",
        "            'window_size': window_size\n",
        "        }\n",
        "\n",
        "    def _extract_conversation_from_utterance(self, utterance_id, user_id):\n",
        "        \"\"\"Extract conversation data from a specific utterance\"\"\"\n",
        "        try:\n",
        "            utterance = self.corpus.get_utterance(utterance_id)\n",
        "            if not utterance:\n",
        "                return None\n",
        "\n",
        "            conversation = utterance.get_conversation()\n",
        "            if not conversation:\n",
        "                return None\n",
        "\n",
        "            op_post = conversation.get_root()\n",
        "            if not op_post:\n",
        "                return None\n",
        "\n",
        "            user_replies = []\n",
        "\n",
        "            # Get ALL user replies in this conversation (not just the target utterance)\n",
        "            for utt in conversation.iter_utterances():\n",
        "                if utt.speaker.id == user_id and utt.id != op_post.id:\n",
        "                    user_replies.append(utt)\n",
        "\n",
        "            if not user_replies:\n",
        "                return None\n",
        "\n",
        "            return {\n",
        "                'conversation_id': conversation.id,\n",
        "                'op_post': op_post,\n",
        "                'user_replies': user_replies,\n",
        "                'target_utterance_id': utterance_id,  # Which utterance led us to this conversation\n",
        "                'topic': conversation.meta.get('detected_topic', 'unknown') if conversation.meta else 'unknown'\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting conversation for utterance {utterance_id}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def extract_rooted_path_units_from_window(self, window_data):\n",
        "        \"\"\"\n",
        "        Extract rooted path units from conversations around a belief change.\n",
        "        Uses your existing conversation extraction approach.\n",
        "        \"\"\"\n",
        "        def process_conversations(conversations):\n",
        "            processed = []\n",
        "\n",
        "            for conv_data in conversations:\n",
        "                # Use the conversation you ALREADY extracted in your working method\n",
        "                conversation = conv_data['op_post'].get_conversation()  # Your existing approach\n",
        "\n",
        "                if not conversation:\n",
        "                    continue\n",
        "\n",
        "                # Extract rooted path units for this conversation\n",
        "                rooted_units = self._extract_rooted_units_from_conversation(conversation)\n",
        "\n",
        "                # Get OP text\n",
        "                op_text = conv_data['op_post'].text if conv_data['op_post'] else \"\"\n",
        "\n",
        "                processed.append({\n",
        "                    'conversation_id': conv_data['conversation_id'],\n",
        "                    'rooted_units': rooted_units,\n",
        "                    'op_text': op_text,\n",
        "                    'topic': conv_data.get('topic', 'unknown'),\n",
        "                    'original_conv_data': conv_data\n",
        "                })\n",
        "\n",
        "            return processed\n",
        "\n",
        "        return {\n",
        "            'before_change': process_conversations(window_data['before_change']),\n",
        "            'after_change': process_conversations(window_data['after_change']),\n",
        "            'change_info': {\n",
        "                'change_position': window_data['change_position'],\n",
        "                'change_utterance_id': window_data['change_utterance_id']\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def _extract_rooted_units_from_conversation(self, conversation):\n",
        "        \"\"\"\n",
        "        Extract rooted path units from a single conversation.\n",
        "        Every speaker gets their own rooted path unit.\n",
        "\n",
        "        Returns:\n",
        "            dict: {speaker_id: [list_of_utterances]}\n",
        "        \"\"\"\n",
        "        rooted_units = {}\n",
        "\n",
        "        for utterance in conversation.iter_utterances():\n",
        "            speaker_id = utterance.speaker.id\n",
        "\n",
        "            if speaker_id not in rooted_units:\n",
        "                rooted_units[speaker_id] = []\n",
        "\n",
        "            rooted_units[speaker_id].append(utterance)\n",
        "\n",
        "        return rooted_units\n",
        "\n",
        "    def preprocess_rooted_units_for_interplay(self, rooted_units_data):\n",
        "        \"\"\"\n",
        "        Preprocess rooted path units for linguistic interplay calculation.\n",
        "\n",
        "        Args:\n",
        "            rooted_units_data: Output from extract_rooted_path_units_from_window()\n",
        "\n",
        "        Returns:\n",
        "            {\n",
        "                'before_change': [\n",
        "                    {\n",
        "                        'conversation_id': str,\n",
        "                        'interplay_pairs': [\n",
        "                            {\n",
        "                                'speaker_id': str,\n",
        "                                'unit_text': str,  # Combined text of all speaker's utterances\n",
        "                                'op_text': str,    # Original post text\n",
        "                                'num_utterances': int\n",
        "                            }, ...\n",
        "                        ]\n",
        "                    }, ...\n",
        "                ],\n",
        "                'after_change': [...] # same structure\n",
        "            }\n",
        "        \"\"\"\n",
        "        def process_rooted_units(conversations_with_units):\n",
        "            processed = []\n",
        "\n",
        "            for conv_data in conversations_with_units:\n",
        "                interplay_pairs = []\n",
        "\n",
        "                for speaker_id, utterances in conv_data['rooted_units'].items():\n",
        "                    # Combine all utterances from this speaker\n",
        "                    unit_text = self._combine_utterances_text(utterances)\n",
        "\n",
        "                    interplay_pairs.append({\n",
        "                        'speaker_id': speaker_id,\n",
        "                        'unit_text': unit_text,\n",
        "                        'op_text': conv_data['op_text'],\n",
        "                        'num_utterances': len(utterances)\n",
        "                    })\n",
        "\n",
        "                processed.append({\n",
        "                    'conversation_id': conv_data['conversation_id'],\n",
        "                    'topic': conv_data['topic'],\n",
        "                    'interplay_pairs': interplay_pairs\n",
        "                })\n",
        "\n",
        "            return processed\n",
        "\n",
        "        return {\n",
        "            'before_change': process_rooted_units(rooted_units_data['before_change']),\n",
        "            'after_change': process_rooted_units(rooted_units_data['after_change']),\n",
        "            'change_info': rooted_units_data['change_info']\n",
        "        }\n",
        "\n",
        "    def _combine_utterances_text(self, utterances):\n",
        "        \"\"\"\n",
        "        Combine all utterances from a speaker into one text block.\n",
        "\n",
        "        Args:\n",
        "            utterances: List of ConvoKit utterances\n",
        "\n",
        "        Returns:\n",
        "            str: Combined text\n",
        "        \"\"\"\n",
        "        return \" \".join([utt.text for utt in utterances])\n",
        "\n",
        "\n",
        "    def print_window_summary(self, window_data):\n",
        "        \"\"\"Helper method to print a summary of extracted conversations\"\"\"\n",
        "        if not window_data:\n",
        "            print(\"No window data to summarize\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\n=== Conversation Window Summary ===\")\n",
        "        print(f\"Change occurred at position {window_data['change_position']} of {window_data['total_timeline_length']} utterances\")\n",
        "        print(f\"Change utterance ID: {window_data['change_utterance_id']}\")\n",
        "        print(f\"Window size: {window_data.get('window_size', 'unknown')}\")\n",
        "\n",
        "        print(f\"\\nConversations BEFORE change: {len(window_data['before_change'])}\")\n",
        "        for i, conv in enumerate(window_data['before_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")\n",
        "\n",
        "        print(f\"\\nConversations AFTER change: {len(window_data['after_change'])}\")\n",
        "        for i, conv in enumerate(window_data['after_change']):\n",
        "            print(f\"  {i+1}. Conversation {conv['conversation_id']}: {len(conv['user_replies'])} user replies\")"
      ],
      "metadata": {
        "id": "zj51bpjrpjTd"
      },
      "id": "zj51bpjrpjTd",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2025-07-14T10:26:41.492540Z",
          "start_time": "2025-07-14T10:26:41.473273Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats import ttest_ind, mannwhitneyu\n",
        "from statsmodels.stats.multitest import fdrcorrection\n",
        "from collections import Counter\n",
        "import logging\n",
        "\n",
        "class ChangeDetector:\n",
        "    \"\"\"Sliding window change detection with proper statistical significance.\"\"\"\n",
        "\n",
        "    def __init__(self, window_size=3, significance_level=0.05):\n",
        "        self.window_size = window_size\n",
        "        self.alpha = significance_level\n",
        "        self.stance_values = {\n",
        "            'strongly_against': -2, 'moderately_against': -1,\n",
        "            'neutral': 0, 'moderately_favor': 1, 'strongly_favor': 2\n",
        "        }\n",
        "\n",
        "    def detect_simple_stance_changes(self, topic_timeline):\n",
        "\n",
        "        if len(topic_timeline) < 2:\n",
        "            return []\n",
        "\n",
        "        changes = []\n",
        "        timeline_items = list(topic_timeline.items())  # Convert to list of (utterance_id, stance) pairs\n",
        "\n",
        "        for i in range(1, len(timeline_items)):\n",
        "            current_utterance_id, current_stance = timeline_items[i]\n",
        "            previous_utterance_id, previous_stance = timeline_items[i-1]\n",
        "\n",
        "            # Check if stance changed\n",
        "            if current_stance != previous_stance:\n",
        "                change = {\n",
        "                    'position': i,\n",
        "                    'current_utterance_id': current_utterance_id,\n",
        "                    'previous_utterance_id': previous_utterance_id,\n",
        "                    'from_stance': previous_stance,\n",
        "                    'to_stance': current_stance,\n",
        "                    'change_type': self._classify_change_direction(previous_stance, current_stance),\n",
        "                    'change_magnitude': self._calculate_simple_magnitude(previous_stance, current_stance)\n",
        "                }\n",
        "                changes.append(change)\n",
        "\n",
        "        return changes\n",
        "\n",
        "    def detect_persistent_changes(self, topic_timeline):\n",
        "        \"\"\"Detect persistent changes in stance.\"\"\"\n",
        "\n",
        "        # Convert to (utt_id, detected_stance) tuple\n",
        "        topic_timeline_list = list(topic_timeline.items())\n",
        "\n",
        "        # Collect the tuples where the stance is persistent across n utterances\n",
        "        change_points = []\n",
        "\n",
        "        for i in range(len(topic_timeline)):\n",
        "          # if current stance is different than prior\n",
        "          if topic_timeline[i][1] != topic_timeline[i-1][1]:\n",
        "            # Check if change persists for more than 1 post\n",
        "            if topic_timeline[i][1] == topic_timeline[i+1][1]:\n",
        "              change_index = i\n",
        "              utt_id = topic_timeline[i][0]\n",
        "              change_point = (change_index, utt_id)\n",
        "              change_points.append(change_point)\n",
        "              print(f\"Current:{topic_timeline[i][1]}, Previous: {topic_timeline[i-1][1]} and Next:{topic_timeline[i+1][1]}\")\n",
        "\n",
        "        return change_points\n",
        "\n",
        "    def _classify_change_direction(self, from_stance, to_stance):\n",
        "        \"\"\"Classify the direction of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "\n",
        "        if to_value > from_value:\n",
        "            return 'more_favorable'\n",
        "        elif to_value < from_value:\n",
        "            return 'less_favorable'\n",
        "        else:\n",
        "            return 'neutral_shift'\n",
        "\n",
        "    def _calculate_simple_magnitude(self, from_stance, to_stance):\n",
        "        \"\"\"Calculate the magnitude of stance change.\"\"\"\n",
        "        from_value = self.stance_values.get(from_stance, 0)\n",
        "        to_value = self.stance_values.get(to_stance, 0)\n",
        "        return abs(to_value - from_value)\n",
        "\n",
        "    def detect_changes_with_significance(self, topic_timeline):\n",
        "        \"\"\"Detect changes with statistical significance testing.\"\"\"\n",
        "\n",
        "        if len(topic_timeline) < self.window_size * 2:\n",
        "            return [], [], []\n",
        "\n",
        "        # Convert to lists to maintain order and get IDs\n",
        "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
        "        stance_sequence = [self.stance_values.get(stance, 0) for _, stance in timeline_items]\n",
        "\n",
        "        potential_changes = []\n",
        "        p_values = []\n",
        "\n",
        "        # Sliding window approach\n",
        "        for i in range(self.window_size, len(stance_sequence) - self.window_size):\n",
        "\n",
        "            # Left window (before potential change)\n",
        "            left_window = stance_sequence[i - self.window_size:i]\n",
        "\n",
        "            # Right window (after potential change)\n",
        "            right_window = stance_sequence[i:i + self.window_size]\n",
        "\n",
        "            # Statistical test: Are these two windows significantly different?\n",
        "            statistic, p_value = self.two_sample_test(left_window, right_window)\n",
        "\n",
        "            p_values.append(p_value)\n",
        "\n",
        "            # Store potential change info with just the key utterance ID\n",
        "            change_magnitude = abs(np.mean(right_window) - np.mean(left_window))\n",
        "            potential_changes.append({\n",
        "                'position': i,\n",
        "                'utterance_id': timeline_items[i][0],  # The utterance where change detected\n",
        "                'p_value': p_value,\n",
        "                'test_statistic': statistic,\n",
        "                'magnitude': change_magnitude,\n",
        "                'left_mean': np.mean(left_window),\n",
        "                'right_mean': np.mean(right_window),\n",
        "                'left_window': left_window.copy(),\n",
        "                'right_window': right_window.copy()\n",
        "            })\n",
        "\n",
        "        # Apply FDR correction to all p-values\n",
        "        if not p_values:\n",
        "            return [], [], []\n",
        "\n",
        "        rejected, p_corrected = self.multiple_testing_correction(p_values)\n",
        "\n",
        "        # Keep only changes that survive FDR correction\n",
        "        significant_changes = []\n",
        "        for i, change in enumerate(potential_changes):\n",
        "            if rejected[i]:  # Survives FDR correction\n",
        "                change.update({\n",
        "                    'p_corrected': p_corrected[i],\n",
        "                    'statistically_significant': True,\n",
        "                    'survives_fdr_correction': True,\n",
        "                    'significance_level': self.alpha\n",
        "                })\n",
        "                significant_changes.append(change)\n",
        "\n",
        "        return significant_changes, p_values, p_corrected\n",
        "\n",
        "    def two_sample_test(self, left_window, right_window):\n",
        "        \"\"\"Statistical test for difference between two windows.\"\"\"\n",
        "        # Use Mann-Whitney U test (non-parametric, more robust)\n",
        "        try:\n",
        "            statistic, p_value = mannwhitneyu(left_window, right_window,\n",
        "                                            alternative='two-sided')\n",
        "            return statistic, p_value\n",
        "        except ValueError:\n",
        "            # Fallback to t-test if Mann-Whitney fails\n",
        "            statistic, p_value = ttest_ind(left_window, right_window)\n",
        "            return statistic, p_value\n",
        "\n",
        "    def multiple_testing_correction(self, p_values):\n",
        "        \"\"\"Correct for multiple testing using Benjamini-Hochberg.\"\"\"\n",
        "        rejected, p_corrected = fdrcorrection(p_values, alpha=self.alpha)\n",
        "        return rejected, p_corrected\n",
        "\n",
        "    # def analyze_user_belief_changes(self, user_timeline):\n",
        "    #     \"\"\"Analyze belief changes across all topics for a user.\"\"\"\n",
        "    #     all_changes = {}\n",
        "    #\n",
        "    #     for topic, topic_timeline in user_timeline.items():\n",
        "    #         changes = self.detect_changes_with_significance(topic_timeline)\n",
        "    #         all_changes[topic] = changes\n",
        "    #\n",
        "    #     return all_changes\n",
        "\n",
        "    def analyze_user_belief_changes(self, user_timeline):\n",
        "        \"\"\"Analyze belief changes across all topics for a user.\n",
        "\n",
        "        Args:\n",
        "            user_timeline: Dict of {topic: {utterance_id: stance}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by topic and total count\n",
        "        \"\"\"\n",
        "        all_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for topic, topic_timeline in user_timeline.items():\n",
        "            significant_changes, p_values, p_corrected = self.detect_changes_with_significance(topic_timeline)\n",
        "            all_changes[topic] = significant_changes\n",
        "            total_changes += len(significant_changes)\n",
        "\n",
        "        return {\n",
        "            'changes_by_topic': all_changes,\n",
        "            'total_changes': total_changes\n",
        "        }\n",
        "\n",
        "    def analyze_all_users_belief_changes(self, timelines):\n",
        "        \"\"\"Analyze belief changes across all users.\n",
        "\n",
        "        Args:\n",
        "            timelines: Dict of {user_id: {topic: {utterance_id: stance}}}\n",
        "\n",
        "        Returns:\n",
        "            Dict with changes by user and total count\n",
        "        \"\"\"\n",
        "        all_user_changes = {}\n",
        "        total_changes = 0\n",
        "\n",
        "        for user_id, user_timeline in timelines.items():\n",
        "            user_result = self.analyze_user_belief_changes(user_timeline)\n",
        "            all_user_changes[user_id] = user_result\n",
        "            total_changes += user_result['total_changes']\n",
        "\n",
        "        return {\n",
        "            'changes_by_user': all_user_changes,\n",
        "            'total_changes': total_changes\n",
        "        }"
      ],
      "outputs": [],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7P9oCLaSGrER"
      },
      "id": "7P9oCLaSGrER",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mock corpus-like objects for testing\n",
        "class MockUtterance:\n",
        "    def __init__(self, id, speaker_id, text, timestamp, conversation):\n",
        "        self.id = id\n",
        "        self.speaker = MockSpeaker(speaker_id)\n",
        "        self.text = text\n",
        "        self.timestamp = timestamp\n",
        "        self._conversation = conversation\n",
        "\n",
        "    def get_conversation(self):\n",
        "        return self._conversation\n",
        "\n",
        "class MockSpeaker:\n",
        "    def __init__(self, speaker_id):\n",
        "        self.id = speaker_id\n",
        "\n",
        "class MockConversation:\n",
        "    def __init__(self, id, root_post, all_utterances):\n",
        "        self.id = id\n",
        "        self._root = root_post\n",
        "        self._utterances = all_utterances\n",
        "        self.meta = {'detected_topic': 'taxation and government spending'}\n",
        "\n",
        "    def get_root(self):\n",
        "        return self._root\n",
        "\n",
        "    def iter_utterances(self):\n",
        "        return iter(self._utterances)\n",
        "\n",
        "class MockCorpus:\n",
        "    def __init__(self):\n",
        "        # Create mock conversations with realistic political discussion\n",
        "        self.utterances = {}\n",
        "        self.conversations = {}\n",
        "        self._setup_mock_data()\n",
        "\n",
        "    def get_utterance(self, utterance_id):\n",
        "        return self.utterances.get(utterance_id)\n",
        "\n",
        "    def _setup_mock_data(self):\n",
        "        # Create 3 conversations for testing\n",
        "\n",
        "        # Conversation 1: Tax policy discussion\n",
        "        conv1_utterances = []\n",
        "        op1 = MockUtterance(\n",
        "            id=\"op_conv1\",\n",
        "            speaker_id=\"original_poster_1\",\n",
        "            text=\"I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't working.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply1 = MockUtterance(\n",
        "            id=\"user_reply_conv1\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt economic growth.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv1_utterances = [op1, user_reply1]\n",
        "        conv1 = MockConversation(\"conv_1\", op1, conv1_utterances)\n",
        "\n",
        "        # Set conversation references\n",
        "        for utt in conv1_utterances:\n",
        "            utt._conversation = conv1\n",
        "\n",
        "        # Conversation 2: Healthcare spending\n",
        "        op2 = MockUtterance(\n",
        "            id=\"op_conv2\",\n",
        "            speaker_id=\"original_poster_2\",\n",
        "            text=\"Government healthcare spending is out of control. We need to cut Medicare and focus on private solutions.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply2 = MockUtterance(\n",
        "            id=\"user_reply_conv2\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without reducing benefits.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv2_utterances = [op2, user_reply2]\n",
        "        conv2 = MockConversation(\"conv_2\", op2, conv2_utterances)\n",
        "\n",
        "        for utt in conv2_utterances:\n",
        "            utt._conversation = conv2\n",
        "\n",
        "        # Conversation 3: Budget discussion\n",
        "        op3 = MockUtterance(\n",
        "            id=\"op_conv3\",\n",
        "            speaker_id=\"original_poster_3\",\n",
        "            text=\"The federal budget deficit is unsustainable. We need major spending cuts across all departments.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        user_reply3 = MockUtterance(\n",
        "            id=\"user_reply_conv3\",\n",
        "            speaker_id=\"TestUser\",\n",
        "            text=\"You're absolutely right. Government spending is completely out of control and we need dramatic cuts immediately.\",\n",
        "            timestamp=None,\n",
        "            conversation=None\n",
        "        )\n",
        "\n",
        "        conv3_utterances = [op3, user_reply3]\n",
        "        conv3 = MockConversation(\"conv_3\", op3, conv3_utterances)\n",
        "\n",
        "        for utt in conv3_utterances:\n",
        "            utt._conversation = conv3\n",
        "\n",
        "        # Store all utterances and conversations\n",
        "        all_utterances = conv1_utterances + conv2_utterances + conv3_utterances\n",
        "        for utt in all_utterances:\n",
        "            self.utterances[utt.id] = utt\n",
        "\n",
        "        self.conversations[\"conv_1\"] = conv1\n",
        "        self.conversations[\"conv_2\"] = conv2\n",
        "        self.conversations[\"conv_3\"] = conv3\n",
        "\n",
        "# Mock timeline data showing a clear stance change\n",
        "mock_timelines = {\n",
        "    \"TestUser\": {\n",
        "        \"taxation and government spending\": {\n",
        "            \"user_reply_conv1\": \"moderately_against\",  # Position 0: Against tax increases\n",
        "            \"user_reply_conv2\": \"neutral\",             # Position 1: Moderate on spending\n",
        "            \"user_reply_conv3\": \"strongly_against\"     # Position 2: Strong anti-spending (CHANGE HERE)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Mock significant change (what your detector would return)\n",
        "mock_significant_change = {\n",
        "    'position': 2,\n",
        "    'utterance_id': 'user_reply_conv3',  # The utterance where change was detected\n",
        "    'p_value': 0.023,\n",
        "    'p_corrected': 0.041,\n",
        "    'magnitude': 1.5,\n",
        "    'left_mean': -0.5,   # Was moderate\n",
        "    'right_mean': -2.0,  # Became strongly against\n",
        "    'statistically_significant': True,\n",
        "    'survives_fdr_correction': True\n",
        "}\n",
        "\n",
        "print(\"Mock data created!\")\n",
        "print(\"Timeline:\", mock_timelines[\"TestUser\"][\"taxation and government spending\"])\n",
        "print(\"Significant change detected at:\", mock_significant_change['utterance_id'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HQw0IptDszKn",
        "outputId": "87ab9249-1b51-4a8f-df39-17889ec59bf1"
      },
      "id": "HQw0IptDszKn",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mock data created!\n",
            "Timeline: {'user_reply_conv1': 'moderately_against', 'user_reply_conv2': 'neutral', 'user_reply_conv3': 'strongly_against'}\n",
            "Significant change detected at: user_reply_conv3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test WindowExtractor with mock data\n",
        "mock_corpus = MockCorpus()\n",
        "\n",
        "# Create extractor with mock data\n",
        "extractor = ConversationWindowExtractor(mock_corpus, mock_timelines)\n",
        "\n",
        "# Test extraction around the significant change\n",
        "window_data = extractor.get_conversations_around_change(\n",
        "    user_id=\"TestUser\",\n",
        "    topic=\"taxation and government spending\",\n",
        "    change=mock_significant_change,\n",
        "    window_size=2\n",
        ")\n",
        "\n",
        "rooted_units_data = extractor.extract_rooted_path_units_from_window(window_data)\n",
        "\n",
        "\n",
        "# Preprocessing\n",
        "interplay_data = extractor.preprocess_rooted_units_for_interplay(rooted_units_data)\n",
        "\n",
        "# Print results\n",
        "if window_data:\n",
        "    extractor.print_window_summary(window_data)\n",
        "\n",
        "    # Show actual conversation content\n",
        "    print(\"\\n=== Conversation Content ===\")\n",
        "\n",
        "    print(\"\\nBEFORE change conversations:\")\n",
        "    for i, conv in enumerate(window_data['before_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "    print(\"\\nAFTER change conversations:\")\n",
        "    for i, conv in enumerate(window_data['after_change']):\n",
        "        print(f\"\\nConversation {i+1} ({conv['conversation_id']}):\")\n",
        "        print(f\"OP: {conv['op_post'].text[:100]}...\")\n",
        "        print(f\"User: {conv['user_replies'][0].text[:100]}...\")\n",
        "\n",
        "else:\n",
        "    print(\"No window data extracted - check for errors\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6bvbM-s4XZ",
        "outputId": "01f57637-ac0c-4e2f-aa0e-015361b64609"
      },
      "id": "3W6bvbM-s4XZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found change at position 2 of 3 total utterances\n",
            "Looking for conversations before change: positions 0 to 1\n",
            "  Found conversation before: conv_1\n",
            "  Found conversation before: conv_2\n",
            "Looking for conversations after change: positions 3 to 2\n",
            "\n",
            "=== Conversation Window Summary ===\n",
            "Change occurred at position 2 of 3 utterances\n",
            "Change utterance ID: user_reply_conv3\n",
            "Window size: 2\n",
            "\n",
            "Conversations BEFORE change: 2\n",
            "  1. Conversation conv_1: 1 user replies\n",
            "  2. Conversation conv_2: 1 user replies\n",
            "\n",
            "Conversations AFTER change: 0\n",
            "\n",
            "=== Conversation Content ===\n",
            "\n",
            "BEFORE change conversations:\n",
            "\n",
            "Conversation 1 (conv_1):\n",
            "OP: I think we should raise taxes on the wealthy to fund infrastructure. The current system isn't workin...\n",
            "User: I disagree with raising taxes. The wealthy already pay their fair share and higher taxes will hurt e...\n",
            "\n",
            "Conversation 2 (conv_2):\n",
            "OP: Government healthcare spending is out of control. We need to cut Medicare and focus on private solut...\n",
            "User: Medicare is essential for seniors. We shouldn't cut it, but maybe we can find efficiencies without r...\n",
            "\n",
            "AFTER change conversations:\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b356989ed61b101a",
        "outputId": "c999497f-3d16-42c7-d26f-4e7c5ca65e3e"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-08-03 18:07:26,335 - temporal_belief.core.timeline_building - INFO - timeline_building:71 - Built timelines for 4781 users\n",
            "INFO:temporal_belief.core.timeline_building:Built timelines for 4781 users\n"
          ]
        }
      ],
      "execution_count": 99,
      "source": [
        "# Test persistence detector:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Filter for analysis\n",
        "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
        "\n",
        "# Convert to list of tupples\n",
        "topic_timeline_list = list(topic_timeline.items())\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"media and political commentary\"\n",
        "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "persistence_detector = ChangeDetector()"
      ],
      "id": "b356989ed61b101a"
    },
    {
      "cell_type": "code",
      "source": [
        "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L1MBPPOaic2F",
        "outputId": "8cf0c673-0aa6-4bb2-db60-01e284c1c24f"
      },
      "id": "L1MBPPOaic2F",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the window extractor:\n",
        "window_extractor = ConversationWindowExtractor(corpus, timelines=timelines)\n",
        "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)\n",
        "recent_convos = window_extractor.get_conversation_around_change_point(change_points=change_points, corpus=corpus)\n",
        "for convo in recent_convos:\n",
        "  print(f'ID:{convo.id}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "18KTGg8HAEJV",
        "outputId": "2def5ce3-04cf-4a4b-a661-c0975bf0fb45"
      },
      "id": "18KTGg8HAEJV",
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
            "ID:muccw\n",
            "ID:mv2yv\n",
            "ID:mv3ou\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(change_points)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "atuQv-CBkHt6",
        "outputId": "38fc4518-a65b-4bf5-be27-fe1833efccb6"
      },
      "id": "atuQv-CBkHt6",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(141, 'c3dpsmt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(topic_timeline_list[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "L4ePoNkPOifg",
        "outputId": "09f7eb0b-913c-475f-a89f-f75a30f746d0"
      },
      "id": "L4ePoNkPOifg",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lnrey\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:27:22.794077Z",
          "start_time": "2025-07-14T10:27:10.717627Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e5cd23a3a61604c",
        "outputId": "aac6e556-08e6-4f8f-93a4-97d5169afbc1"
      },
      "cell_type": "code",
      "source": [
        "# Detect changes with significance:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Filter for analysis\n",
        "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"media and political commentary\"\n",
        "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = ChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(significant_changes)} statistically significant stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in significant_changes:\n",
        "    print(f\"  {change['stance_before']} → {change['stance_after']} (magnitude: {change['magnitude']:.3f}, p={change['p_corrected']:.4f})\")"
      ],
      "id": "9e5cd23a3a61604c",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 0 statistically significant stance changes for user HardCoreModerate on topic media and political commentary:\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Test window extractor\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]\n",
        "\n",
        "# Get significant changes\n",
        "detector = ChangeDetector()\n",
        "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
        "\n",
        "if significant_changes:\n",
        "    # Test the window extractor\n",
        "    extractor = ConversationWindowExtractor(corpus, timelines)\n",
        "    window_data = extractor.get_conversations_around_change(\n",
        "        user_id=user_id,\n",
        "        topic=topic,\n",
        "        change=significant_changes[0],\n",
        "        window_size=2  # 2 conversations before + 2 after\n",
        "    )\n",
        "\n",
        "    # Print summary\n",
        "    extractor.print_window_summary(window_data)\n",
        "else:\n",
        "    print(\"No significant changes found to test with\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkM5xlBWrl-X",
        "outputId": "94aff112-5932-44c9-d38c-2fdd9103a9eb"
      },
      "id": "XkM5xlBWrl-X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No significant changes found to test with\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:46:54.285111Z",
          "start_time": "2025-07-14T10:46:54.278201Z"
        },
        "id": "d6a1cb6bb6b62c85",
        "outputId": "cbaf6df3-ad32-4863-c995-0c67b1df0fab"
      },
      "cell_type": "code",
      "source": [
        "# Most populated topic for a user\n",
        "def topic_with_most_contributions(user_id):\n",
        "    posts_in_topic = {}\n",
        "    for topic in timelines[user_id].keys():\n",
        "      posts_in_topic[topic] = len(list(timelines[user_id][topic]))\n",
        "    # key with the largest value\n",
        "    topic = max(posts_in_topic, key=posts_in_topic.get)\n",
        "\n",
        "    return topic, posts_in_topic[topic]\n",
        "\n",
        "# Yea the number came cause the posts_in_topic was not encapsulated\n",
        "user_id = 'HardCoreModerate'\n",
        "topic, number = topic_with_most_contributions(user_id)\n",
        "print(f\"{topic}: {number}\")\n",
        "# print(posts_in_topic)"
      ],
      "id": "d6a1cb6bb6b62c85",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "media and political commentary: 145\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "cd56563c479c5f7f"
      },
      "cell_type": "code",
      "source": [
        "# Total number of users with metadata (unfiltered)\n",
        "print(len(timelines))"
      ],
      "id": "cd56563c479c5f7f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-14T10:51:13.890752Z",
          "start_time": "2025-07-14T10:51:13.850561Z"
        },
        "id": "484f1d1c47361a1f"
      },
      "cell_type": "code",
      "source": [
        "# NOT WORKING\n",
        "# user with the most utterances:\n",
        "# I have to find the max between their topics and then find the overall max\n",
        "users = {}\n",
        "for user_id, data in timelines.items():\n",
        "    topic, number = topic_with_most_contributions(user_id)\n",
        "    users[user_id] = topic\n",
        "    users[user_id][topic] = number\n",
        "\n",
        "for user in users:\n",
        "    print(user)\n",
        "# user_id = max(users, key=users.get)\n",
        "# print(f\"{user_id}: {users[user_id]}\")"
      ],
      "id": "484f1d1c47361a1f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-13T14:02:24.843970Z",
          "start_time": "2025-07-13T14:02:12.281770Z"
        },
        "id": "fa8987174cfc2918",
        "outputId": "8d33f8e0-0b83-4332-df71-6ee72803ad5c"
      },
      "cell_type": "code",
      "source": [
        "# Detect simple stance change:\n",
        "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=3, min_topics_per_user=1)\n",
        "timelines = timeline_builder.build_timelines()\n",
        "\n",
        "# Get a specific user's timeline for a specific topic\n",
        "user_id = \"HardCoreModerate\"\n",
        "topic = \"taxation and government spending\"\n",
        "topic_timeline = timelines[user_id][topic]  # This is {utterance_id: stance}\n",
        "\n",
        "# Initialize detector and detect changes\n",
        "detector = ChangeDetector()\n",
        "changes = detector.detect_simple_stance_changes(topic_timeline)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Detected {len(changes)} stance changes for user {user_id} on topic {topic}:\")\n",
        "for change in changes:\n",
        "    print(f\"  {change['from_stance']} → {change['to_stance']} (magnitude: {change['change_magnitude']})\")"
      ],
      "id": "fa8987174cfc2918",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected 2 stance changes for user HardCoreModerate on topic taxation and government spending:\n",
            "  moderately_against → neutral (magnitude: 1)\n",
            "  neutral → moderately_against (magnitude: 1)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "f414b5573c4a4ca6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [
        "# for user_id in"
      ],
      "id": "f414b5573c4a4ca6"
    },
    {
      "metadata": {
        "id": "ad5e6484d5f466e1"
      },
      "cell_type": "code",
      "source": [
        "# Run detection for all topics for a user - NOT TESTED:\n",
        "# Get complete user timeline\n",
        "user_timeline = timelines[\"pixel8\"]  # All topics for this user\n",
        "\n",
        "# Analyze changes across all topics\n",
        "detector = ChangeDetector()\n",
        "all_changes = detector.analyze_user_belief_changes(user_timeline)\n",
        "\n",
        "# Results\n",
        "for topic, changes in all_changes.items():\n",
        "    print(f\"Topic: {topic}\")\n",
        "    for change in changes:\n",
        "        print(f\"  Change at position {change['position']}: magnitude {change['magnitude']}\")"
      ],
      "id": "ad5e6484d5f466e1",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "76049e46c5223f2d"
      },
      "cell_type": "code",
      "source": [
        "# All users that meet the criteria:\n",
        "print(\"Available users:\")\n",
        "print(list(timelines.keys())[:20])"
      ],
      "id": "76049e46c5223f2d",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "ba90763c4b3d61ed"
      },
      "cell_type": "code",
      "source": [
        "# What topics the users have posted about:\n",
        "for user_id in list(timelines.keys())[:20]:  # Check first 5 users\n",
        "    topics = list(timelines[user_id].keys())\n",
        "    print(f\"{user_id}: {topics}\")\n",
        "    break"
      ],
      "id": "ba90763c4b3d61ed",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-07-07T12:45:16.821978Z",
          "start_time": "2025-07-07T12:45:16.653806Z"
        },
        "id": "1fee47509c799599",
        "outputId": "7e5ab68d-0188-48b4-d945-0687433058f6"
      },
      "cell_type": "code",
      "source": [
        "# confidence score:\n",
        "utterances = list(corpus.iter_utterances())\n",
        "print(utterances[1].meta)"
      ],
      "id": "1fee47509c799599",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ConvoKitMeta({'score': 29, 'top_level_comment': None, 'retrieved_on': -1, 'gilded': -1, 'gildings': None, 'subreddit': 'PoliticalDiscussion', 'stickied': False, 'permalink': '/r/PoliticalDiscussion/comments/nz1xu/congrats_rpoliticaldiscussion_you_are_turning/', 'author_flair_text': '', 'detected_stance': 'moderately_against', 'stance_confidence': 0.8540321985880533, 'stance_scores': {'strongly_favor': 0.0016047263949682626, 'moderately_favor': 0.5134096046288809, 'neutral': 0.0072105322033166885, 'moderately_against': 0.8540321985880533, 'strongly_against': 0.3021060957883795}})\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "a81d7e7fa2b05740"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null,
      "source": [],
      "id": "a81d7e7fa2b05740"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}