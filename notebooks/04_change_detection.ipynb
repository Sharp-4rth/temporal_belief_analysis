{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T08:09:51.278612Z",
     "start_time": "2025-07-14T08:08:08.657634Z"
    },
    "id": "bbad0be784b4869a"
   },
   "cell_type": "code",
   "source": [
    "# Need to restart after:\n",
    "!pip install convokit"
   ],
   "id": "bbad0be784b4869a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Download file from Google Drive to colab directory\n",
    "!pip install gdown\n",
    "file_id = \"1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0\"\n",
    "!gdown \"https://drive.google.com/file/d/1N0U_jUJlOYjdaju2FaU8p87uB22YBxJ0/view?usp=sharing\" -O \"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\" --fuzzy"
   ],
   "metadata": {
    "id": "oJ1WKmwwZQYL"
   },
   "id": "oJ1WKmwwZQYL",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Unzip with python:\n",
    "import zipfile\n",
    "zipfile.ZipFile(\"/content/temporal_belief_analysis/pd_corpus_with_topics10000_chronological.zip\").extractall(\"/content/temporal_belief_analysis\")"
   ],
   "metadata": {
    "id": "B2PlEx8QYzgg"
   },
   "id": "B2PlEx8QYzgg",
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# For runpod-jupyter or local (run twice)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Change to the correct working directory (workspace if runpod, content if colab)\n",
    "os.chdir('/content/temporal_belief_analysis/notebooks')\n",
    "print(\"Changed working directory to:\", os.getcwd())\n",
    "\n",
    "# Absolute path to src directory\n",
    "src_path = os.path.abspath(os.path.join(os.getcwd(), '..', 'src'))\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "# Comment out if in colab:\n",
    "from temporal_belief.core.timeline_building import TimelineBuilder"
   ],
   "metadata": {
    "id": "_yv_LVXGjggY",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "outputId": "509fa62d-cacb-4129-c7b1-5fefed8abec1"
   },
   "id": "_yv_LVXGjggY",
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Changed working directory to: /content/temporal_belief_analysis/notebooks\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# For colab:\n",
    "from temporal_belief_analysis.src.temporal_belief.core.timeline_building import TimelineBuilder"
   ],
   "metadata": {
    "id": "3sIZWUc9i5WL"
   },
   "id": "3sIZWUc9i5WL",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "22220bf09f61753c"
   },
   "cell_type": "code",
   "source": [
    "# Run twice\n",
    "# import unsloth\n",
    "# import unsloth_zoo\n",
    "from convokit import Corpus, download\n",
    "import convokit"
   ],
   "id": "22220bf09f61753c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "781d4e0509ad3c21"
   },
   "cell_type": "code",
   "source": [
    "# Load a corpus:\n",
    "# corpus = Corpus(filename=\"/Users/leonidas/.convokit/saved-corpora/pd_corpus_with_stances1000_chronological\")\n",
    "corpus = Corpus(filename=\"/content/temporal_belief_analysis/pd_corpus_with_stances100000_chronological\")"
   ],
   "id": "781d4e0509ad3c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "print(corpus.meta)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31uKA6O37H9J",
    "outputId": "a19ffb8d-feb7-41bb-9da9-44503276d2b2"
   },
   "id": "31uKA6O37H9J",
   "execution_count": 50,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ConvoKitMeta({'subreddit': 'PoliticalDiscussion', 'num_posts': 102848, 'num_comments': 4553046})\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T08:17:28.390010Z",
     "start_time": "2025-07-14T08:17:20.788691Z"
    },
    "id": "ad611eb7998835c2"
   },
   "cell_type": "code",
   "source": [
    "!pip install scipy\n",
    "!pip install statsmodels"
   ],
   "id": "ad611eb7998835c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T10:26:41.170080Z",
     "start_time": "2025-07-14T10:26:41.164333Z"
    },
    "id": "de0d75b2335f7dce"
   },
   "cell_type": "code",
   "source": [
    "def filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2, min_confidence=0.0):\n",
    "    \"\"\"Filter timelines to only include users/topics suitable for change detection\"\"\"\n",
    "    filtered_timelines = {}\n",
    "\n",
    "    for user_id, user_timeline in timelines.items():\n",
    "        filtered_user_timeline = {}\n",
    "\n",
    "        for topic, topic_posts in user_timeline.items():\n",
    "            # Filter by confidence (if you have access to corpus here)\n",
    "            reliable_posts = {}\n",
    "            for utt_id, stance in topic_posts.items():\n",
    "                # You'd need to pass corpus or confidence scores here\n",
    "                # For now, assume all posts are reliable\n",
    "                reliable_posts[utt_id] = stance\n",
    "\n",
    "            # Check minimum posts per topic\n",
    "            if len(reliable_posts) >= min_posts_per_topic:\n",
    "                filtered_user_timeline[topic] = reliable_posts\n",
    "\n",
    "        # Check minimum topics per user\n",
    "        if len(filtered_user_timeline) >= min_topics_per_user:\n",
    "            filtered_timelines[user_id] = filtered_user_timeline\n",
    "\n",
    "    return filtered_timelines"
   ],
   "id": "de0d75b2335f7dce",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "class ConversationWindowExtractor:\n",
    "    def __init__(self, corpus, timelines):\n",
    "        self.corpus = corpus\n",
    "        self.timelines = timelines\n",
    "\n",
    "    def get_user_conversations_chronological(self, corpus, speaker_id):\n",
    "      \"\"\"Get all conversations for a user in chronological order.\"\"\"\n",
    "\n",
    "      # Get all conversations where the speaker participated\n",
    "      user_conversations = [convo for convo in corpus.iter_conversations()\n",
    "                          if speaker_id in [utt.speaker.id for utt in convo.iter_utterances()]]\n",
    "\n",
    "      # Sort conversations by their earliest timestamp\n",
    "      user_conversations.sort(key=lambda convo: min(utt.timestamp for utt in convo.iter_utterances()))\n",
    "\n",
    "      return user_conversations\n",
    "\n",
    "    def get_conversations_around_change_point(self, corpus, change_points):\n",
    "      # Get first change (probably only one I need)\n",
    "      utterance = corpus.get_utterance(change_points[0][1])\n",
    "\n",
    "      # Find the convo this utterance belongs to:\n",
    "      conversation = utterance.get_conversation()\n",
    "\n",
    "      # Put all user's convos in a list\n",
    "      speaker_id = utterance.speaker.id\n",
    "      user_conversations = self.get_user_conversations_chronological(corpus, speaker_id)\n",
    "\n",
    "      candidate_convos = []\n",
    "      # find the index of the convo, and return the convo id of the 3 prior convos\n",
    "      for i, convo in enumerate(user_conversations):\n",
    "        if conversation.id == user_conversations[i].id:\n",
    "          candidate_convos.append(user_conversations[i-2])\n",
    "          candidate_convos.append(user_conversations[i-1])\n",
    "\n",
    "      # Append the first convo at the end so they are in chronological order\n",
    "      candidate_convos.append(conversation)\n",
    "\n",
    "      return candidate_convos\n",
    "\n",
    "    def _trim_paths(self, op_utterance):\n",
    "        try:\n",
    "          conversation = op_utterance.get_conversation()\n",
    "        except Exception as e:\n",
    "          print(f\"Can't access convo from utterance, error{e}\")\n",
    "\n",
    "        paths = conversation.get_root_to_leaf_paths()\n",
    "\n",
    "        trimmed_paths = []\n",
    "        for path in paths:\n",
    "            if op_utterance in path:\n",
    "                # Find where op_utterance is in this path\n",
    "                op_index = path.index(op_utterance)\n",
    "                # Slice from that index onwards\n",
    "                trimmed_path = path[op_index+1:]\n",
    "                trimmed_paths.append(trimmed_path)\n",
    "\n",
    "        return trimmed_paths\n",
    "\n",
    "    def _filter_paths(self, trimmed_paths):\n",
    "        filtered_paths = {}\n",
    "        for path_index, path in enumerate(trimmed_paths):\n",
    "            for utt in path:\n",
    "                key = f\"{utt.speaker.id}_path_{path_index}\"\n",
    "                if key not in filtered_paths:\n",
    "                    filtered_paths[key] = []\n",
    "                filtered_paths[key].append(utt)\n",
    "\n",
    "        return filtered_paths\n",
    "\n",
    "    def extract_rooted_paths(self, op_utterance):\n",
    "        trimmed_path = self._trim_paths(op_utterance)\n",
    "        filtered_path = self._filter_paths(trimmed_path)\n",
    "\n",
    "        return filtered_path\n",
    "\n",
    "    # Find the op_utterances from a convo and add them to a list\n",
    "    def extract_op_utterances_from_convo(self, candidate_convo, user_id):\n",
    "        paths = candidate_convo.get_root_to_leaf_paths()\n",
    "        op_utterances = []\n",
    "        for path in paths:\n",
    "            for utt in path:\n",
    "                if utt.speaker.id == user_id and utt not in op_utterances:\n",
    "                    op_utterances.append(utt)\n",
    "                    break\n",
    "\n",
    "        return op_utterances\n",
    "\n",
    "    # Get all op_utterances accross every candidate convo\n",
    "    def extract_op_utterances_from_all_convos(self, candidate_convos, user_id):\n",
    "        all_op_utterances = []\n",
    "        for candidate_convo in candidate_convos:\n",
    "            op_utterances = self.extract_op_utterances_from_convo(candidate_convo, user_id)\n",
    "            all_op_utterances.extend(op_utterances)\n",
    "\n",
    "        return all_op_utterances\n",
    "\n",
    "    # Get the paths of an op_utterance from the op_utterances list\n",
    "    def extract_rooted_path_from_candidate_convos(self, candidate_convos, user_id):\n",
    "        all_op_utterances = self.extract_op_utterances_from_all_convos(candidate_convos, user_id)\n",
    "\n",
    "        # debug:\n",
    "        for op_utt in all_op_utterances:\n",
    "          print(f'my input user_id: {user_id}')\n",
    "          speaker_id = corpus.get_utterance(op_utt.id).speaker.id\n",
    "          print(f'Utt_id: {op_utt.id} and user_id: {speaker_id} in the list of all op utterances.')\n",
    "\n",
    "        all_ops_n_paths = []\n",
    "        for op_utt in all_op_utterances:\n",
    "            # So rooted paths is a dict. Should I convert to list?\n",
    "            rooted_paths = self.extract_rooted_paths(op_utt)\n",
    "\n",
    "            op_n_paths = (op_utt, rooted_paths)\n",
    "            all_ops_n_paths.append(op_n_paths)\n",
    "\n",
    "        return all_ops_n_paths"
   ],
   "metadata": {
    "id": "zj51bpjrpjTd"
   },
   "id": "zj51bpjrpjTd",
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def calculate_interplay_features(op_text, reply_path_text, stop_words_set):\n",
    "    \"\"\"Calculate 12 interplay features between OP and reply path.\"\"\"\n",
    "\n",
    "    # Tokenize and clean\n",
    "    op_words = op_text.lower().split()\n",
    "    reply_words = reply_path_text.lower().split()\n",
    "\n",
    "    # Create word sets\n",
    "    op_all = set(op_words)\n",
    "    reply_all = set(reply_words)\n",
    "    op_stop = set(w for w in op_words if w in stop_words_set)\n",
    "    reply_stop = set(w for w in reply_words if w in stop_words_set)\n",
    "    op_content = set(w for w in op_words if w not in stop_words_set)\n",
    "    reply_content = set(w for w in reply_words if w not in stop_words_set)\n",
    "\n",
    "    # Calculate 4 metrics for each word type\n",
    "    features = {}\n",
    "\n",
    "    for word_type, (op_set, reply_set) in [\n",
    "        ('all', (op_all, reply_all)),\n",
    "        ('stop', (op_stop, reply_stop)),\n",
    "        ('content', (op_content, reply_content))\n",
    "    ]:\n",
    "        intersection = len(op_set & reply_set)\n",
    "        union = len(op_set | reply_set)\n",
    "\n",
    "        features[f'common_words_{word_type}'] = intersection\n",
    "        features[f'sim_frac_reply_{word_type}'] = intersection / len(reply_set) if reply_set else 0\n",
    "        features[f'sim_frac_op_{word_type}'] = intersection / len(op_set) if op_set else 0\n",
    "        features[f'jaccard_{word_type}'] = intersection / union if union else 0\n",
    "\n",
    "    return features"
   ],
   "metadata": {
    "id": "NcIbPuXLvoL0"
   },
   "id": "NcIbPuXLvoL0",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-14T10:26:41.492540Z",
     "start_time": "2025-07-14T10:26:41.473273Z"
    },
    "id": "initial_id"
   },
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from collections import Counter\n",
    "import logging\n",
    "\n",
    "class ChangeDetector:\n",
    "    \"\"\"Sliding window change detection with proper statistical significance.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size=3, significance_level=0.05):\n",
    "        self.window_size = window_size\n",
    "        self.alpha = significance_level\n",
    "        self.stance_values = {\n",
    "            'strongly_against': -2, 'moderately_against': -1,\n",
    "            'neutral': 0, 'moderately_favor': 1, 'strongly_favor': 2\n",
    "        }\n",
    "\n",
    "    def detect_simple_stance_changes(self, topic_timeline):\n",
    "\n",
    "        if len(topic_timeline) < 2:\n",
    "            return []\n",
    "\n",
    "        changes = []\n",
    "        timeline_items = list(topic_timeline.items())  # Convert to list of (utterance_id, stance) pairs\n",
    "\n",
    "        for i in range(1, len(timeline_items)):\n",
    "            current_utterance_id, current_stance = timeline_items[i]\n",
    "            previous_utterance_id, previous_stance = timeline_items[i-1]\n",
    "\n",
    "            # Check if stance changed\n",
    "            if current_stance != previous_stance:\n",
    "                change = {\n",
    "                    'position': i,\n",
    "                    'current_utterance_id': current_utterance_id,\n",
    "                    'previous_utterance_id': previous_utterance_id,\n",
    "                    'from_stance': previous_stance,\n",
    "                    'to_stance': current_stance,\n",
    "                    'change_type': self._classify_change_direction(previous_stance, current_stance),\n",
    "                    'change_magnitude': self._calculate_simple_magnitude(previous_stance, current_stance)\n",
    "                }\n",
    "                changes.append(change)\n",
    "\n",
    "        return changes\n",
    "\n",
    "    def detect_persistent_changes(self, topic_timeline):\n",
    "        \"\"\"Detect persistent changes in stance.\"\"\"\n",
    "\n",
    "        # Convert to (utt_id, detected_stance) tuple\n",
    "        # topic_timeline_list = list(topic_timeline.items())\n",
    "\n",
    "        # Collect the tuples where the stance is persistent across n utterances\n",
    "        change_points = []\n",
    "\n",
    "        for i in range(len(topic_timeline)):\n",
    "          # if current stance is different than prior\n",
    "          if topic_timeline[i][1] != topic_timeline[i-1][1]:\n",
    "            # Check if change persists for more than 1 post\n",
    "            if topic_timeline[i][1] == topic_timeline[i+1][1]:\n",
    "              change_index = i\n",
    "              utt_id = topic_timeline[i][0]\n",
    "              change_point = (change_index, utt_id)\n",
    "              change_points.append(change_point)\n",
    "              print(f\"Current:{topic_timeline[i][1]}, Previous: {topic_timeline[i-1][1]} and Next:{topic_timeline[i+1][1]}\")\n",
    "\n",
    "        return change_points\n",
    "\n",
    "    def _classify_change_direction(self, from_stance, to_stance):\n",
    "        \"\"\"Classify the direction of stance change.\"\"\"\n",
    "        from_value = self.stance_values.get(from_stance, 0)\n",
    "        to_value = self.stance_values.get(to_stance, 0)\n",
    "\n",
    "        if to_value > from_value:\n",
    "            return 'more_favorable'\n",
    "        elif to_value < from_value:\n",
    "            return 'less_favorable'\n",
    "        else:\n",
    "            return 'neutral_shift'\n",
    "\n",
    "    def _calculate_simple_magnitude(self, from_stance, to_stance):\n",
    "        \"\"\"Calculate the magnitude of stance change.\"\"\"\n",
    "        from_value = self.stance_values.get(from_stance, 0)\n",
    "        to_value = self.stance_values.get(to_stance, 0)\n",
    "        return abs(to_value - from_value)\n",
    "\n",
    "    def detect_changes_with_significance(self, topic_timeline):\n",
    "        \"\"\"Detect changes with statistical significance testing.\"\"\"\n",
    "\n",
    "        if len(topic_timeline) < self.window_size * 2:\n",
    "            return [], [], []\n",
    "\n",
    "        # Convert to lists to maintain order and get IDs\n",
    "        timeline_items = list(topic_timeline.items())  # [(utterance_id, stance), ...]\n",
    "        stance_sequence = [self.stance_values.get(stance, 0) for _, stance in timeline_items]\n",
    "\n",
    "        potential_changes = []\n",
    "        p_values = []\n",
    "\n",
    "        # Sliding window approach\n",
    "        for i in range(self.window_size, len(stance_sequence) - self.window_size):\n",
    "\n",
    "            # Left window (before potential change)\n",
    "            left_window = stance_sequence[i - self.window_size:i]\n",
    "\n",
    "            # Right window (after potential change)\n",
    "            right_window = stance_sequence[i:i + self.window_size]\n",
    "\n",
    "            # Statistical test: Are these two windows significantly different?\n",
    "            statistic, p_value = self.two_sample_test(left_window, right_window)\n",
    "\n",
    "            p_values.append(p_value)\n",
    "\n",
    "            # Store potential change info with just the key utterance ID\n",
    "            change_magnitude = abs(np.mean(right_window) - np.mean(left_window))\n",
    "            potential_changes.append({\n",
    "                'position': i,\n",
    "                'utterance_id': timeline_items[i][0],  # The utterance where change detected\n",
    "                'p_value': p_value,\n",
    "                'test_statistic': statistic,\n",
    "                'magnitude': change_magnitude,\n",
    "                'left_mean': np.mean(left_window),\n",
    "                'right_mean': np.mean(right_window),\n",
    "                'left_window': left_window.copy(),\n",
    "                'right_window': right_window.copy()\n",
    "            })\n",
    "\n",
    "        # Apply FDR correction to all p-values\n",
    "        if not p_values:\n",
    "            return [], [], []\n",
    "\n",
    "        rejected, p_corrected = self.multiple_testing_correction(p_values)\n",
    "\n",
    "        # Keep only changes that survive FDR correction\n",
    "        significant_changes = []\n",
    "        for i, change in enumerate(potential_changes):\n",
    "            if rejected[i]:  # Survives FDR correction\n",
    "                change.update({\n",
    "                    'p_corrected': p_corrected[i],\n",
    "                    'statistically_significant': True,\n",
    "                    'survives_fdr_correction': True,\n",
    "                    'significance_level': self.alpha\n",
    "                })\n",
    "                significant_changes.append(change)\n",
    "\n",
    "        return significant_changes, p_values, p_corrected\n",
    "\n",
    "    def two_sample_test(self, left_window, right_window):\n",
    "        \"\"\"Statistical test for difference between two windows.\"\"\"\n",
    "        # Use Mann-Whitney U test (non-parametric, more robust)\n",
    "        try:\n",
    "            statistic, p_value = mannwhitneyu(left_window, right_window,\n",
    "                                            alternative='two-sided')\n",
    "            return statistic, p_value\n",
    "        except ValueError:\n",
    "            # Fallback to t-test if Mann-Whitney fails\n",
    "            statistic, p_value = ttest_ind(left_window, right_window)\n",
    "            return statistic, p_value\n",
    "\n",
    "    def multiple_testing_correction(self, p_values):\n",
    "        \"\"\"Correct for multiple testing using Benjamini-Hochberg.\"\"\"\n",
    "        rejected, p_corrected = fdrcorrection(p_values, alpha=self.alpha)\n",
    "        return rejected, p_corrected\n",
    "\n",
    "    # def analyze_user_belief_changes(self, user_timeline):\n",
    "    #     \"\"\"Analyze belief changes across all topics for a user.\"\"\"\n",
    "    #     all_changes = {}\n",
    "    #\n",
    "    #     for topic, topic_timeline in user_timeline.items():\n",
    "    #         changes = self.detect_changes_with_significance(topic_timeline)\n",
    "    #         all_changes[topic] = changes\n",
    "    #\n",
    "    #     return all_changes\n",
    "\n",
    "    def analyze_user_belief_changes(self, user_timeline):\n",
    "        \"\"\"Analyze belief changes across all topics for a user.\n",
    "\n",
    "        Args:\n",
    "            user_timeline: Dict of {topic: {utterance_id: stance}}\n",
    "\n",
    "        Returns:\n",
    "            Dict with changes by topic and total count\n",
    "        \"\"\"\n",
    "        all_changes = {}\n",
    "        total_changes = 0\n",
    "\n",
    "        for topic, topic_timeline in user_timeline.items():\n",
    "            significant_changes, p_values, p_corrected = self.detect_changes_with_significance(topic_timeline)\n",
    "            all_changes[topic] = significant_changes\n",
    "            total_changes += len(significant_changes)\n",
    "\n",
    "        return {\n",
    "            'changes_by_topic': all_changes,\n",
    "            'total_changes': total_changes\n",
    "        }\n",
    "\n",
    "    def analyze_all_users_belief_changes(self, timelines):\n",
    "        \"\"\"Analyze belief changes across all users.\n",
    "\n",
    "        Args:\n",
    "            timelines: Dict of {user_id: {topic: {utterance_id: stance}}}\n",
    "\n",
    "        Returns:\n",
    "            Dict with changes by user and total count\n",
    "        \"\"\"\n",
    "        all_user_changes = {}\n",
    "        total_changes = 0\n",
    "\n",
    "        for user_id, user_timeline in timelines.items():\n",
    "            user_result = self.analyze_user_belief_changes(user_timeline)\n",
    "            all_user_changes[user_id] = user_result\n",
    "            total_changes += user_result['total_changes']\n",
    "\n",
    "        return {\n",
    "            'changes_by_user': all_user_changes,\n",
    "            'total_changes': total_changes\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b356989ed61b101a",
    "outputId": "00575cb5-d842-488c-adce-9ca0ba8fa31b"
   },
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2025-08-06 10:45:42,431 - temporal_belief.core.timeline_building - INFO - timeline_building:71 - Built timelines for 4781 users\n",
      "INFO:temporal_belief.core.timeline_building:Built timelines for 4781 users\n"
     ]
    }
   ],
   "execution_count": 46,
   "source": [
    "# Test persistence detector:\n",
    "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
    "timelines = timeline_builder.build_timelines()\n",
    "\n",
    "# Filter for analysis\n",
    "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
    "\n",
    "# Get a specific user's timeline for a specific topic\n",
    "user_id = \"HardCoreModerate\"\n",
    "topic = \"media and political commentary\"\n",
    "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
    "\n",
    "# Convert to list of tupples\n",
    "topic_timeline_list = list(topic_timeline.items())\n",
    "\n",
    "persistence_detector = ChangeDetector()"
   ],
   "id": "b356989ed61b101a"
  },
  {
   "cell_type": "code",
   "source": [
    "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1MBPPOaic2F",
    "outputId": "070f6717-637e-4a42-d553-e781792d75aa"
   },
   "id": "L1MBPPOaic2F",
   "execution_count": 47,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:neutral, Previous: moderately_against and Next:neutral\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_favor, Previous: moderately_against and Next:moderately_favor\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Test the window extractor:\n",
    "window_extractor = ConversationWindowExtractor(corpus, timelines=timelines)\n",
    "change_points = persistence_detector.detect_persistent_changes(topic_timeline_list)\n",
    "candidate_convos = window_extractor.get_conversations_around_change_point(change_points=change_points, corpus=corpus)\n",
    "for convo in candidate_convos:\n",
    "  print(f'ID:{convo.id}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18KTGg8HAEJV",
    "outputId": "e308cc5b-1b97-416f-a0f9-0f4cb543e5d5"
   },
   "id": "18KTGg8HAEJV",
   "execution_count": 48,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:neutral, Previous: moderately_against and Next:neutral\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_favor, Previous: moderately_against and Next:moderately_favor\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: strongly_against and Next:moderately_against\n",
      "Current:moderately_against, Previous: neutral and Next:moderately_against\n",
      "Current:moderately_against, Previous: moderately_favor and Next:moderately_against\n",
      "ID:muccw\n",
      "ID:mv2yv\n",
      "ID:mv3ou\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Should return (op_utterance, paths), (op_utterance2, paths) etc.\n",
    "utt_id = change_points[0][1]\n",
    "user_id = corpus.get_utterance(change_points[0][1]).speaker.id\n",
    "rooted_units_per_convo = window_extractor.extract_rooted_path_from_candidate_convos(candidate_convos, user_id)"
   ],
   "metadata": {
    "id": "A-AsX1NOEyw8"
   },
   "id": "A-AsX1NOEyw8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(change_points)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "atuQv-CBkHt6",
    "outputId": "2d974d85-710d-4e35-c1bf-85bf1dad3c5b"
   },
   "id": "atuQv-CBkHt6",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(20, 'c345fu2'), (26, 'c34bigz'), (30, 'c34e3d0'), (39, 'c37rgne'), (42, 'c37rsmm'), (52, 'c37tt9j'), (54, 'c37tts1'), (64, 'c37vnob'), (71, 'c381lme'), (77, 'c382x1h'), (80, 'c386bvm'), (82, 'c387opl'), (89, 'c3ctdtd'), (104, 'nz1xu'), (108, 'c3d3mf9'), (117, 'c3d8hjg'), (125, 'c3dc5rj'), (135, 'c3df7re'), (142, 'c3dq15f')]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(change_points[0])"
   ],
   "metadata": {
    "id": "k2lo4iqIaJVJ",
    "outputId": "916a3c62-b8ae-4c10-ce24-c3bffee00e1f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "id": "k2lo4iqIaJVJ",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 'c345fu2')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "2DtaqDUGfAv1"
   },
   "id": "2DtaqDUGfAv1",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(topic_timeline_list[0][0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4ePoNkPOifg",
    "outputId": "232a85b7-c668-4d03-a240-046ee7eee72c"
   },
   "id": "L4ePoNkPOifg",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lnrey\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T10:27:22.794077Z",
     "start_time": "2025-07-14T10:27:10.717627Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5cd23a3a61604c",
    "outputId": "aac6e556-08e6-4f8f-93a4-97d5169afbc1"
   },
   "cell_type": "code",
   "source": [
    "# Detect changes with significance:\n",
    "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=0, min_topics_per_user=0)\n",
    "timelines = timeline_builder.build_timelines()\n",
    "\n",
    "# Filter for analysis\n",
    "filtered_timelines = filter_for_change_detection(timelines, min_posts_per_topic=5, min_topics_per_user=2)\n",
    "\n",
    "# Get a specific user's timeline for a specific topic\n",
    "user_id = \"HardCoreModerate\"\n",
    "topic = \"media and political commentary\"\n",
    "topic_timeline = filtered_timelines[user_id][topic]  # This is {utterance_id: stance}\n",
    "\n",
    "# Initialize detector and detect changes\n",
    "detector = ChangeDetector()\n",
    "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Detected {len(significant_changes)} statistically significant stance changes for user {user_id} on topic {topic}:\")\n",
    "for change in significant_changes:\n",
    "    print(f\"  {change['stance_before']} → {change['stance_after']} (magnitude: {change['magnitude']:.3f}, p={change['p_corrected']:.4f})\")"
   ],
   "id": "9e5cd23a3a61604c",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Detected 0 statistically significant stance changes for user HardCoreModerate on topic media and political commentary:\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Test window extractor\n",
    "user_id = \"HardCoreModerate\"\n",
    "topic = \"taxation and government spending\"\n",
    "topic_timeline = timelines[user_id][topic]\n",
    "\n",
    "# Get significant changes\n",
    "detector = ChangeDetector()\n",
    "significant_changes, p_values, p_corrected = detector.detect_changes_with_significance(topic_timeline)\n",
    "\n",
    "if significant_changes:\n",
    "    # Test the window extractor\n",
    "    extractor = ConversationWindowExtractor(corpus, timelines)\n",
    "    window_data = extractor.get_conversations_around_change(\n",
    "        user_id=user_id,\n",
    "        topic=topic,\n",
    "        change=significant_changes[0],\n",
    "        window_size=2  # 2 conversations before + 2 after\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    extractor.print_window_summary(window_data)\n",
    "else:\n",
    "    print(\"No significant changes found to test with\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkM5xlBWrl-X",
    "outputId": "94aff112-5932-44c9-d38c-2fdd9103a9eb"
   },
   "id": "XkM5xlBWrl-X",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "No significant changes found to test with\n"
     ]
    }
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T10:46:54.285111Z",
     "start_time": "2025-07-14T10:46:54.278201Z"
    },
    "id": "d6a1cb6bb6b62c85",
    "outputId": "cbaf6df3-ad32-4863-c995-0c67b1df0fab"
   },
   "cell_type": "code",
   "source": [
    "# Most populated topic for a user\n",
    "def topic_with_most_contributions(user_id):\n",
    "    posts_in_topic = {}\n",
    "    for topic in timelines[user_id].keys():\n",
    "      posts_in_topic[topic] = len(list(timelines[user_id][topic]))\n",
    "    # key with the largest value\n",
    "    topic = max(posts_in_topic, key=posts_in_topic.get)\n",
    "\n",
    "    return topic, posts_in_topic[topic]\n",
    "\n",
    "# Yea the number came cause the posts_in_topic was not encapsulated\n",
    "user_id = 'HardCoreModerate'\n",
    "topic, number = topic_with_most_contributions(user_id)\n",
    "print(f\"{topic}: {number}\")\n",
    "# print(posts_in_topic)"
   ],
   "id": "d6a1cb6bb6b62c85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "media and political commentary: 145\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "cd56563c479c5f7f"
   },
   "cell_type": "code",
   "source": [
    "# Total number of users with metadata (unfiltered)\n",
    "print(len(timelines))"
   ],
   "id": "cd56563c479c5f7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-14T10:51:13.890752Z",
     "start_time": "2025-07-14T10:51:13.850561Z"
    },
    "id": "484f1d1c47361a1f"
   },
   "cell_type": "code",
   "source": [
    "# NOT WORKING\n",
    "# user with the most utterances:\n",
    "# I have to find the max between their topics and then find the overall max\n",
    "users = {}\n",
    "for user_id, data in timelines.items():\n",
    "    topic, number = topic_with_most_contributions(user_id)\n",
    "    users[user_id] = topic\n",
    "    users[user_id][topic] = number\n",
    "\n",
    "for user in users:\n",
    "    print(user)\n",
    "# user_id = max(users, key=users.get)\n",
    "# print(f\"{user_id}: {users[user_id]}\")"
   ],
   "id": "484f1d1c47361a1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T14:02:24.843970Z",
     "start_time": "2025-07-13T14:02:12.281770Z"
    },
    "id": "fa8987174cfc2918",
    "outputId": "8d33f8e0-0b83-4332-df71-6ee72803ad5c"
   },
   "cell_type": "code",
   "source": [
    "# Detect simple stance change:\n",
    "timeline_builder = TimelineBuilder(corpus, min_posts_per_topic=3, min_topics_per_user=1)\n",
    "timelines = timeline_builder.build_timelines()\n",
    "\n",
    "# Get a specific user's timeline for a specific topic\n",
    "user_id = \"HardCoreModerate\"\n",
    "topic = \"taxation and government spending\"\n",
    "topic_timeline = timelines[user_id][topic]  # This is {utterance_id: stance}\n",
    "\n",
    "# Initialize detector and detect changes\n",
    "detector = ChangeDetector()\n",
    "changes = detector.detect_simple_stance_changes(topic_timeline)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Detected {len(changes)} stance changes for user {user_id} on topic {topic}:\")\n",
    "for change in changes:\n",
    "    print(f\"  {change['from_stance']} → {change['to_stance']} (magnitude: {change['change_magnitude']})\")"
   ],
   "id": "fa8987174cfc2918",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 2 stance changes for user HardCoreModerate on topic taxation and government spending:\n",
      "  moderately_against → neutral (magnitude: 1)\n",
      "  neutral → moderately_against (magnitude: 1)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "f414b5573c4a4ca6"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# for user_id in"
   ],
   "id": "f414b5573c4a4ca6"
  },
  {
   "metadata": {
    "id": "ad5e6484d5f466e1"
   },
   "cell_type": "code",
   "source": [
    "# Run detection for all topics for a user - NOT TESTED:\n",
    "# Get complete user timeline\n",
    "user_timeline = timelines[\"pixel8\"]  # All topics for this user\n",
    "\n",
    "# Analyze changes across all topics\n",
    "detector = ChangeDetector()\n",
    "all_changes = detector.analyze_user_belief_changes(user_timeline)\n",
    "\n",
    "# Results\n",
    "for topic, changes in all_changes.items():\n",
    "    print(f\"Topic: {topic}\")\n",
    "    for change in changes:\n",
    "        print(f\"  Change at position {change['position']}: magnitude {change['magnitude']}\")"
   ],
   "id": "ad5e6484d5f466e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "76049e46c5223f2d"
   },
   "cell_type": "code",
   "source": [
    "# All users that meet the criteria:\n",
    "print(\"Available users:\")\n",
    "print(list(timelines.keys())[:20])"
   ],
   "id": "76049e46c5223f2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "ba90763c4b3d61ed"
   },
   "cell_type": "code",
   "source": [
    "# What topics the users have posted about:\n",
    "for user_id in list(timelines.keys())[:20]:  # Check first 5 users\n",
    "    topics = list(timelines[user_id].keys())\n",
    "    print(f\"{user_id}: {topics}\")\n",
    "    break"
   ],
   "id": "ba90763c4b3d61ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-07T12:45:16.821978Z",
     "start_time": "2025-07-07T12:45:16.653806Z"
    },
    "id": "1fee47509c799599",
    "outputId": "7e5ab68d-0188-48b4-d945-0687433058f6"
   },
   "cell_type": "code",
   "source": [
    "# confidence score:\n",
    "utterances = list(corpus.iter_utterances())\n",
    "print(utterances[1].meta)"
   ],
   "id": "1fee47509c799599",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvoKitMeta({'score': 29, 'top_level_comment': None, 'retrieved_on': -1, 'gilded': -1, 'gildings': None, 'subreddit': 'PoliticalDiscussion', 'stickied': False, 'permalink': '/r/PoliticalDiscussion/comments/nz1xu/congrats_rpoliticaldiscussion_you_are_turning/', 'author_flair_text': '', 'detected_stance': 'moderately_against', 'stance_confidence': 0.8540321985880533, 'stance_scores': {'strongly_favor': 0.0016047263949682626, 'moderately_favor': 0.5134096046288809, 'neutral': 0.0072105322033166885, 'moderately_against': 0.8540321985880533, 'strongly_against': 0.3021060957883795}})\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a81d7e7fa2b05740"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "a81d7e7fa2b05740"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": [],
   "machine_shape": "hm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
